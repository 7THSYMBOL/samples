[{
	"State": "live",
	"name": "021_pair_at_work",
	"description": "This example shows off the Pair operator that is used for pairing tuples arriving on different input ports. Only when all the tuples arrive at all the input ports, this operator will emit them one after the other in their order of arrival.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/021_pair_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["pair", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "'096_consistent_region_spl_07",
	"description": "This particular example shows how a C++ primitive operator can play a role inside a consistent region.  It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/096_consistent_region_cpp_07_com_acme_test_ConsistentRegion7_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "097_consistent_region_spl_08",
	"description": "This particular example shows how a C++ primitive operator can be the start of a consistent region.   It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/097_consistent_region_cpp_08_com_acme_test_ConsistentRegion8_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "098_consistent_region_spl_09",
	"description": "This particular example shows how a Java primitive operator can be the start of a consistent region. ",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/098_consistent_region_java_09_com_acme_test_ConsistentRegion9_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "099_consistent_region_spl_10",
	"description": "This particular example shows how a Java primitive operator can play a role inside a consistent region. It demonstrates how to implement the necessary callback functions to support checkpoint and reset.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/099_consistent_region_java_10_com_acme_test_ConsistentRegion10_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "052_streams_to_python",
	"description": "This example shows a powerful feature of Streams to wrap existing code assets written using the Python programming language. This example teaches developers how to use the Streams C++ native functions to call any arbitrary Python function and return the results back to SPL code. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory. You can also read a very detailed IBM developerWorks technical article about this example:  http://tinyurl.com/c3s56fq. [THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED StreamsToPythonLib THAT IS DESCRIBED BELOW.]",
	"language": ["Python"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/052_streams_to_python_python_wrapper_example_streams_to_python_spl",
	"urlLink": "",
	"tags": ["call python from streams", "call python from cpp", " python"]
}, {
	"State": "live",
	"name": "042_dynamic_import_export_api_at_work",
	"description": "This example shows how to use the SPL APIs for dynamically importing and exporting streams. This is achieved by changing the import and export properties on the fly. This powerful feature in Streams provides a way to change the streams producing and consuming operators to change the way in which they publish and subscribe to streams while the application is running.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/042_dynamic_import_export_api_at_work_dynamic_importing_exporting_dynamic_import_spl",
	"urlLink": "",
	"tags": ["import", "export", "dynamic import", "microservices", "export stream", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "045_file_source_using_spl_custom_operator",
	"description": "This example shows how to create source operators using the Custom operator available in the SPL standard toolkit. Starting in Streams 3.x, it is possible to create source operators without writing primitive source operators in C++ or Java. Simple source operators can be written using the built-in SPL Custom operator. This will come handy for those who don't want to do an extra layer of C++ or Java code for satisfying simple needs for a source operator. You will see a function of a file source operator being implemented all using SPL code in this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions,Ingest & Store Data", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/045_file_source_using_spl_custom_operator_my_file_source_file_source_using_spl_custom_operator_spl",
	"urlLink": "",
	"tags": ["read a file using a custom", "custom", "read a file", "filesource", "open a file", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "032_native_function_at_work",
	"description": "This application shows how native functions written in C++ can be called within an SPL application.There are two ways in which native functions can be written in C++.1) Code for the C++ functions can be written in a C++ header file.2) C++ functions can be written outside of the SPL project and packaged into a shared library (.so) file. All the SPL developer will have to work with are an .so file and a C++ header file.This application demonstrates incorporating native functions built in both of those ways.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/032_native_function_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["native functions", " c++", "native functions", " native function model"]
}, {
	"State": "live",
	"name": "018_directory_scan_at_work",
	"description": "This example demonstrates one of the important features desired in the real world (mostly in the Retail banking and in the Telco industries). In many real-world scenarios, they still work via files and such files get dropped into a directory for processing. It is shown here how the DirectoryScan operator picks up a new file as soon as it appears inside an input directory. (Apply caution if huge files are copied to the watch directory. DirectoryScan may detect that big file copy as multiple new files and output multiple tuples with the same file name.)",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/018_directory_scan_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["directoryscan", "read directory repeatedly", "scan directory", "list directory"]
}, {
	"State": "live",
	"name": "011_compiler_intrinsic_functions",
	"description": "Streams compiler provides several intrinsic functions to query the SPL filename, file path, absolute path of the directory, source code line number, composite instance name etc. This example shows the use of the compiler intrinsic functions inside of a Functor operator.",
	"language": ["SPL"],
	"category": ["troubleshooting", " Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/011_compiler_intrinsic_functions_Main_spl",
	"urlLink": "",
	"tags": ["compiler functions", " utility", "print line number", " current line number", " print line number", " print file name", " get file name", " print debug info"]
}, {
	"State": "live",
	"name": "041_real_time_streams_merger",
	"description": "This example shows how two or more incoming streams with a common schema can be merged to flow in a sequence one after the other. This merger is done using a common tuple attribute in those multiple incoming streams as a key. We will use a C++ primitive operator called OrderedMerger that is included in this project. In order for the OrderedMerger to work correctly, it is assumed that multiple input streams for this primitive operator should already be in sorted order based on the key used to merge and sequence them together. ",
	"language": ["C++"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/041_real_time_streams_merger_real_time_merger_real_time_streams_merger_spl",
	"urlLink": "",
	"tags": ["ordered merge of multiple streams ", "c++ example", "merge  streams", " join streams", " c++ operator model", " application development", " ordered merge"]
}, {
	"State": "live",
	"name": "060_simple_pe_failover_technique_at_work",
	"description": "This example shows a way to protect the logic in an analytic operator  when its PE (Processing Element) or its host machine crashes. It uses a well-known fail-over technique that is done through a primary/secondary pair configured for an operator that will need safety from PE or machine crash. This example outlines a scheme for protecting the analytic logic written inside an SPL Custom operator against failures. When such failures occur, a specific fail-over technique employed here will continue the business logic without any interruption. This is done by making a secondary PE to takeover the tasks of the failed primary PE. Thus, the secondary PE does the detection of the primary PE's failure and then changes its role from a secondary PE to a new primary PE. All of this is done without losing any data during the fail-over. At the same time, the failed primary PE will be automatically restarted to do its work as a new secondary PE. This particular fail-over technique ensures that there is always a primary/secondary pair working in concert to provide high availability for a business-critical operator that is coded and configured in this manner.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/060_simple_pe_failover_technique_at_work_com_acme_failover_test_simple_pe_failover_technique_at_work_spl",
	"urlLink": "",
	"tags": ["recovery", " fail over", " crash", "redundancy"]
}, {
	"State": "live",
	"name": "030_spl_config_at_work",
	"description": "This example introduces one of the must-learn features of the SPL language. SPL language offers an extensive list of options to do configuration at the operator level as well as at the composite level. This application attempts to sprinkle many of the available configuration parameters as shown below.a) host,b) hostColocation,c) partitionColocation,d) placement,e) threadedPort and queue,f) relocatable and many more.In addition, this example shows how to make this application toolkit dependent on another (025_dynamic_filter_at_work) SPL toolkit project.",
	"language": ["SPL"],
	"category": ["Tips", "Configuration", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/030_spl_config_at_work_my_sample3_Main_spl",
	"urlLink": "",
	"tags": ["spl config clause", "spl", "concurrency", " threading", "operator fusion", "threading", "host exlocation", "job submission", "load balancing", "host colocation", " spl config clause", "threaded port", "resource allocation", "application deployment"]
}, {
	"State": "live",
	"name": "048_source_operator_with_control_port",
	"description": "This example shows a way to create a C++ primitive source operator and then provide a control input port for it. Certain classes of applications can make use of this facility to control the kind of data a source operator generates. In addition, this example shows how to pass one or more string literals to the C++ primitive operator as invocation time parameters. As a bonus, this example also shows a simple way to do performance measurement inside the SPL code using the built-in SPL high precision timestamp functions.",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/048_source_operator_with_control_port_source_op_with_control_port_source_operator_with_control_port_spl",
	"urlLink": "",
	"tags": ["customized source operator in c++", " control port", "custom", "read a file", "filesource", "open a file", "c++ primitive operator", " custom source operator", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "055_json_to_tuple_to_json_using_c++",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished using an open source C++ JSON API. In order to run this application, you will be required to download an open source component that carries a BSD license. Please read the detailed instructions available in the SPL file for this project. There is also another SPL project that does similar conversion using Java (049_json_to_tuple_to_json_using_java).",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "ttp://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/055_json_to_tuple_to_json_using_c++_com_acme_test_json_to_tuple_to_json_using_cpp_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "parse json from c++", "jsontotuple", "c++ native function"]
}, {
	"State": "live",
	"name": "029_spl_functions_at_work",
	"description": "This example shows how helper and utility functions can be written using the SPL language. It also shows how such SPL functions can be put to use inside the context of an application. Learning this simple concept will go a long way in doing a lot of neat stuff in real-world applications.",
	"language": ["SPL"],
	"category": [" Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/029_spl_functions_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "007_split_at_work",
	"description": "This example shows how a Split operator can be used to split the incoming tuples based on a key. In this example, the split condition (which tuples comes out on which port) is pre configured through a text file. Alternatively, one can compute the index of the output port on the fly inside the Split operator parameter section.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/007_split_at_work_sample_split_at_work_spl",
	"urlLink": "",
	"tags": ["split", "split", " split stream", " divide stream"]
}, {
	"State": "live",
	"name": "028_multiple_composites_at_work",
	"description": "This example shows the use of multiple composites in a single application. There is a main composite that in turn uses two other composites. This application shows how the additional composites in different namespaces get included into the main composite via the 'use' directive. It also demonstrates how the additional composites can accept their own operator parameters. It teaches the basics of an important feature that will come handy when big applications need to be componentized. ",
	"language": ["SPL"],
	"category": ["Best Practices", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/028_multiple_composites_at_work_my_sample1_Main_spl",
	"urlLink": "",
	"tags": ["multiple composites", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "024_threaded_split_at_work",
	"description": "This example demonstrates an important standard toolkit operator named ThreadedSplit. It is a multi-threaded split that is different from the other content-based Split operator. ThreadedSplit uses its own algorithm to split the incoming tuples to the available output ports to improve concurrency. This will speed up the distribution of tuples by using individual threads assigned to each of the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "performance"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/024_threaded_split_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "split stream", "threaded split"]
}, {
	"State": "live",
	"name": "057_reading_nested_tuple_data_via_file_source",
	"description": "This example shows how to ingest nested tuple data via input files specified in a CSV format. There are certain syntactical rules that need to be followed in specifying data for nested tuples inside a CSV formatted input file. This example is a good one for developers to get an idea about how to do this.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/057_reading_nested_tuple_data_via_file_source_com_acme_test_Test1_spl",
	"urlLink": "",
	"tags": ["filesource", "parse", " nested tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "016_aggregate_at_work",
	"description": "This example shows off yet another powerful standard toolkit operator named the Aggregate. It is very good in computing on the fly aggregate values after collecting a set of tuples. Tuples are grouped based on tumbling and sliding windows with partitioned variants. This example also shows how to use the built-in assignment functions provided by this operator to compute regular statistical calculations such as min, max, average, standard deviation etc.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/016_aggregate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["aggregate", "aggregate", "rolling average", "windowing", "average", "window"]
}, {
	"State": "live",
	"name": "020_metrics_sink_at_work",
	"description": "This example shows how one can use the MetricsSink standard toolkit operator to create application-specific custom metrics that can be viewed in real-time when the application is running. Viewing of custom metrics is typically done inside Streams Explorer view of the Streams Studio or by using the capturestate option in streamtool.",
	"language": ["SPL"],
	"category": ["Monitoring", "metrics"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/020_metrics_sink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["metricssink", "metrics", "custom metrics", "application monitoring", "custom statistics"]
}, {
	"State": "live",
	"name": "002_source_sink_at_work",
	"description": "This example shows how a FileSource operator can be used to read CSV formatted records from a file and then receive those tuples in a FileSink to be written to a file in the data directory of this application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/002_source_sink_at_work_sample_source_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", " ", "filesink"]
}, {
	"State": "live",
	"name": "026_gate_at_work",
	"description": "This is an example that uses the Gate operator from the standard toolkit. This operator delays the incoming tuples until a downstream operator signals with an acknowledgment to receive any further tuples. This is a great way to have a feedback through which we can control the rate at which tuples are passed through. (Please refer to another example named 905_gate_load_balancer that shows the effectiveness of the Gate operator in combination with the ThreadedSplit operator to provide load balancing the incoming tuples.)",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/026_gate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["gate", "wait", " hold tuples until signal", "control tuple flow", "wait for tuples"]
}, {
	"State": "live",
	"name": "050_recursive_dir_scan",
	"description": "This example shows how to use the Streams C++ native function facility to recursively scan a given directory and obtain the names of the files present. The logic for the recursive directory scan polls the specified directory periodically and notifies the downstream operator with a new file that just appeared. There is a companion C++ project for this SPL project. Please refer to the RecursiveDirScanLib project for the C++ logic.Important sequence of logic for this application: 1) SPL code resolves the C++ native function in its native.function/function.xml file.2) A call from the SPL code to the native function lands in the wrapper inline C++ function defined in the RecursiveDirScanWrappers.h file of the companion C++ project.3) From that wrapper function, it gets access to a singleton C++ object of the RecursiveDirScan class and then invokes the getFileNamesInDirectory C++ method.4) When that C++ method returns, it will have the results stored in a list<string> reference that was passed to it.5) Back in the SPL code, there is additional logic to cache the already seen files and to filter only the newly found files to send to the downstream operator.In order to test this application, please refer to the commentary at the top of the SPL file in this project.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED RecursiveDirScanLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/050_recursive_dir_scan_recursive_dir_scan_recursive_dir_scan_spl",
	"urlLink": "",
	"tags": ["recursive directory scan in c++", "c++ native functions example", "c++", "application development"]
}, {
	"State": "live",
	"name": "005_throttle_at_work",
	"description": "This example shows how a stream can be throttled to flow at a specified rate. This example also mixes other operators such as Beacon, Custom, and FileSink.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/005_throttle_at_work_sample_throttle_at_work_spl",
	"urlLink": "",
	"tags": ["custom", " throttle", " slow down", "delay", " create tuple", " custom", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "004_delay_at_work",
	"description": "This example shows how a Delay standard toolkit operator can be used to delay a stream. This example also introduces the Custom operator that can be used to perform custom logic. You can also notice the use of a state variable that is mutable inside the Custom operator. It also shows how to create a new tuple on the fly and do your own submissions onto the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/004_delay_at_work_sample_delay_at_work_spl",
	"urlLink": "",
	"tags": ["custom", "delay", "filesink"]
}, {
	"State": "live",
	"name": "019_import_export_at_work",
	"description": "This example demonstrates how two different SPL applications can share streams between them. This is an important feature that is elegantly done using two pseudo operators called Export and Import. This application also shows how two different main composites can be part of the same application by using two different namespaces. As an aside, there is also a demonstration of using a Custom operator to customize the Beacon generated tuples by involving state variables. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/019_import_export_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["import", "export", "microservices", "export stream", "import stream"]
}, {
	"State": "live",
	"name": "033_java_primitive_operator_at_work",
	"description": "This example shows how a Java primitive operator is created from scratch. Java primitive operator is different from JavaOp that you have seen earlier in a different example. Java primitive operator is a first class operator in SPL, whereas JavaOp only permits a callout to another Java operator. In addition, Java primitive operator has the advantage of keeping its name as the operator\u2019s runtime instance name.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT NAMED RSS_Reader_Primitive THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/033_java_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["java operator", " primitive java operator", "java operators", " application development"]
}, {
	"State": "live",
	"name": "043_import_export_filter_at_work",
	"description": "This example shows how to use the SPL feature to apply a filter for what gets exported and what gets imported. This powerful feature lets the downstream import operators to specify what kind of tuples they want to receive by specifying conditional expressions involving tuple attributes. That lets the Streams runtime to apply content-based filtering at the point of export. Those who need such a feature to control what information should be sent downstream based on the tuple contents can make use of this flexible feature. This can be done on the fly without stopping and restarting the application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/043_import_export_filter_at_work_importing_exporting_filter_import_with_filter_spl",
	"urlLink": "",
	"tags": ["import", "export", "filtered import", "dynamic import", "microservices", "export stream", " filter imports", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "017_filesource_filesink_at_work",
	"description": "We have used the FileSource and the FileSink operators in other examples before. However, this example shows off the following intriguing features that will become handy in a lot of practical situations.a) Automatic deletion of a file after the FileSource finishes reading all the records.b) Flushing the sink file on demand after writing a certain number of tuples.c) Ability of the FileSource to move the file once it reads all the content in that file.d) Creating a fresh and new output sink file after writing a certain number of tuples.e) Ability of the FileSource to keep reading from a hot file as new CSV records get written to the end of that file.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/017_filesource_filesink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "advanced file operations", " reread file", "move file", " hot file", "flushing", " automatic deletion", "delete a file"]
}, {
	"State": "live",
	"name": "008_get_submission_time_value",
	"description": "This example shows how the tuple attributes can be assigned values that were supplied by the user at the application/job submission time. It employs the getSubmissionTimeValue function to obtain different values made of different SPL data types. ",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/008_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["functor", "getsubmissiontimevalue", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "014_sort_at_work",
	"description": "This example shows the use of the Sort operator in the context of an application. Sort operator is highly configurable with all kinds of windowing support. In this example, the following window configurations are applied for sorting the incoming tuples:a) Count-based tumbling window.b) Time-based tumbling window.c) Punctuation-based tumbling window.d) Delta-based tumbling window.e) Count-based sliding window.",
	"language": ["SPL"],
	"category": ["transform", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/014_sort_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["sort", " Time-based", " delta based", "time based", " punctuation-based Count based", "sort", " tumbling window", " sliding window", " punctuation based", " sort with windowing", " count-based"]
}, {
	"State": "live",
	"name": "027_java_op_at_work",
	"description": "This example shows an important operator that brings Java into the C++ dominated world of Streams!!! That operator is called JavaOp, which is used to call out to other operators implemented in Java using the Java Operator API. In this example, we will have a tiny Java logic that will calculate the current time and add that time string to a tuple attribute and output that tuple. There is another example that shows the Java primitive operator that is different from the JavaOp operator.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/027_java_op_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in and C++ primitive operators that are NOT fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["dps", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "dps", "c++", "share data"]
}, {
	"State": "live",
	"name": "053_java_primitive_operator_with_complex_output_tuple_types",
	"description": "This example shows important features that can be done via a Java primitive operator. It shows how to do tracing and logging inside a Java operator. It also shows how we can create an output tuple inside a Java primitive operator to have a list of tuple objects carrying complex typed attributes.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT CALLED Java_Complex_Tuple_Type_Submission THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/053_java_primitive_operator_with_complex_output_tuple_types_com_acme_test_java_primitive_operator_with_complex_output_tuple_types_spl",
	"urlLink": "",
	"tags": [" submit tuple from java", "tuple in java operator", "tuple", "complex tuple", " java operator"]
}, {
	"State": "live",
	"name": "035_c++_primitive_operator_at_work",
	"description": "This example shows the steps required to create a C++ primitive operator from scratch. In this application, a C++ primitive operator model XML file can be explored to learn how the different fields in that file are configured. Then, the code generation template header and implementation files (*_h.cgt and *_cpp.cgt) can be browsed to learn about the primitive operator logic. Additionally, this example demonstrates about including a Java operator and a C++ primitive operator as part of the application flow.",
	"language": ["C++"],
	"category": ["Operators & Functions", " Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/035_c++_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["c++ operators", "c++ example", "c++ operator model", " application development"]
}, {
	"State": "live",
	"name": "037_odbc_adapters_for_solid_db_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters for connecting to a SolidDB in-memory database. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test SolidDB database inside IBM. You have to create your own SolidDB database and tables to make this application work in your environment.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/037_odbc_adapters_for_solid_db_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "soliddb"]
}, {
	"State": "live",
	"name": "061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators that are not fused with each other and a C++ native function. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "hsa", "java", "native function", "db", "query"]
}, {
	"State": "live",
	"name": "006_barrier_at_work",
	"description": "This example shows how to synchronize the incoming tuples using a Barrier operator. It uses a bank deposit/debit scenario to split the deposit/debit requests, perform that account activity, and then combine the post-activity result with the incoming requests. Barrier operator does what is needed to accomplish that i.e. it waits for the streams to arrive at all the configured input ports before emitting an output tuple.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/006_barrier_at_work_sample_barrier_at_work_spl",
	"urlLink": "",
	"tags": ["barrier", "functor", "custom", " slow down stream", "delay", "create tuple", "slow down tuples", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "015_join_at_work",
	"description": "This example shows one of the power-packed standard toolkit operators; i.e. Join. This operator is so versatile that it is hard to do justice in explaining it thoroughly in a simple example such as this one.  This example provides coverage to the following Join operator features.a) Inner Join,b) Inner (Equi) Join,c) Left Outer Join,d) Right Outer Join,e) Full Outer Join",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/015_join_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["join", " inner join", "merge stream", "join", " join stream"]
}, {
	"State": "live",
	"name": "031_spl_mixed_mode_at_work",
	"description": "This example shows a cool SPL feature called mixed-mode support. In this, developers can mix PERL code islands inside of an SPL application. Mixed-mode enables the easy parameterization of SPL applications. This example gives a slight flavor of how a PERL code snippet inter-mixed with SPL allows us to parameterize the SPL Stream names and the number of output stream definitions for an SPL operator. ",
	"language": ["perl"],
	"category": ["Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/031_spl_mixed_mode_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["mixed mode", "spl", "mixed mode", "code generation"]
}, {
	"State": "live",
	"name": "047_streams_host_tags_at_work",
	"description": "This example shows how to create host tags for a given Streams instance and then use those host tags inside an SPL application. By using host tags, it is possible to avoid hard-coding the host names inside the SPL application code. Detailed instructions about creating and using host tags are explained in this example.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/047_streams_host_tags_at_work_host_tags_streams_host_tags_at_work_spl",
	"urlLink": "",
	"tags": ["tcpsink", "tcpsource", "host tags", "operator placement", "tcpsink", "tcpsource", "config clause", "host pools"]
}, {
	"State": "live",
	"name": "049_json_to_tuple_to_json_using_java",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished via two Java primitive operators that make use of the JSON (Java) libraries shipped as part of the Streams product. Those two Java operators are JSONToTuple and TupleToJSON.Note: Performance of the JSON<-->Tuple conversion in this example will be limited by the speed of your Java environment. If you want to get better performance, C++ code would help. There is a separate example (055_json_to_tuple_to_json_using_c++) that shows how to do this conversion using C++.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/049_json_to_tuple_to_json_using_java_sample_Main_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "json", " parse json"]
}, {
	"State": "live",
	"name": "046_launching_external_apps_in_spl",
	"description": "This example shows how to launch/execute an external application within the Streams SPL code. In this case, we defined a simple C++ native function in which we have the required C++ code to launch an external application. That C++ code uses pipes to execute a given application. This function would be useful to launch any custom script within the Streams application logic when certain application specific conditions arise.",
	"language": ["C++"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/046_launching_external_apps_in_spl_launch_external_apps_launching_external_apps_spl",
	"urlLink": "",
	"tags": ["launch an external app", " spl utility functions", "launch a program", "execute program"]
}, {
	"State": "live",
	"name": "059_dynamic_scaleout_of_streams_application",
	"description": "This example shows a particular style of writing Streams applications that can be scaled up or scaled down as the application input workload changes. It uses a familiar scenario from the Financial Services Sector, where the price calculation engines will require scaling up when the market data load increases. Code written in this example uses a pattern for starting more instances of an analytic operator to increase parallelism. New instances of such analytic operators can be started on demand without disrupting the already running application flow. As soon as the newly started operator instances are ready, application load will be promptly distributed across the existing and the newly started instances of that operator. In the same way, when the application data load is not high, some of the most recently started operator instances can be stopped to release the CPU cores for other use. This technique is one of many ways to design Streams applications that will scale up and down dynamically according to the changing input data workload.",
	"language": ["C++"],
	"category": ["Tips,Best Practices,Microservices,Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/059_dynamic_scaleout_of_streams_application_com_ibm_streams_pricing_test_DynamicScaleOut_spl",
	"urlLink": "",
	"tags": ["import", "export", "ingest"]
}, {
	"State": "live",
	"name": "009_custom_operator_using_get_submission_time_value",
	"description": "This example demonstrates how to assign tuple attributes at the time of job submission inside a custom operator. When the incoming tuples arrive at the Custom operator in this example, values entered by the user at the application startup are assigned to the tuple attributes.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/009_custom_operator_using_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["custom", "getsubmissiontimevalue", "get submission time value", " submission time", "parameter lists", " parameters", " custom", "create tuple"]
}, {
	"State": "live",
	"name": "012_filter_functor_at_work",
	"description": "This example puts the two commonly used standard toolkit operators to work. They are Filter and Functor. Filter allows you to route tuples based on conditional checks. It provides two output ports to send the matched tuples on the first output port and the unmatched tuples on the second output port. Functor operator allows us to transform the incoming tuple attributes and then to send it on many different output ports with different stream schemas.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/012_filter_functor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["functor", "filter", "filter tuples", "remove tuples"]
}, {
	"State": "live",
	"name": "022_deduplicate_at_work",
	"description": "This example describes the use of an important operator that is highly applicable in many Telco scenarios. That operator is called DeDuplicate, which eliminates duplicate tuples for a specified duration of time. It also has an optional second output port on which duplicate tuples could be sent out for additional processing.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/022_deduplicate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["deduplicate", "separate two streams", "remove duplicates", "split streams"]
}, {
	"State": "live",
	"name": "013_punctor_at_work",
	"description": "This example shows how a Punctor operator could be used in an application. Punctor operator allows us to transform the input tuples and then inject puncuation markers either before or after the output tuple as configured.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/013_punctor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["punctor", "custom logic", " generate punctuation", " punctuation"]
}, {
	"State": "live",
	"name": "036_shared_lib_primitive_operator_at_work",
	"description": "This example demonstrates two important techniques that will be commonly used in real-world use cases.1) Creating a C++ primitive operator.2) Calling a function available inside a .so shared library from the C++ primitive operator logic.Application logic here is to receive input tuples as hostnames and then make the C++ primitive operator logic invoke a shared library function that does a name server lookup.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED PrimitiveOperatorLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/036_shared_lib_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" c++", " operator dependencies", " library", "shared library", " application development"]
}, {
	"State": "live",
	"name": "003_sink_at_work",
	"description": "This example shows how FileSink and Custom sinks can be employed in applications. It also shows how a Beacon operator can be used to customize tuple attributes. In addition, it introduces the Filter operator to route the incoming tuples by inspecting their attributes using a conditional statement specified in the filter parameter. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/003_sink_at_work_sample_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "read", "files", "write"]
}, {
	"State": "live",
	"name": "023_union_at_work",
	"description": "This example demonstrates an utility operator called Union. This operator combines all the tuples from several input ports as they arrive and emits a single output stream. All the input ports must have a schema that contains attributes of the same name and type as those of the output port. The order of the attributes in the input ports need not match the order in the output port.",
	"language": ["SPL"],
	"category": ["enrich", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/023_union_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["union", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "044_streams_checkpointing_at_work",
	"description": "This example shows a key feature of Streams by which an operator's state variables can be preserved when a PE fails and gets restarted. This is done through a combination of the SPL configuration directives named 'checkpointing' and 'restartable'. Developers can protect their critical operator data by taking advantage of this built-in checkpointing feature. When you run this example, you will see data flows without any gaps or interruption, when a PE is killed manually and then gets restored automatically by the Streams runtime.",
	"language": ["SPL"],
	"category": ["performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/044_streams_checkpointing_at_work_checkpointing_example_streams_checkpointing_at_work_spl",
	"urlLink": "",
	"tags": ["checkpoint config clause", " data consistency", "automatic checkpointing", " fail over", "checkpoint"]
}, {
	"State": "live",
	"name": "001_hello_world_in_spl",
	"description": "This example is the simplest possible SPL application. It uses a Beacon operator to generate tuples that carry Hello World' messages. A custom sink operator receives the tuples from Beacon and displays it on the console.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/001_hello_world_in_spl_HelloWorld_spl",
	"urlLink": "",
	"tags": ["custom"]
}, {
	"State": "live",
	"name": "038_spl_built_in_functions_at_work",
	"description": "This is a very simple example that showcases a random collection of powerful built-in SPL functions that are available out of the box. This application demonstrates how time, math, and collection type functions can be used inside of an SPL application.",
	"language": ["SPL"],
	"category": ["Best Practices", "Collections and Data Types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/038_spl_built_in_functions_at_work_test_scratch_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "data types", " spl functions", "list", " mutable", " convert time stamp", "map", " convert timestamp", " timestamps", " utility functions"]
}, {
	"State": "live",
	"name": "056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example shows a particular implementation about how data can be shared across multiple FUSED operators using an SPL map based in-memory store. Here, we are simply showing a way to use the SPL native function facility to perform data sharing via an SPL map based in-memory store that will serve multiple SPL standard toolkit operators and C++ primitive operators. As mentioned above, this example shows data sharing between multiple operators that are fused inside a single PE (Processing Element). This technical approach is called Process Store (ps). This data sharing mechanism will NOT work between operators that are on different PEs. This example depends on the com.ibm.streamsx.ps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "db", "query"]
}, {
	"State": "live",
	"name": "034_odbc_adapters_for_db2_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test DB2 database inside IBM. You have to create your own DB2 database and tables to make this application work in your environment. After creating your own database and tables, you have to change the etc/connections.xml file in this application's directory to match your database/table names, userid, and password. You also have to make changes in the SPL code using your database information for all the three ODBC operator invocations.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/034_odbc_adapters_for_db2_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "db2"]
}, {
	"State": "live",
	"name": "051_native_functions_with_collection_types",
	"description": "This example shows an important feature of Streams. In Streams applications, it may be necessary to accept and return collection types in and out of the C++ native functions. This will require native function code that can directly deal with types such as list, map, and tuple. Streams provides C++ reflection APIs to directly deal with such collection types. In this example, developers can learn how to build native functions inside of a C++ class and then pass list, map, and tuple types to those native functions. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionsWithCollectionTypesLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/051_native_functions_with_collection_types_com_ibm_nf_test_native_functions_with_collection_types_spl",
	"urlLink": "",
	"tags": [" data types", "native functions", "collections", "list", "c++ native functions example", "c++", "map", " collections", "application development", "tuple"]
}, {
	"State": "live",
	"name": "040_ingest_data_generation_in_spl",
	"description": "This example shows how SPL provides rich features to generate synthetic data required for large scale testing. Many real-life applications in the Telco and the Retail Banking sectors consume large amounts of daily business data through CSV formatted text files. There could be huge amounts of CDR data from several telecom circles or daily transaction data for millions of accounts in a retail bank.While building and testing the SPL applications, it will become necessary to generate such ingest data files with artificial data that is close enough to be realistic. This application shows how such large amounts of data in several thousands of files can be created very quickly using the SPL standard toolkit operators as well as the SPL file IO and math random built-in functions.",
	"language": ["SPL"],
	"category": ["Collections & Data types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/040_ingest_data_generation_in_spl_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["test data generation", "data types", " test data generation", "sample data", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "025_dynamic_filter_at_work",
	"description": "This example deals with an interesting standard toolkit operator called DynamicFilter. This operator is a special version of the Filter operator that you have already seen in another example; it decides at runtime which input tuples will be passed through, based on the control input it receives. This operator is applicable in many real-life scenarios. This example also demonstrates using a second composite operator to perform a sub-task that the main composite will make use of. There is also coverage to show how the second composite can take its own operator parameters.  ",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/025_dynamic_filter_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["dynamicfilter", " reusable composite", "composite operators", " filter based on input", " dynamic filter", "filter"]
}, {
	"State": "live",
	"name": "062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators and a Java primitive operator that are not fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples. In this SPL project, you will find a Java primitive operator that exercises all the dps APIs in a very comprehensive manner. In order to get access to the dps APIs, this project's build path is added with dps-helper.jar available inside the com.ibm.streamsx.dps toolkit directory (i.e. impl/java/bin). Please read at the top of this project's SPL file and the TickerIdGenerator.java primitive operator file for an extensive commentary about how to run this example.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["java database", "database", "redis", "hsa", "java", "mongo", "db", "query"]
}, {
	"State": "live",
	"name": "063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators",
	"description": "This example shows how to create a tuple on the fly inside a Java primitive operator. In addition, this example also shows how to convert a tuple into a blob (Java byte buffer) and how to convert a blob (Java byte buffer) in to a tuple. It is an interesting concept that a Java primitive operator developer can put into use in certain situations that warrant dynamic tuple creation, tuple encoding and decoding all inside Java.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators_application_Main_spl",
	"urlLink": "",
	"tags": ["create tuple in java", "java", "blob", "blob java", "create tuple"]
}, {
	"State": "live",
	"name": "064_using_spl_composite_params",
	"description": "This example shows different ways in which parameters can be passed to SPL composites. It is very useful to pass parameters as attributes, expressions, functions, operators, and types. These different ways of passing parameters to the composites is the focus of this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/064_using_spl_composite_params_com_acme_test_CompositeParams_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "065_using_multiple_threads_in_java_operator",
	"description": "This example shows how to spawn multiple threads within a Java primitive operator and then submit tuples from within those threads concurrently.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/065_using_multiple_threads_in_java_operator_com_acme_test_JavaOpSubmitFromMultipleThreads_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "066_load_balancing_using_gate",
	"description": "As documented in the Streams Info Center for a ThreadedSplit, if the processing time of a tuple varies considerably depending on the tuple data, it may cause problems where a tuple with a long processing time may cause subsequent tuples to be backed up in the stream. This example shows how a Gate operator can be combined with the ThreadedSplit can be used to ensure load balancing.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/066_load_balancing_using_gate_com_acme_test_LoadBalancingUsingGate_spl",
	"urlLink": "",
	"tags": ["gate"]
}, {
	"State": "live",
	"name": "067_simple_java_source_operator",
	"description": "This example shows a basic source operator implemented in Java. There are specific steps required for implementing a source operator and it can be learned in this example.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/067_simple_java_source_operator_com_acme_test_Temp1_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "068_tuple_introspection_inside_java_operator",
	"description": "This example shows how a tuple can be introspected to learn about its structure and its attribute names and their types. Inside a Java operator, this example illustrates how it is possible to recursively look through a tuple to understand its composition.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/068_tuple_introspection_inside_java_operator_com_acme_test_Temp2_spl",
	"urlLink": "",
	"tags": ["parse tuple in java", "tuples", " collections", "tuples java", " java operator", "spl data types"]
}, {
	"State": "live",
	"name": "069_changing_map_value_during_iteration",
	"description": "Until the release of Streams version 3.2.1, it was not possible to modify the value of a map inside an iteration loop. This example shows a new feature available in Streams version 3.2.1 that permits the value of a map to be modified inside a for loop.",
	"language": ["SPL"],
	"category": ["Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/069_changing_map_value_during_iteration_com_acme_test_ChangeCollectionValue_spl",
	"urlLink": "",
	"tags": ["iterate over map", "iteration", "change map value", "change map"]
}, {
	"State": "live",
	"name": "070_convert_block_data_into_tuples_using_parse",
	"description": "This example shows how a block of data ingested as a blob type can be converted into individual tuples using the Parse operator.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/070_convert_block_data_into_tuples_using_parse_com_acme_test_ConvertBlockDataWithParse_spl",
	"urlLink": "",
	"tags": ["parse", "parse operator", "parse blob", " convert blob to tuple", "tuples"]
}, {
	"State": "live",
	"name": "071_java_native_functions",
	"description": "Java native functions provide a cool way to add user-defined functions in Java and then call them directly within the SPL code. This example shows how easy it is to create java native functions.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/071_java_native_functions_com_acme_test_JavaNativeFunctions_spl",
	"urlLink": "",
	"tags": ["create java native function", "java function"]
}, {
	"State": "live",
	"name": "072_using_streams_rest_apis",
	"description": "Streams provides REST APIs to query different kinds of metrics about the instances, jobs, resources during the runtime operation. It is a comprehensive set of APIs that can be used with proper security configuration. This example shows a few different REST APIs in action by invoking them within Java code.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/072_using_streams_rest_apis_com_acme_test_UsingStreamsRestApis_spl",
	"urlLink": "",
	"tags": ["get job info", "monitoring", "rest", "rest api example", "jobs"]
}, {
	"State": "live",
	"name": "073_java_operator_fusion",
	"description": "This example shows how two different Java operators one performing the Sink operation and the other performing the analytics operation can be fused to operate within a single PE.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/073_java_operator_fusion_com_acme_test_JavaFusion_spl",
	"urlLink": "",
	"tags": ["java operator fusion", " ", "fuse multiple operators"]
}, {
	"State": "live",
	"name": "074_user_defined_parallelism_01",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/074_user_defined_parallelism_01_com_acme_test_UDP1_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "075_user_defined_parallelism_02",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/075_user_defined_parallelism_02_com_acme_test_UDP2_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "076_user_defined_parallelism_03",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/076_user_defined_parallelism_03_com_acme_test_UDP3_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "077_user_defined_parallelism_04",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/077_user_defined_parallelism_04_com_acme_test_UDP4_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "078_user_defined_parallelism_05",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/078_user_defined_parallelism_05_com_acme_test_UDP5_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "079_user_defined_parallelism_06",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/079_user_defined_parallelism_06_com_acme_test_UDP6_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "080_user_defined_parallelism_07",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/080_user_defined_parallelism_07_com_acme_test_UDP7_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "081_user_defined_parallelism_08",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/081_user_defined_parallelism_08_com_acme_test_UDP8_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "083_user_defined_parallelism_10",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/083_user_defined_parallelism_10_com_acme_test_UDP10_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "084_user_defined_parallelism_11",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/084_user_defined_parallelism_11_com_acme_test_UDP11_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "085_user_defined_parallelism_12",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/085_user_defined_parallelism_12_com_acme_test_UDP12_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "086_jms_source_sink_using_activemq",
	"description": "This example shows how the JMSSource and JMSSink operators from the Streams standard toolkit can be put to use for sending messages from Streams into the Apache ActiveMQ queues and topics as well as reading messages from there into Streams.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/086_jms_source_sink_using_activemq_com_acme_test_JMSSourceSink_spl",
	"urlLink": "",
	"tags": ["jmssource", "jmssink", "activemq", "jms", "read from activemq", "messaging server", "messaging"]
}, {
	"State": "live",
	"name": "087_email_alerts_via_java_native_function",
	"description": "This example shows a way to send email alerts from an SPL application. It is done via a Java native function by using the email API available in the standard Java platform. If an SMTP server is present in the same   network where Streams servers are connected, the technique shown in this example can be put to use for sending email alerts.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/087_email_alerts_via_java_native_function_com_acme_test_EmailAlerts_spl",
	"urlLink": "",
	"tags": ["send email", "email", "send email java"]
}, {
	"State": "live",
	"name": "088_java_operator_params_and_multiple_input_output_ports",
	"description": "This example demonstrates two different features of the Java primitive operator framework. It first shows how operator parameters can be easily processed inside the Java operators via the @Parameter annotations. Then, it shows how multiple input and output ports can be accessed inside the Java operators. As a bonus, it also shows a better approach for on the fly creation of the output tuples made with complex nested types.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/088_java_operator_params_and_multiple_input_output_ports_com_acme_test_JavaOperatorParams_spl",
	"urlLink": "",
	"tags": [" complex tuple", "java operator", "java operator parameters", "java", "java operator", "multiple input ports", "create tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "089_integrating_streams_apps_with_web_apps",
	"description": "This example demonstrates one of the Streams open source toolkits (com.ibm.streamsx.inet). Using this toolkit one can integrate Streams applications with web applications. Please read the comments in the SPL file for this example project to download that toolkit, install it, and then use that toolkit inside a simple SPL application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/089_integrating_streams_apps_with_web_apps_com_acme_test_WebCalculator_spl",
	"urlLink": "",
	"tags": ["httptupleinjection", "httptupleview", "send tuples to browser", "rest", "post to streams app", "streams web app"]
}, {
	"State": "live",
	"name": "090_consistent_region_spl_01",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/090_consistent_region_spl_01_com_acme_test_ConsistentRegion1_spl",
	"urlLink": "",
	"tags": ["filesource"]
}, {
	"State": "live",
	"name": "091_consistent_region_spl_02",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a FileSource with a periodic checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/091_consistent_region_spl_02_com_acme_test_ConsistentRegion2_spl",
	"urlLink": "",
	"tags": ["beacon"]
}, {
	"State": "live",
	"name": "092_consistent_region_spl_03",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the Aggregate operators in this application is forcefully aborted inside the application multiple times to prove that application survive those multiple crashes at different times and yet will continue processing tuples normally after an automatic restart of that failed operator. In addition, during those crashes Streams will preserve the windows contents of that Aggregate operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/092_consistent_region_spl_03_com_acme_test_ConsistentRegion3_spl",
	"urlLink": "",
	"tags": ["aggregate", "consistent region window", "consistent region"]
}, {
	"State": "live",
	"name": "093_consistent_region_spl_04",
	"description": "This example demonstrates how a consistent region can be defined for two different composites acting as sources for this application. These consistent regions have a periodic checkpoint trigger. Couple of different Custom operators connected to those sources are forcefully aborted inside the application. Output streams of those operators will be combined using a Join operator. This application will ensure that the application will continue normally without losing any tuples by withstanding the random crash of those two Custom operators.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/093_consistent_region_spl_04_com_acme_test_ConsistentRegion4_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "094_consistent_region_spl_05",
	"description": "This particular example shows how only a portion of the topology will take part in the consistent region by having an autonomous section in the application graph. This example simulates the operator failure by aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Join operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration. At the same time, parts of the application that is in the autonomous area will get duplicate tuples during a crash recovery happening in the consistent region of this application graph. This example's purpose is to make the users aware of this fact. In the autonomous area, measures need to be taken to do deduplication.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/094_consistent_region_spl_05_com_acme_test_ConsistentRegion5_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "095_consistent_region_spl_06",
	"description": "This particular example shows how a non-replay capable Source operator will not be a show stopper when it comes to employing the consistent region feature in such applications. When using sources (such as TCPSource) that can't realistically replay data, there is way to configure your application with consistent region by using an utility operator called ReplaybleStart (shipped with the Streams product). In this example, we will use a topology that uses TCPSource along with ReplayableStart to achieve application-level fault tolerance.  This example simulates the operator failure by  aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Aggregate operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/095_consistent_region_spl_06_com_acme_test_ConsistentRegion6_spl",
	"urlLink": "",
	"tags": ["replayablestart", "enabling consistent regions when the source operator deos not support it", "failure", "crash", "high availability", "guaranteed processing", "replayablestart"]
}, {
	"State": "live",
	"name": "100_using_jmx_api_01",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to query information about the Streams domain and the Streams instance.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/100_using_jmx_api_01",
	"urlLink": "",
	"tags": ["jmx api", " jmx", " monitoring", "domains"]
}, {
	"State": "live",
	"name": "101_using_jmx_api_02",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to fetch the bulk contents from a log file for a given domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/101_using_jmx_api_02",
	"urlLink": "",
	"tags": ["jmx api", "monitoring", "get log file using jmx"]
}, {
	"State": "live",
	"name": "102_using_jmx_api_03",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX API notifications to get alerted via callback functions about an inactivity timeout in a given Streams domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/102_using_jmx_api_03",
	"urlLink": "",
	"tags": [" use jmx to get alerts", " monitoring", "jmx"]
}, {
	"State": "live",
	"name": "103_view_annotation_at_work",
	"description": "This is a simple SPL application that explains the steps required to use the view annotation and then how to visualize the view annotated stream in the Streams web console. Detailed steps to view the annotated stream are shown in the commentary section of this SPL file.",
	"language": ["SPL"],
	"category": ["Visualization and Reporting"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/103_view_annotation_at_work_com_acme_test_ViewAnnotationAtWork_spl",
	"urlLink": "",
	"tags": ["microsoft excel", "console", "view annotation", "views example", "reporting", "views", "visualization", "visualize", "application development"]
}, {
	"State": "live",
	"name": "901_cat_example",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/901_cat_example_NumberedCat_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "902_word_count",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/902_word_count_word_count_WordCount_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "903_unique",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/903_unique_Main_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "904_primitive_round_robin_split",
	"description": "SPL Introductory Tutorial sample",
	"language": ["C++"],
	"category": ["Beginner/General", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/904_primitive_round_robin_split_Main_spl",
	"urlLink": "",
	"tags": ["pair", "spl"]
}, {
	"State": "live",
	"name": "905_gate_load_balancer",
	"description": "SPL Introductory Tutorial sample\"",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/905_gate_load_balancer_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "gate", "improve performance", " gate operator", "threadedsplit", " threadedsplit operator", "gate"]
}
,{
	"State": "live",
	"name": "021_pair_at_work",
	"description": "This example shows off the Pair operator that is used for pairing tuples arriving on different input ports. Only when all the tuples arrive at all the input ports, this operator will emit them one after the other in their order of arrival.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/021_pair_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["pair", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "'096_consistent_region_spl_07",
	"description": "This particular example shows how a C++ primitive operator can play a role inside a consistent region.  It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/096_consistent_region_cpp_07_com_acme_test_ConsistentRegion7_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "097_consistent_region_spl_08",
	"description": "This particular example shows how a C++ primitive operator can be the start of a consistent region.   It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/097_consistent_region_cpp_08_com_acme_test_ConsistentRegion8_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "098_consistent_region_spl_09",
	"description": "This particular example shows how a Java primitive operator can be the start of a consistent region. ",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/098_consistent_region_java_09_com_acme_test_ConsistentRegion9_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "099_consistent_region_spl_10",
	"description": "This particular example shows how a Java primitive operator can play a role inside a consistent region. It demonstrates how to implement the necessary callback functions to support checkpoint and reset.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/099_consistent_region_java_10_com_acme_test_ConsistentRegion10_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "052_streams_to_python",
	"description": "This example shows a powerful feature of Streams to wrap existing code assets written using the Python programming language. This example teaches developers how to use the Streams C++ native functions to call any arbitrary Python function and return the results back to SPL code. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory. You can also read a very detailed IBM developerWorks technical article about this example:  http://tinyurl.com/c3s56fq. [THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED StreamsToPythonLib THAT IS DESCRIBED BELOW.]",
	"language": ["Python"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/052_streams_to_python_python_wrapper_example_streams_to_python_spl",
	"urlLink": "",
	"tags": ["call python from streams", "call python from cpp", " python"]
}, {
	"State": "live",
	"name": "042_dynamic_import_export_api_at_work",
	"description": "This example shows how to use the SPL APIs for dynamically importing and exporting streams. This is achieved by changing the import and export properties on the fly. This powerful feature in Streams provides a way to change the streams producing and consuming operators to change the way in which they publish and subscribe to streams while the application is running.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/042_dynamic_import_export_api_at_work_dynamic_importing_exporting_dynamic_import_spl",
	"urlLink": "",
	"tags": ["import", "export", "dynamic import", "microservices", "export stream", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "045_file_source_using_spl_custom_operator",
	"description": "This example shows how to create source operators using the Custom operator available in the SPL standard toolkit. Starting in Streams 3.x, it is possible to create source operators without writing primitive source operators in C++ or Java. Simple source operators can be written using the built-in SPL Custom operator. This will come handy for those who don't want to do an extra layer of C++ or Java code for satisfying simple needs for a source operator. You will see a function of a file source operator being implemented all using SPL code in this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions,Ingest & Store Data", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/045_file_source_using_spl_custom_operator_my_file_source_file_source_using_spl_custom_operator_spl",
	"urlLink": "",
	"tags": ["read a file using a custom", "custom", "read a file", "filesource", "open a file", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "032_native_function_at_work",
	"description": "This application shows how native functions written in C++ can be called within an SPL application.There are two ways in which native functions can be written in C++.1) Code for the C++ functions can be written in a C++ header file.2) C++ functions can be written outside of the SPL project and packaged into a shared library (.so) file. All the SPL developer will have to work with are an .so file and a C++ header file.This application demonstrates incorporating native functions built in both of those ways.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/032_native_function_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["native functions", " c++", "native functions", " native function model"]
}, {
	"State": "live",
	"name": "018_directory_scan_at_work",
	"description": "This example demonstrates one of the important features desired in the real world (mostly in the Retail banking and in the Telco industries). In many real-world scenarios, they still work via files and such files get dropped into a directory for processing. It is shown here how the DirectoryScan operator picks up a new file as soon as it appears inside an input directory. (Apply caution if huge files are copied to the watch directory. DirectoryScan may detect that big file copy as multiple new files and output multiple tuples with the same file name.)",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/018_directory_scan_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["directoryscan", "read directory repeatedly", "scan directory", "list directory"]
}, {
	"State": "live",
	"name": "011_compiler_intrinsic_functions",
	"description": "Streams compiler provides several intrinsic functions to query the SPL filename, file path, absolute path of the directory, source code line number, composite instance name etc. This example shows the use of the compiler intrinsic functions inside of a Functor operator.",
	"language": ["SPL"],
	"category": ["troubleshooting", " Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/011_compiler_intrinsic_functions_Main_spl",
	"urlLink": "",
	"tags": ["compiler functions", " utility", "print line number", " current line number", " print line number", " print file name", " get file name", " print debug info"]
}, {
	"State": "live",
	"name": "041_real_time_streams_merger",
	"description": "This example shows how two or more incoming streams with a common schema can be merged to flow in a sequence one after the other. This merger is done using a common tuple attribute in those multiple incoming streams as a key. We will use a C++ primitive operator called OrderedMerger that is included in this project. In order for the OrderedMerger to work correctly, it is assumed that multiple input streams for this primitive operator should already be in sorted order based on the key used to merge and sequence them together. ",
	"language": ["C++"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/041_real_time_streams_merger_real_time_merger_real_time_streams_merger_spl",
	"urlLink": "",
	"tags": ["ordered merge of multiple streams ", "c++ example", "merge  streams", " join streams", " c++ operator model", " application development", " ordered merge"]
}, {
	"State": "live",
	"name": "060_simple_pe_failover_technique_at_work",
	"description": "This example shows a way to protect the logic in an analytic operator  when its PE (Processing Element) or its host machine crashes. It uses a well-known fail-over technique that is done through a primary/secondary pair configured for an operator that will need safety from PE or machine crash. This example outlines a scheme for protecting the analytic logic written inside an SPL Custom operator against failures. When such failures occur, a specific fail-over technique employed here will continue the business logic without any interruption. This is done by making a secondary PE to takeover the tasks of the failed primary PE. Thus, the secondary PE does the detection of the primary PE's failure and then changes its role from a secondary PE to a new primary PE. All of this is done without losing any data during the fail-over. At the same time, the failed primary PE will be automatically restarted to do its work as a new secondary PE. This particular fail-over technique ensures that there is always a primary/secondary pair working in concert to provide high availability for a business-critical operator that is coded and configured in this manner.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/060_simple_pe_failover_technique_at_work_com_acme_failover_test_simple_pe_failover_technique_at_work_spl",
	"urlLink": "",
	"tags": ["recovery", " fail over", " crash", "redundancy"]
}, {
	"State": "live",
	"name": "030_spl_config_at_work",
	"description": "This example introduces one of the must-learn features of the SPL language. SPL language offers an extensive list of options to do configuration at the operator level as well as at the composite level. This application attempts to sprinkle many of the available configuration parameters as shown below.a) host,b) hostColocation,c) partitionColocation,d) placement,e) threadedPort and queue,f) relocatable and many more.In addition, this example shows how to make this application toolkit dependent on another (025_dynamic_filter_at_work) SPL toolkit project.",
	"language": ["SPL"],
	"category": ["Tips", "Configuration", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/030_spl_config_at_work_my_sample3_Main_spl",
	"urlLink": "",
	"tags": ["spl config clause", "spl", "concurrency", " threading", "operator fusion", "threading", "host exlocation", "job submission", "load balancing", "host colocation", " spl config clause", "threaded port", "resource allocation", "application deployment"]
}, {
	"State": "live",
	"name": "048_source_operator_with_control_port",
	"description": "This example shows a way to create a C++ primitive source operator and then provide a control input port for it. Certain classes of applications can make use of this facility to control the kind of data a source operator generates. In addition, this example shows how to pass one or more string literals to the C++ primitive operator as invocation time parameters. As a bonus, this example also shows a simple way to do performance measurement inside the SPL code using the built-in SPL high precision timestamp functions.",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/048_source_operator_with_control_port_source_op_with_control_port_source_operator_with_control_port_spl",
	"urlLink": "",
	"tags": ["customized source operator in c++", " control port", "custom", "read a file", "filesource", "open a file", "c++ primitive operator", " custom source operator", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "055_json_to_tuple_to_json_using_c++",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished using an open source C++ JSON API. In order to run this application, you will be required to download an open source component that carries a BSD license. Please read the detailed instructions available in the SPL file for this project. There is also another SPL project that does similar conversion using Java (049_json_to_tuple_to_json_using_java).",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "ttp://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/055_json_to_tuple_to_json_using_c++_com_acme_test_json_to_tuple_to_json_using_cpp_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "parse json from c++", "jsontotuple", "c++ native function"]
}, {
	"State": "live",
	"name": "029_spl_functions_at_work",
	"description": "This example shows how helper and utility functions can be written using the SPL language. It also shows how such SPL functions can be put to use inside the context of an application. Learning this simple concept will go a long way in doing a lot of neat stuff in real-world applications.",
	"language": ["SPL"],
	"category": [" Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/029_spl_functions_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "007_split_at_work",
	"description": "This example shows how a Split operator can be used to split the incoming tuples based on a key. In this example, the split condition (which tuples comes out on which port) is pre configured through a text file. Alternatively, one can compute the index of the output port on the fly inside the Split operator parameter section.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/007_split_at_work_sample_split_at_work_spl",
	"urlLink": "",
	"tags": ["split", "split", " split stream", " divide stream"]
}, {
	"State": "live",
	"name": "028_multiple_composites_at_work",
	"description": "This example shows the use of multiple composites in a single application. There is a main composite that in turn uses two other composites. This application shows how the additional composites in different namespaces get included into the main composite via the 'use' directive. It also demonstrates how the additional composites can accept their own operator parameters. It teaches the basics of an important feature that will come handy when big applications need to be componentized. ",
	"language": ["SPL"],
	"category": ["Best Practices", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/028_multiple_composites_at_work_my_sample1_Main_spl",
	"urlLink": "",
	"tags": ["multiple composites", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "024_threaded_split_at_work",
	"description": "This example demonstrates an important standard toolkit operator named ThreadedSplit. It is a multi-threaded split that is different from the other content-based Split operator. ThreadedSplit uses its own algorithm to split the incoming tuples to the available output ports to improve concurrency. This will speed up the distribution of tuples by using individual threads assigned to each of the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "performance"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/024_threaded_split_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "split stream", "threaded split"]
}, {
	"State": "live",
	"name": "057_reading_nested_tuple_data_via_file_source",
	"description": "This example shows how to ingest nested tuple data via input files specified in a CSV format. There are certain syntactical rules that need to be followed in specifying data for nested tuples inside a CSV formatted input file. This example is a good one for developers to get an idea about how to do this.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/057_reading_nested_tuple_data_via_file_source_com_acme_test_Test1_spl",
	"urlLink": "",
	"tags": ["filesource", "parse", " nested tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "016_aggregate_at_work",
	"description": "This example shows off yet another powerful standard toolkit operator named the Aggregate. It is very good in computing on the fly aggregate values after collecting a set of tuples. Tuples are grouped based on tumbling and sliding windows with partitioned variants. This example also shows how to use the built-in assignment functions provided by this operator to compute regular statistical calculations such as min, max, average, standard deviation etc.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/016_aggregate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["aggregate", "aggregate", "rolling average", "windowing", "average", "window"]
}, {
	"State": "live",
	"name": "020_metrics_sink_at_work",
	"description": "This example shows how one can use the MetricsSink standard toolkit operator to create application-specific custom metrics that can be viewed in real-time when the application is running. Viewing of custom metrics is typically done inside Streams Explorer view of the Streams Studio or by using the capturestate option in streamtool.",
	"language": ["SPL"],
	"category": ["Monitoring", "metrics"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/020_metrics_sink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["metricssink", "metrics", "custom metrics", "application monitoring", "custom statistics"]
}, {
	"State": "live",
	"name": "002_source_sink_at_work",
	"description": "This example shows how a FileSource operator can be used to read CSV formatted records from a file and then receive those tuples in a FileSink to be written to a file in the data directory of this application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/002_source_sink_at_work_sample_source_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", " ", "filesink"]
}, {
	"State": "live",
	"name": "026_gate_at_work",
	"description": "This is an example that uses the Gate operator from the standard toolkit. This operator delays the incoming tuples until a downstream operator signals with an acknowledgment to receive any further tuples. This is a great way to have a feedback through which we can control the rate at which tuples are passed through. (Please refer to another example named 905_gate_load_balancer that shows the effectiveness of the Gate operator in combination with the ThreadedSplit operator to provide load balancing the incoming tuples.)",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/026_gate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["gate", "wait", " hold tuples until signal", "control tuple flow", "wait for tuples"]
}, {
	"State": "live",
	"name": "050_recursive_dir_scan",
	"description": "This example shows how to use the Streams C++ native function facility to recursively scan a given directory and obtain the names of the files present. The logic for the recursive directory scan polls the specified directory periodically and notifies the downstream operator with a new file that just appeared. There is a companion C++ project for this SPL project. Please refer to the RecursiveDirScanLib project for the C++ logic.Important sequence of logic for this application: 1) SPL code resolves the C++ native function in its native.function/function.xml file.2) A call from the SPL code to the native function lands in the wrapper inline C++ function defined in the RecursiveDirScanWrappers.h file of the companion C++ project.3) From that wrapper function, it gets access to a singleton C++ object of the RecursiveDirScan class and then invokes the getFileNamesInDirectory C++ method.4) When that C++ method returns, it will have the results stored in a list<string> reference that was passed to it.5) Back in the SPL code, there is additional logic to cache the already seen files and to filter only the newly found files to send to the downstream operator.In order to test this application, please refer to the commentary at the top of the SPL file in this project.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED RecursiveDirScanLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/050_recursive_dir_scan_recursive_dir_scan_recursive_dir_scan_spl",
	"urlLink": "",
	"tags": ["recursive directory scan in c++", "c++ native functions example", "c++", "application development"]
}, {
	"State": "live",
	"name": "005_throttle_at_work",
	"description": "This example shows how a stream can be throttled to flow at a specified rate. This example also mixes other operators such as Beacon, Custom, and FileSink.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/005_throttle_at_work_sample_throttle_at_work_spl",
	"urlLink": "",
	"tags": ["custom", " throttle", " slow down", "delay", " create tuple", " custom", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "004_delay_at_work",
	"description": "This example shows how a Delay standard toolkit operator can be used to delay a stream. This example also introduces the Custom operator that can be used to perform custom logic. You can also notice the use of a state variable that is mutable inside the Custom operator. It also shows how to create a new tuple on the fly and do your own submissions onto the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/004_delay_at_work_sample_delay_at_work_spl",
	"urlLink": "",
	"tags": ["custom", "delay", "filesink"]
}, {
	"State": "live",
	"name": "019_import_export_at_work",
	"description": "This example demonstrates how two different SPL applications can share streams between them. This is an important feature that is elegantly done using two pseudo operators called Export and Import. This application also shows how two different main composites can be part of the same application by using two different namespaces. As an aside, there is also a demonstration of using a Custom operator to customize the Beacon generated tuples by involving state variables. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/019_import_export_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["import", "export", "microservices", "export stream", "import stream"]
}, {
	"State": "live",
	"name": "033_java_primitive_operator_at_work",
	"description": "This example shows how a Java primitive operator is created from scratch. Java primitive operator is different from JavaOp that you have seen earlier in a different example. Java primitive operator is a first class operator in SPL, whereas JavaOp only permits a callout to another Java operator. In addition, Java primitive operator has the advantage of keeping its name as the operator\u2019s runtime instance name.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT NAMED RSS_Reader_Primitive THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/033_java_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["java operator", " primitive java operator", "java operators", " application development"]
}, {
	"State": "live",
	"name": "043_import_export_filter_at_work",
	"description": "This example shows how to use the SPL feature to apply a filter for what gets exported and what gets imported. This powerful feature lets the downstream import operators to specify what kind of tuples they want to receive by specifying conditional expressions involving tuple attributes. That lets the Streams runtime to apply content-based filtering at the point of export. Those who need such a feature to control what information should be sent downstream based on the tuple contents can make use of this flexible feature. This can be done on the fly without stopping and restarting the application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/043_import_export_filter_at_work_importing_exporting_filter_import_with_filter_spl",
	"urlLink": "",
	"tags": ["import", "export", "filtered import", "dynamic import", "microservices", "export stream", " filter imports", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "017_filesource_filesink_at_work",
	"description": "We have used the FileSource and the FileSink operators in other examples before. However, this example shows off the following intriguing features that will become handy in a lot of practical situations.a) Automatic deletion of a file after the FileSource finishes reading all the records.b) Flushing the sink file on demand after writing a certain number of tuples.c) Ability of the FileSource to move the file once it reads all the content in that file.d) Creating a fresh and new output sink file after writing a certain number of tuples.e) Ability of the FileSource to keep reading from a hot file as new CSV records get written to the end of that file.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/017_filesource_filesink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "advanced file operations", " reread file", "move file", " hot file", "flushing", " automatic deletion", "delete a file"]
}, {
	"State": "live",
	"name": "008_get_submission_time_value",
	"description": "This example shows how the tuple attributes can be assigned values that were supplied by the user at the application/job submission time. It employs the getSubmissionTimeValue function to obtain different values made of different SPL data types. ",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/008_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["functor", "getsubmissiontimevalue", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "014_sort_at_work",
	"description": "This example shows the use of the Sort operator in the context of an application. Sort operator is highly configurable with all kinds of windowing support. In this example, the following window configurations are applied for sorting the incoming tuples:a) Count-based tumbling window.b) Time-based tumbling window.c) Punctuation-based tumbling window.d) Delta-based tumbling window.e) Count-based sliding window.",
	"language": ["SPL"],
	"category": ["transform", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/014_sort_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["sort", " Time-based", " delta based", "time based", " punctuation-based Count based", "sort", " tumbling window", " sliding window", " punctuation based", " sort with windowing", " count-based"]
}, {
	"State": "live",
	"name": "027_java_op_at_work",
	"description": "This example shows an important operator that brings Java into the C++ dominated world of Streams!!! That operator is called JavaOp, which is used to call out to other operators implemented in Java using the Java Operator API. In this example, we will have a tiny Java logic that will calculate the current time and add that time string to a tuple attribute and output that tuple. There is another example that shows the Java primitive operator that is different from the JavaOp operator.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/027_java_op_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in and C++ primitive operators that are NOT fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["dps", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "dps", "c++", "share data"]
}, {
	"State": "live",
	"name": "053_java_primitive_operator_with_complex_output_tuple_types",
	"description": "This example shows important features that can be done via a Java primitive operator. It shows how to do tracing and logging inside a Java operator. It also shows how we can create an output tuple inside a Java primitive operator to have a list of tuple objects carrying complex typed attributes.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT CALLED Java_Complex_Tuple_Type_Submission THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/053_java_primitive_operator_with_complex_output_tuple_types_com_acme_test_java_primitive_operator_with_complex_output_tuple_types_spl",
	"urlLink": "",
	"tags": [" submit tuple from java", "tuple in java operator", "tuple", "complex tuple", " java operator"]
}, {
	"State": "live",
	"name": "035_c++_primitive_operator_at_work",
	"description": "This example shows the steps required to create a C++ primitive operator from scratch. In this application, a C++ primitive operator model XML file can be explored to learn how the different fields in that file are configured. Then, the code generation template header and implementation files (*_h.cgt and *_cpp.cgt) can be browsed to learn about the primitive operator logic. Additionally, this example demonstrates about including a Java operator and a C++ primitive operator as part of the application flow.",
	"language": ["C++"],
	"category": ["Operators & Functions", " Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/035_c++_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["c++ operators", "c++ example", "c++ operator model", " application development"]
}, {
	"State": "live",
	"name": "037_odbc_adapters_for_solid_db_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters for connecting to a SolidDB in-memory database. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test SolidDB database inside IBM. You have to create your own SolidDB database and tables to make this application work in your environment.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/037_odbc_adapters_for_solid_db_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "soliddb"]
}, {
	"State": "live",
	"name": "061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators that are not fused with each other and a C++ native function. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "hsa", "java", "native function", "db", "query"]
}, {
	"State": "live",
	"name": "006_barrier_at_work",
	"description": "This example shows how to synchronize the incoming tuples using a Barrier operator. It uses a bank deposit/debit scenario to split the deposit/debit requests, perform that account activity, and then combine the post-activity result with the incoming requests. Barrier operator does what is needed to accomplish that i.e. it waits for the streams to arrive at all the configured input ports before emitting an output tuple.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/006_barrier_at_work_sample_barrier_at_work_spl",
	"urlLink": "",
	"tags": ["barrier", "functor", "custom", " slow down stream", "delay", "create tuple", "slow down tuples", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "015_join_at_work",
	"description": "This example shows one of the power-packed standard toolkit operators; i.e. Join. This operator is so versatile that it is hard to do justice in explaining it thoroughly in a simple example such as this one.  This example provides coverage to the following Join operator features.a) Inner Join,b) Inner (Equi) Join,c) Left Outer Join,d) Right Outer Join,e) Full Outer Join",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/015_join_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["join", " inner join", "merge stream", "join", " join stream"]
}, {
	"State": "live",
	"name": "031_spl_mixed_mode_at_work",
	"description": "This example shows a cool SPL feature called mixed-mode support. In this, developers can mix PERL code islands inside of an SPL application. Mixed-mode enables the easy parameterization of SPL applications. This example gives a slight flavor of how a PERL code snippet inter-mixed with SPL allows us to parameterize the SPL Stream names and the number of output stream definitions for an SPL operator. ",
	"language": ["perl"],
	"category": ["Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/031_spl_mixed_mode_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["mixed mode", "spl", "mixed mode", "code generation"]
}, {
	"State": "live",
	"name": "047_streams_host_tags_at_work",
	"description": "This example shows how to create host tags for a given Streams instance and then use those host tags inside an SPL application. By using host tags, it is possible to avoid hard-coding the host names inside the SPL application code. Detailed instructions about creating and using host tags are explained in this example.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/047_streams_host_tags_at_work_host_tags_streams_host_tags_at_work_spl",
	"urlLink": "",
	"tags": ["tcpsink", "tcpsource", "host tags", "operator placement", "tcpsink", "tcpsource", "config clause", "host pools"]
}, {
	"State": "live",
	"name": "049_json_to_tuple_to_json_using_java",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished via two Java primitive operators that make use of the JSON (Java) libraries shipped as part of the Streams product. Those two Java operators are JSONToTuple and TupleToJSON.Note: Performance of the JSON<-->Tuple conversion in this example will be limited by the speed of your Java environment. If you want to get better performance, C++ code would help. There is a separate example (055_json_to_tuple_to_json_using_c++) that shows how to do this conversion using C++.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/049_json_to_tuple_to_json_using_java_sample_Main_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "json", " parse json"]
}, {
	"State": "live",
	"name": "046_launching_external_apps_in_spl",
	"description": "This example shows how to launch/execute an external application within the Streams SPL code. In this case, we defined a simple C++ native function in which we have the required C++ code to launch an external application. That C++ code uses pipes to execute a given application. This function would be useful to launch any custom script within the Streams application logic when certain application specific conditions arise.",
	"language": ["C++"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/046_launching_external_apps_in_spl_launch_external_apps_launching_external_apps_spl",
	"urlLink": "",
	"tags": ["launch an external app", " spl utility functions", "launch a program", "execute program"]
}, {
	"State": "live",
	"name": "059_dynamic_scaleout_of_streams_application",
	"description": "This example shows a particular style of writing Streams applications that can be scaled up or scaled down as the application input workload changes. It uses a familiar scenario from the Financial Services Sector, where the price calculation engines will require scaling up when the market data load increases. Code written in this example uses a pattern for starting more instances of an analytic operator to increase parallelism. New instances of such analytic operators can be started on demand without disrupting the already running application flow. As soon as the newly started operator instances are ready, application load will be promptly distributed across the existing and the newly started instances of that operator. In the same way, when the application data load is not high, some of the most recently started operator instances can be stopped to release the CPU cores for other use. This technique is one of many ways to design Streams applications that will scale up and down dynamically according to the changing input data workload.",
	"language": ["C++"],
	"category": ["Tips,Best Practices,Microservices,Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/059_dynamic_scaleout_of_streams_application_com_ibm_streams_pricing_test_DynamicScaleOut_spl",
	"urlLink": "",
	"tags": ["import", "export", "ingest"]
}, {
	"State": "live",
	"name": "009_custom_operator_using_get_submission_time_value",
	"description": "This example demonstrates how to assign tuple attributes at the time of job submission inside a custom operator. When the incoming tuples arrive at the Custom operator in this example, values entered by the user at the application startup are assigned to the tuple attributes.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/009_custom_operator_using_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["custom", "getsubmissiontimevalue", "get submission time value", " submission time", "parameter lists", " parameters", " custom", "create tuple"]
}, {
	"State": "live",
	"name": "012_filter_functor_at_work",
	"description": "This example puts the two commonly used standard toolkit operators to work. They are Filter and Functor. Filter allows you to route tuples based on conditional checks. It provides two output ports to send the matched tuples on the first output port and the unmatched tuples on the second output port. Functor operator allows us to transform the incoming tuple attributes and then to send it on many different output ports with different stream schemas.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/012_filter_functor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["functor", "filter", "filter tuples", "remove tuples"]
}, {
	"State": "live",
	"name": "022_deduplicate_at_work",
	"description": "This example describes the use of an important operator that is highly applicable in many Telco scenarios. That operator is called DeDuplicate, which eliminates duplicate tuples for a specified duration of time. It also has an optional second output port on which duplicate tuples could be sent out for additional processing.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/022_deduplicate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["deduplicate", "separate two streams", "remove duplicates", "split streams"]
}, {
	"State": "live",
	"name": "013_punctor_at_work",
	"description": "This example shows how a Punctor operator could be used in an application. Punctor operator allows us to transform the input tuples and then inject puncuation markers either before or after the output tuple as configured.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/013_punctor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["punctor", "custom logic", " generate punctuation", " punctuation"]
}, {
	"State": "live",
	"name": "036_shared_lib_primitive_operator_at_work",
	"description": "This example demonstrates two important techniques that will be commonly used in real-world use cases.1) Creating a C++ primitive operator.2) Calling a function available inside a .so shared library from the C++ primitive operator logic.Application logic here is to receive input tuples as hostnames and then make the C++ primitive operator logic invoke a shared library function that does a name server lookup.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED PrimitiveOperatorLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/036_shared_lib_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" c++", " operator dependencies", " library", "shared library", " application development"]
}, {
	"State": "live",
	"name": "003_sink_at_work",
	"description": "This example shows how FileSink and Custom sinks can be employed in applications. It also shows how a Beacon operator can be used to customize tuple attributes. In addition, it introduces the Filter operator to route the incoming tuples by inspecting their attributes using a conditional statement specified in the filter parameter. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/003_sink_at_work_sample_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "read", "files", "write"]
}, {
	"State": "live",
	"name": "023_union_at_work",
	"description": "This example demonstrates an utility operator called Union. This operator combines all the tuples from several input ports as they arrive and emits a single output stream. All the input ports must have a schema that contains attributes of the same name and type as those of the output port. The order of the attributes in the input ports need not match the order in the output port.",
	"language": ["SPL"],
	"category": ["enrich", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/023_union_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["union", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "044_streams_checkpointing_at_work",
	"description": "This example shows a key feature of Streams by which an operator's state variables can be preserved when a PE fails and gets restarted. This is done through a combination of the SPL configuration directives named 'checkpointing' and 'restartable'. Developers can protect their critical operator data by taking advantage of this built-in checkpointing feature. When you run this example, you will see data flows without any gaps or interruption, when a PE is killed manually and then gets restored automatically by the Streams runtime.",
	"language": ["SPL"],
	"category": ["performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/044_streams_checkpointing_at_work_checkpointing_example_streams_checkpointing_at_work_spl",
	"urlLink": "",
	"tags": ["checkpoint config clause", " data consistency", "automatic checkpointing", " fail over", "checkpoint"]
}, {
	"State": "live",
	"name": "001_hello_world_in_spl",
	"description": "This example is the simplest possible SPL application. It uses a Beacon operator to generate tuples that carry Hello World' messages. A custom sink operator receives the tuples from Beacon and displays it on the console.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/001_hello_world_in_spl_HelloWorld_spl",
	"urlLink": "",
	"tags": ["custom"]
}, {
	"State": "live",
	"name": "038_spl_built_in_functions_at_work",
	"description": "This is a very simple example that showcases a random collection of powerful built-in SPL functions that are available out of the box. This application demonstrates how time, math, and collection type functions can be used inside of an SPL application.",
	"language": ["SPL"],
	"category": ["Best Practices", "Collections and Data Types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/038_spl_built_in_functions_at_work_test_scratch_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "data types", " spl functions", "list", " mutable", " convert time stamp", "map", " convert timestamp", " timestamps", " utility functions"]
}, {
	"State": "live",
	"name": "056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example shows a particular implementation about how data can be shared across multiple FUSED operators using an SPL map based in-memory store. Here, we are simply showing a way to use the SPL native function facility to perform data sharing via an SPL map based in-memory store that will serve multiple SPL standard toolkit operators and C++ primitive operators. As mentioned above, this example shows data sharing between multiple operators that are fused inside a single PE (Processing Element). This technical approach is called Process Store (ps). This data sharing mechanism will NOT work between operators that are on different PEs. This example depends on the com.ibm.streamsx.ps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "db", "query"]
}, {
	"State": "live",
	"name": "034_odbc_adapters_for_db2_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test DB2 database inside IBM. You have to create your own DB2 database and tables to make this application work in your environment. After creating your own database and tables, you have to change the etc/connections.xml file in this application's directory to match your database/table names, userid, and password. You also have to make changes in the SPL code using your database information for all the three ODBC operator invocations.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/034_odbc_adapters_for_db2_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "db2"]
}, {
	"State": "live",
	"name": "051_native_functions_with_collection_types",
	"description": "This example shows an important feature of Streams. In Streams applications, it may be necessary to accept and return collection types in and out of the C++ native functions. This will require native function code that can directly deal with types such as list, map, and tuple. Streams provides C++ reflection APIs to directly deal with such collection types. In this example, developers can learn how to build native functions inside of a C++ class and then pass list, map, and tuple types to those native functions. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionsWithCollectionTypesLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/051_native_functions_with_collection_types_com_ibm_nf_test_native_functions_with_collection_types_spl",
	"urlLink": "",
	"tags": [" data types", "native functions", "collections", "list", "c++ native functions example", "c++", "map", " collections", "application development", "tuple"]
}, {
	"State": "live",
	"name": "040_ingest_data_generation_in_spl",
	"description": "This example shows how SPL provides rich features to generate synthetic data required for large scale testing. Many real-life applications in the Telco and the Retail Banking sectors consume large amounts of daily business data through CSV formatted text files. There could be huge amounts of CDR data from several telecom circles or daily transaction data for millions of accounts in a retail bank.While building and testing the SPL applications, it will become necessary to generate such ingest data files with artificial data that is close enough to be realistic. This application shows how such large amounts of data in several thousands of files can be created very quickly using the SPL standard toolkit operators as well as the SPL file IO and math random built-in functions.",
	"language": ["SPL"],
	"category": ["Collections & Data types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/040_ingest_data_generation_in_spl_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["test data generation", "data types", " test data generation", "sample data", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "025_dynamic_filter_at_work",
	"description": "This example deals with an interesting standard toolkit operator called DynamicFilter. This operator is a special version of the Filter operator that you have already seen in another example; it decides at runtime which input tuples will be passed through, based on the control input it receives. This operator is applicable in many real-life scenarios. This example also demonstrates using a second composite operator to perform a sub-task that the main composite will make use of. There is also coverage to show how the second composite can take its own operator parameters.  ",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/025_dynamic_filter_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["dynamicfilter", " reusable composite", "composite operators", " filter based on input", " dynamic filter", "filter"]
}, {
	"State": "live",
	"name": "062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators and a Java primitive operator that are not fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples. In this SPL project, you will find a Java primitive operator that exercises all the dps APIs in a very comprehensive manner. In order to get access to the dps APIs, this project's build path is added with dps-helper.jar available inside the com.ibm.streamsx.dps toolkit directory (i.e. impl/java/bin). Please read at the top of this project's SPL file and the TickerIdGenerator.java primitive operator file for an extensive commentary about how to run this example.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["java database", "database", "redis", "hsa", "java", "mongo", "db", "query"]
}, {
	"State": "live",
	"name": "063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators",
	"description": "This example shows how to create a tuple on the fly inside a Java primitive operator. In addition, this example also shows how to convert a tuple into a blob (Java byte buffer) and how to convert a blob (Java byte buffer) in to a tuple. It is an interesting concept that a Java primitive operator developer can put into use in certain situations that warrant dynamic tuple creation, tuple encoding and decoding all inside Java.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators_application_Main_spl",
	"urlLink": "",
	"tags": ["create tuple in java", "java", "blob", "blob java", "create tuple"]
}, {
	"State": "live",
	"name": "064_using_spl_composite_params",
	"description": "This example shows different ways in which parameters can be passed to SPL composites. It is very useful to pass parameters as attributes, expressions, functions, operators, and types. These different ways of passing parameters to the composites is the focus of this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/064_using_spl_composite_params_com_acme_test_CompositeParams_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "065_using_multiple_threads_in_java_operator",
	"description": "This example shows how to spawn multiple threads within a Java primitive operator and then submit tuples from within those threads concurrently.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/065_using_multiple_threads_in_java_operator_com_acme_test_JavaOpSubmitFromMultipleThreads_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "066_load_balancing_using_gate",
	"description": "As documented in the Streams Info Center for a ThreadedSplit, if the processing time of a tuple varies considerably depending on the tuple data, it may cause problems where a tuple with a long processing time may cause subsequent tuples to be backed up in the stream. This example shows how a Gate operator can be combined with the ThreadedSplit can be used to ensure load balancing.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/066_load_balancing_using_gate_com_acme_test_LoadBalancingUsingGate_spl",
	"urlLink": "",
	"tags": ["gate"]
}, {
	"State": "live",
	"name": "067_simple_java_source_operator",
	"description": "This example shows a basic source operator implemented in Java. There are specific steps required for implementing a source operator and it can be learned in this example.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/067_simple_java_source_operator_com_acme_test_Temp1_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "068_tuple_introspection_inside_java_operator",
	"description": "This example shows how a tuple can be introspected to learn about its structure and its attribute names and their types. Inside a Java operator, this example illustrates how it is possible to recursively look through a tuple to understand its composition.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/068_tuple_introspection_inside_java_operator_com_acme_test_Temp2_spl",
	"urlLink": "",
	"tags": ["parse tuple in java", "tuples", " collections", "tuples java", " java operator", "spl data types"]
}, {
	"State": "live",
	"name": "069_changing_map_value_during_iteration",
	"description": "Until the release of Streams version 3.2.1, it was not possible to modify the value of a map inside an iteration loop. This example shows a new feature available in Streams version 3.2.1 that permits the value of a map to be modified inside a for loop.",
	"language": ["SPL"],
	"category": ["Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/069_changing_map_value_during_iteration_com_acme_test_ChangeCollectionValue_spl",
	"urlLink": "",
	"tags": ["iterate over map", "iteration", "change map value", "change map"]
}, {
	"State": "live",
	"name": "070_convert_block_data_into_tuples_using_parse",
	"description": "This example shows how a block of data ingested as a blob type can be converted into individual tuples using the Parse operator.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/070_convert_block_data_into_tuples_using_parse_com_acme_test_ConvertBlockDataWithParse_spl",
	"urlLink": "",
	"tags": ["parse", "parse operator", "parse blob", " convert blob to tuple", "tuples"]
}, {
	"State": "live",
	"name": "071_java_native_functions",
	"description": "Java native functions provide a cool way to add user-defined functions in Java and then call them directly within the SPL code. This example shows how easy it is to create java native functions.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/071_java_native_functions_com_acme_test_JavaNativeFunctions_spl",
	"urlLink": "",
	"tags": ["create java native function", "java function"]
}, {
	"State": "live",
	"name": "072_using_streams_rest_apis",
	"description": "Streams provides REST APIs to query different kinds of metrics about the instances, jobs, resources during the runtime operation. It is a comprehensive set of APIs that can be used with proper security configuration. This example shows a few different REST APIs in action by invoking them within Java code.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/072_using_streams_rest_apis_com_acme_test_UsingStreamsRestApis_spl",
	"urlLink": "",
	"tags": ["get job info", "monitoring", "rest", "rest api example", "jobs"]
}, {
	"State": "live",
	"name": "073_java_operator_fusion",
	"description": "This example shows how two different Java operators one performing the Sink operation and the other performing the analytics operation can be fused to operate within a single PE.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/073_java_operator_fusion_com_acme_test_JavaFusion_spl",
	"urlLink": "",
	"tags": ["java operator fusion", " ", "fuse multiple operators"]
}, {
	"State": "live",
	"name": "074_user_defined_parallelism_01",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/074_user_defined_parallelism_01_com_acme_test_UDP1_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "075_user_defined_parallelism_02",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/075_user_defined_parallelism_02_com_acme_test_UDP2_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "076_user_defined_parallelism_03",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/076_user_defined_parallelism_03_com_acme_test_UDP3_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "077_user_defined_parallelism_04",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/077_user_defined_parallelism_04_com_acme_test_UDP4_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "078_user_defined_parallelism_05",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/078_user_defined_parallelism_05_com_acme_test_UDP5_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "079_user_defined_parallelism_06",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/079_user_defined_parallelism_06_com_acme_test_UDP6_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "080_user_defined_parallelism_07",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/080_user_defined_parallelism_07_com_acme_test_UDP7_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "081_user_defined_parallelism_08",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/081_user_defined_parallelism_08_com_acme_test_UDP8_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "083_user_defined_parallelism_10",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/083_user_defined_parallelism_10_com_acme_test_UDP10_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "084_user_defined_parallelism_11",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/084_user_defined_parallelism_11_com_acme_test_UDP11_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "085_user_defined_parallelism_12",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/085_user_defined_parallelism_12_com_acme_test_UDP12_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "086_jms_source_sink_using_activemq",
	"description": "This example shows how the JMSSource and JMSSink operators from the Streams standard toolkit can be put to use for sending messages from Streams into the Apache ActiveMQ queues and topics as well as reading messages from there into Streams.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/086_jms_source_sink_using_activemq_com_acme_test_JMSSourceSink_spl",
	"urlLink": "",
	"tags": ["jmssource", "jmssink", "activemq", "jms", "read from activemq", "messaging server", "messaging"]
}, {
	"State": "live",
	"name": "087_email_alerts_via_java_native_function",
	"description": "This example shows a way to send email alerts from an SPL application. It is done via a Java native function by using the email API available in the standard Java platform. If an SMTP server is present in the same   network where Streams servers are connected, the technique shown in this example can be put to use for sending email alerts.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/087_email_alerts_via_java_native_function_com_acme_test_EmailAlerts_spl",
	"urlLink": "",
	"tags": ["send email", "email", "send email java"]
}, {
	"State": "live",
	"name": "088_java_operator_params_and_multiple_input_output_ports",
	"description": "This example demonstrates two different features of the Java primitive operator framework. It first shows how operator parameters can be easily processed inside the Java operators via the @Parameter annotations. Then, it shows how multiple input and output ports can be accessed inside the Java operators. As a bonus, it also shows a better approach for on the fly creation of the output tuples made with complex nested types.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/088_java_operator_params_and_multiple_input_output_ports_com_acme_test_JavaOperatorParams_spl",
	"urlLink": "",
	"tags": [" complex tuple", "java operator", "java operator parameters", "java", "java operator", "multiple input ports", "create tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "089_integrating_streams_apps_with_web_apps",
	"description": "This example demonstrates one of the Streams open source toolkits (com.ibm.streamsx.inet). Using this toolkit one can integrate Streams applications with web applications. Please read the comments in the SPL file for this example project to download that toolkit, install it, and then use that toolkit inside a simple SPL application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/089_integrating_streams_apps_with_web_apps_com_acme_test_WebCalculator_spl",
	"urlLink": "",
	"tags": ["httptupleinjection", "httptupleview", "send tuples to browser", "rest", "post to streams app", "streams web app"]
}, {
	"State": "live",
	"name": "090_consistent_region_spl_01",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/090_consistent_region_spl_01_com_acme_test_ConsistentRegion1_spl",
	"urlLink": "",
	"tags": ["filesource"]
}, {
	"State": "live",
	"name": "091_consistent_region_spl_02",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a FileSource with a periodic checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/091_consistent_region_spl_02_com_acme_test_ConsistentRegion2_spl",
	"urlLink": "",
	"tags": ["beacon"]
}, {
	"State": "live",
	"name": "092_consistent_region_spl_03",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the Aggregate operators in this application is forcefully aborted inside the application multiple times to prove that application survive those multiple crashes at different times and yet will continue processing tuples normally after an automatic restart of that failed operator. In addition, during those crashes Streams will preserve the windows contents of that Aggregate operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/092_consistent_region_spl_03_com_acme_test_ConsistentRegion3_spl",
	"urlLink": "",
	"tags": ["aggregate", "consistent region window", "consistent region"]
}, {
	"State": "live",
	"name": "093_consistent_region_spl_04",
	"description": "This example demonstrates how a consistent region can be defined for two different composites acting as sources for this application. These consistent regions have a periodic checkpoint trigger. Couple of different Custom operators connected to those sources are forcefully aborted inside the application. Output streams of those operators will be combined using a Join operator. This application will ensure that the application will continue normally without losing any tuples by withstanding the random crash of those two Custom operators.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/093_consistent_region_spl_04_com_acme_test_ConsistentRegion4_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "094_consistent_region_spl_05",
	"description": "This particular example shows how only a portion of the topology will take part in the consistent region by having an autonomous section in the application graph. This example simulates the operator failure by aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Join operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration. At the same time, parts of the application that is in the autonomous area will get duplicate tuples during a crash recovery happening in the consistent region of this application graph. This example's purpose is to make the users aware of this fact. In the autonomous area, measures need to be taken to do deduplication.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/094_consistent_region_spl_05_com_acme_test_ConsistentRegion5_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "095_consistent_region_spl_06",
	"description": "This particular example shows how a non-replay capable Source operator will not be a show stopper when it comes to employing the consistent region feature in such applications. When using sources (such as TCPSource) that can't realistically replay data, there is way to configure your application with consistent region by using an utility operator called ReplaybleStart (shipped with the Streams product). In this example, we will use a topology that uses TCPSource along with ReplayableStart to achieve application-level fault tolerance.  This example simulates the operator failure by  aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Aggregate operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/095_consistent_region_spl_06_com_acme_test_ConsistentRegion6_spl",
	"urlLink": "",
	"tags": ["replayablestart", "enabling consistent regions when the source operator deos not support it", "failure", "crash", "high availability", "guaranteed processing", "replayablestart"]
}, {
	"State": "live",
	"name": "100_using_jmx_api_01",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to query information about the Streams domain and the Streams instance.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/100_using_jmx_api_01",
	"urlLink": "",
	"tags": ["jmx api", " jmx", " monitoring", "domains"]
}, {
	"State": "live",
	"name": "101_using_jmx_api_02",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to fetch the bulk contents from a log file for a given domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/101_using_jmx_api_02",
	"urlLink": "",
	"tags": ["jmx api", "monitoring", "get log file using jmx"]
}, {
	"State": "live",
	"name": "102_using_jmx_api_03",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX API notifications to get alerted via callback functions about an inactivity timeout in a given Streams domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/102_using_jmx_api_03",
	"urlLink": "",
	"tags": [" use jmx to get alerts", " monitoring", "jmx"]
}, {
	"State": "live",
	"name": "103_view_annotation_at_work",
	"description": "This is a simple SPL application that explains the steps required to use the view annotation and then how to visualize the view annotated stream in the Streams web console. Detailed steps to view the annotated stream are shown in the commentary section of this SPL file.",
	"language": ["SPL"],
	"category": ["Visualization and Reporting"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/103_view_annotation_at_work_com_acme_test_ViewAnnotationAtWork_spl",
	"urlLink": "",
	"tags": ["microsoft excel", "console", "view annotation", "views example", "reporting", "views", "visualization", "visualize", "application development"]
}, {
	"State": "live",
	"name": "901_cat_example",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/901_cat_example_NumberedCat_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "902_word_count",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/902_word_count_word_count_WordCount_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "903_unique",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/903_unique_Main_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "904_primitive_round_robin_split",
	"description": "SPL Introductory Tutorial sample",
	"language": ["C++"],
	"category": ["Beginner/General", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/904_primitive_round_robin_split_Main_spl",
	"urlLink": "",
	"tags": ["pair", "spl"]
}, {
	"State": "live",
	"name": "905_gate_load_balancer",
	"description": "SPL Introductory Tutorial sample\"",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/905_gate_load_balancer_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "gate", "improve performance", " gate operator", "threadedsplit", " threadedsplit operator", "gate"]
}
,{
	"State": "live",
	"name": "021_pair_at_work",
	"description": "This example shows off the Pair operator that is used for pairing tuples arriving on different input ports. Only when all the tuples arrive at all the input ports, this operator will emit them one after the other in their order of arrival.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/021_pair_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["pair", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "'096_consistent_region_spl_07",
	"description": "This particular example shows how a C++ primitive operator can play a role inside a consistent region.  It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/096_consistent_region_cpp_07_com_acme_test_ConsistentRegion7_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "097_consistent_region_spl_08",
	"description": "This particular example shows how a C++ primitive operator can be the start of a consistent region.   It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/097_consistent_region_cpp_08_com_acme_test_ConsistentRegion8_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "098_consistent_region_spl_09",
	"description": "This particular example shows how a Java primitive operator can be the start of a consistent region. ",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/098_consistent_region_java_09_com_acme_test_ConsistentRegion9_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "099_consistent_region_spl_10",
	"description": "This particular example shows how a Java primitive operator can play a role inside a consistent region. It demonstrates how to implement the necessary callback functions to support checkpoint and reset.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/099_consistent_region_java_10_com_acme_test_ConsistentRegion10_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "052_streams_to_python",
	"description": "This example shows a powerful feature of Streams to wrap existing code assets written using the Python programming language. This example teaches developers how to use the Streams C++ native functions to call any arbitrary Python function and return the results back to SPL code. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory. You can also read a very detailed IBM developerWorks technical article about this example:  http://tinyurl.com/c3s56fq. [THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED StreamsToPythonLib THAT IS DESCRIBED BELOW.]",
	"language": ["Python"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/052_streams_to_python_python_wrapper_example_streams_to_python_spl",
	"urlLink": "",
	"tags": ["call python from streams", "call python from cpp", " python"]
}, {
	"State": "live",
	"name": "042_dynamic_import_export_api_at_work",
	"description": "This example shows how to use the SPL APIs for dynamically importing and exporting streams. This is achieved by changing the import and export properties on the fly. This powerful feature in Streams provides a way to change the streams producing and consuming operators to change the way in which they publish and subscribe to streams while the application is running.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/042_dynamic_import_export_api_at_work_dynamic_importing_exporting_dynamic_import_spl",
	"urlLink": "",
	"tags": ["import", "export", "dynamic import", "microservices", "export stream", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "045_file_source_using_spl_custom_operator",
	"description": "This example shows how to create source operators using the Custom operator available in the SPL standard toolkit. Starting in Streams 3.x, it is possible to create source operators without writing primitive source operators in C++ or Java. Simple source operators can be written using the built-in SPL Custom operator. This will come handy for those who don't want to do an extra layer of C++ or Java code for satisfying simple needs for a source operator. You will see a function of a file source operator being implemented all using SPL code in this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions,Ingest & Store Data", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/045_file_source_using_spl_custom_operator_my_file_source_file_source_using_spl_custom_operator_spl",
	"urlLink": "",
	"tags": ["read a file using a custom", "custom", "read a file", "filesource", "open a file", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "032_native_function_at_work",
	"description": "This application shows how native functions written in C++ can be called within an SPL application.There are two ways in which native functions can be written in C++.1) Code for the C++ functions can be written in a C++ header file.2) C++ functions can be written outside of the SPL project and packaged into a shared library (.so) file. All the SPL developer will have to work with are an .so file and a C++ header file.This application demonstrates incorporating native functions built in both of those ways.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/032_native_function_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["native functions", " c++", "native functions", " native function model"]
}, {
	"State": "live",
	"name": "018_directory_scan_at_work",
	"description": "This example demonstrates one of the important features desired in the real world (mostly in the Retail banking and in the Telco industries). In many real-world scenarios, they still work via files and such files get dropped into a directory for processing. It is shown here how the DirectoryScan operator picks up a new file as soon as it appears inside an input directory. (Apply caution if huge files are copied to the watch directory. DirectoryScan may detect that big file copy as multiple new files and output multiple tuples with the same file name.)",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/018_directory_scan_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["directoryscan", "read directory repeatedly", "scan directory", "list directory"]
}, {
	"State": "live",
	"name": "011_compiler_intrinsic_functions",
	"description": "Streams compiler provides several intrinsic functions to query the SPL filename, file path, absolute path of the directory, source code line number, composite instance name etc. This example shows the use of the compiler intrinsic functions inside of a Functor operator.",
	"language": ["SPL"],
	"category": ["troubleshooting", " Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/011_compiler_intrinsic_functions_Main_spl",
	"urlLink": "",
	"tags": ["compiler functions", " utility", "print line number", " current line number", " print line number", " print file name", " get file name", " print debug info"]
}, {
	"State": "live",
	"name": "041_real_time_streams_merger",
	"description": "This example shows how two or more incoming streams with a common schema can be merged to flow in a sequence one after the other. This merger is done using a common tuple attribute in those multiple incoming streams as a key. We will use a C++ primitive operator called OrderedMerger that is included in this project. In order for the OrderedMerger to work correctly, it is assumed that multiple input streams for this primitive operator should already be in sorted order based on the key used to merge and sequence them together. ",
	"language": ["C++"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/041_real_time_streams_merger_real_time_merger_real_time_streams_merger_spl",
	"urlLink": "",
	"tags": ["ordered merge of multiple streams ", "c++ example", "merge  streams", " join streams", " c++ operator model", " application development", " ordered merge"]
}, {
	"State": "live",
	"name": "060_simple_pe_failover_technique_at_work",
	"description": "This example shows a way to protect the logic in an analytic operator  when its PE (Processing Element) or its host machine crashes. It uses a well-known fail-over technique that is done through a primary/secondary pair configured for an operator that will need safety from PE or machine crash. This example outlines a scheme for protecting the analytic logic written inside an SPL Custom operator against failures. When such failures occur, a specific fail-over technique employed here will continue the business logic without any interruption. This is done by making a secondary PE to takeover the tasks of the failed primary PE. Thus, the secondary PE does the detection of the primary PE's failure and then changes its role from a secondary PE to a new primary PE. All of this is done without losing any data during the fail-over. At the same time, the failed primary PE will be automatically restarted to do its work as a new secondary PE. This particular fail-over technique ensures that there is always a primary/secondary pair working in concert to provide high availability for a business-critical operator that is coded and configured in this manner.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/060_simple_pe_failover_technique_at_work_com_acme_failover_test_simple_pe_failover_technique_at_work_spl",
	"urlLink": "",
	"tags": ["recovery", " fail over", " crash", "redundancy"]
}, {
	"State": "live",
	"name": "030_spl_config_at_work",
	"description": "This example introduces one of the must-learn features of the SPL language. SPL language offers an extensive list of options to do configuration at the operator level as well as at the composite level. This application attempts to sprinkle many of the available configuration parameters as shown below.a) host,b) hostColocation,c) partitionColocation,d) placement,e) threadedPort and queue,f) relocatable and many more.In addition, this example shows how to make this application toolkit dependent on another (025_dynamic_filter_at_work) SPL toolkit project.",
	"language": ["SPL"],
	"category": ["Tips", "Configuration", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/030_spl_config_at_work_my_sample3_Main_spl",
	"urlLink": "",
	"tags": ["spl config clause", "spl", "concurrency", " threading", "operator fusion", "threading", "host exlocation", "job submission", "load balancing", "host colocation", " spl config clause", "threaded port", "resource allocation", "application deployment"]
}, {
	"State": "live",
	"name": "048_source_operator_with_control_port",
	"description": "This example shows a way to create a C++ primitive source operator and then provide a control input port for it. Certain classes of applications can make use of this facility to control the kind of data a source operator generates. In addition, this example shows how to pass one or more string literals to the C++ primitive operator as invocation time parameters. As a bonus, this example also shows a simple way to do performance measurement inside the SPL code using the built-in SPL high precision timestamp functions.",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/048_source_operator_with_control_port_source_op_with_control_port_source_operator_with_control_port_spl",
	"urlLink": "",
	"tags": ["customized source operator in c++", " control port", "custom", "read a file", "filesource", "open a file", "c++ primitive operator", " custom source operator", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "055_json_to_tuple_to_json_using_c++",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished using an open source C++ JSON API. In order to run this application, you will be required to download an open source component that carries a BSD license. Please read the detailed instructions available in the SPL file for this project. There is also another SPL project that does similar conversion using Java (049_json_to_tuple_to_json_using_java).",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "ttp://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/055_json_to_tuple_to_json_using_c++_com_acme_test_json_to_tuple_to_json_using_cpp_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "parse json from c++", "jsontotuple", "c++ native function"]
}, {
	"State": "live",
	"name": "029_spl_functions_at_work",
	"description": "This example shows how helper and utility functions can be written using the SPL language. It also shows how such SPL functions can be put to use inside the context of an application. Learning this simple concept will go a long way in doing a lot of neat stuff in real-world applications.",
	"language": ["SPL"],
	"category": [" Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/029_spl_functions_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "007_split_at_work",
	"description": "This example shows how a Split operator can be used to split the incoming tuples based on a key. In this example, the split condition (which tuples comes out on which port) is pre configured through a text file. Alternatively, one can compute the index of the output port on the fly inside the Split operator parameter section.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/007_split_at_work_sample_split_at_work_spl",
	"urlLink": "",
	"tags": ["split", "split", " split stream", " divide stream"]
}, {
	"State": "live",
	"name": "028_multiple_composites_at_work",
	"description": "This example shows the use of multiple composites in a single application. There is a main composite that in turn uses two other composites. This application shows how the additional composites in different namespaces get included into the main composite via the 'use' directive. It also demonstrates how the additional composites can accept their own operator parameters. It teaches the basics of an important feature that will come handy when big applications need to be componentized. ",
	"language": ["SPL"],
	"category": ["Best Practices", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/028_multiple_composites_at_work_my_sample1_Main_spl",
	"urlLink": "",
	"tags": ["multiple composites", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "024_threaded_split_at_work",
	"description": "This example demonstrates an important standard toolkit operator named ThreadedSplit. It is a multi-threaded split that is different from the other content-based Split operator. ThreadedSplit uses its own algorithm to split the incoming tuples to the available output ports to improve concurrency. This will speed up the distribution of tuples by using individual threads assigned to each of the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "performance"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/024_threaded_split_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "split stream", "threaded split"]
}, {
	"State": "live",
	"name": "057_reading_nested_tuple_data_via_file_source",
	"description": "This example shows how to ingest nested tuple data via input files specified in a CSV format. There are certain syntactical rules that need to be followed in specifying data for nested tuples inside a CSV formatted input file. This example is a good one for developers to get an idea about how to do this.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/057_reading_nested_tuple_data_via_file_source_com_acme_test_Test1_spl",
	"urlLink": "",
	"tags": ["filesource", "parse", " nested tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "016_aggregate_at_work",
	"description": "This example shows off yet another powerful standard toolkit operator named the Aggregate. It is very good in computing on the fly aggregate values after collecting a set of tuples. Tuples are grouped based on tumbling and sliding windows with partitioned variants. This example also shows how to use the built-in assignment functions provided by this operator to compute regular statistical calculations such as min, max, average, standard deviation etc.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/016_aggregate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["aggregate", "aggregate", "rolling average", "windowing", "average", "window"]
}, {
	"State": "live",
	"name": "020_metrics_sink_at_work",
	"description": "This example shows how one can use the MetricsSink standard toolkit operator to create application-specific custom metrics that can be viewed in real-time when the application is running. Viewing of custom metrics is typically done inside Streams Explorer view of the Streams Studio or by using the capturestate option in streamtool.",
	"language": ["SPL"],
	"category": ["Monitoring", "metrics"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/020_metrics_sink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["metricssink", "metrics", "custom metrics", "application monitoring", "custom statistics"]
}, {
	"State": "live",
	"name": "002_source_sink_at_work",
	"description": "This example shows how a FileSource operator can be used to read CSV formatted records from a file and then receive those tuples in a FileSink to be written to a file in the data directory of this application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/002_source_sink_at_work_sample_source_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", " ", "filesink"]
}, {
	"State": "live",
	"name": "026_gate_at_work",
	"description": "This is an example that uses the Gate operator from the standard toolkit. This operator delays the incoming tuples until a downstream operator signals with an acknowledgment to receive any further tuples. This is a great way to have a feedback through which we can control the rate at which tuples are passed through. (Please refer to another example named 905_gate_load_balancer that shows the effectiveness of the Gate operator in combination with the ThreadedSplit operator to provide load balancing the incoming tuples.)",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/026_gate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["gate", "wait", " hold tuples until signal", "control tuple flow", "wait for tuples"]
}, {
	"State": "live",
	"name": "050_recursive_dir_scan",
	"description": "This example shows how to use the Streams C++ native function facility to recursively scan a given directory and obtain the names of the files present. The logic for the recursive directory scan polls the specified directory periodically and notifies the downstream operator with a new file that just appeared. There is a companion C++ project for this SPL project. Please refer to the RecursiveDirScanLib project for the C++ logic.Important sequence of logic for this application: 1) SPL code resolves the C++ native function in its native.function/function.xml file.2) A call from the SPL code to the native function lands in the wrapper inline C++ function defined in the RecursiveDirScanWrappers.h file of the companion C++ project.3) From that wrapper function, it gets access to a singleton C++ object of the RecursiveDirScan class and then invokes the getFileNamesInDirectory C++ method.4) When that C++ method returns, it will have the results stored in a list<string> reference that was passed to it.5) Back in the SPL code, there is additional logic to cache the already seen files and to filter only the newly found files to send to the downstream operator.In order to test this application, please refer to the commentary at the top of the SPL file in this project.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED RecursiveDirScanLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/050_recursive_dir_scan_recursive_dir_scan_recursive_dir_scan_spl",
	"urlLink": "",
	"tags": ["recursive directory scan in c++", "c++ native functions example", "c++", "application development"]
}, {
	"State": "live",
	"name": "005_throttle_at_work",
	"description": "This example shows how a stream can be throttled to flow at a specified rate. This example also mixes other operators such as Beacon, Custom, and FileSink.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/005_throttle_at_work_sample_throttle_at_work_spl",
	"urlLink": "",
	"tags": ["custom", " throttle", " slow down", "delay", " create tuple", " custom", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "004_delay_at_work",
	"description": "This example shows how a Delay standard toolkit operator can be used to delay a stream. This example also introduces the Custom operator that can be used to perform custom logic. You can also notice the use of a state variable that is mutable inside the Custom operator. It also shows how to create a new tuple on the fly and do your own submissions onto the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/004_delay_at_work_sample_delay_at_work_spl",
	"urlLink": "",
	"tags": ["custom", "delay", "filesink"]
}, {
	"State": "live",
	"name": "019_import_export_at_work",
	"description": "This example demonstrates how two different SPL applications can share streams between them. This is an important feature that is elegantly done using two pseudo operators called Export and Import. This application also shows how two different main composites can be part of the same application by using two different namespaces. As an aside, there is also a demonstration of using a Custom operator to customize the Beacon generated tuples by involving state variables. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/019_import_export_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["import", "export", "microservices", "export stream", "import stream"]
}, {
	"State": "live",
	"name": "033_java_primitive_operator_at_work",
	"description": "This example shows how a Java primitive operator is created from scratch. Java primitive operator is different from JavaOp that you have seen earlier in a different example. Java primitive operator is a first class operator in SPL, whereas JavaOp only permits a callout to another Java operator. In addition, Java primitive operator has the advantage of keeping its name as the operator\u2019s runtime instance name.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT NAMED RSS_Reader_Primitive THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/033_java_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["java operator", " primitive java operator", "java operators", " application development"]
}, {
	"State": "live",
	"name": "043_import_export_filter_at_work",
	"description": "This example shows how to use the SPL feature to apply a filter for what gets exported and what gets imported. This powerful feature lets the downstream import operators to specify what kind of tuples they want to receive by specifying conditional expressions involving tuple attributes. That lets the Streams runtime to apply content-based filtering at the point of export. Those who need such a feature to control what information should be sent downstream based on the tuple contents can make use of this flexible feature. This can be done on the fly without stopping and restarting the application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/043_import_export_filter_at_work_importing_exporting_filter_import_with_filter_spl",
	"urlLink": "",
	"tags": ["import", "export", "filtered import", "dynamic import", "microservices", "export stream", " filter imports", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "017_filesource_filesink_at_work",
	"description": "We have used the FileSource and the FileSink operators in other examples before. However, this example shows off the following intriguing features that will become handy in a lot of practical situations.a) Automatic deletion of a file after the FileSource finishes reading all the records.b) Flushing the sink file on demand after writing a certain number of tuples.c) Ability of the FileSource to move the file once it reads all the content in that file.d) Creating a fresh and new output sink file after writing a certain number of tuples.e) Ability of the FileSource to keep reading from a hot file as new CSV records get written to the end of that file.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/017_filesource_filesink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "advanced file operations", " reread file", "move file", " hot file", "flushing", " automatic deletion", "delete a file"]
}, {
	"State": "live",
	"name": "008_get_submission_time_value",
	"description": "This example shows how the tuple attributes can be assigned values that were supplied by the user at the application/job submission time. It employs the getSubmissionTimeValue function to obtain different values made of different SPL data types. ",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/008_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["functor", "getsubmissiontimevalue", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "014_sort_at_work",
	"description": "This example shows the use of the Sort operator in the context of an application. Sort operator is highly configurable with all kinds of windowing support. In this example, the following window configurations are applied for sorting the incoming tuples:a) Count-based tumbling window.b) Time-based tumbling window.c) Punctuation-based tumbling window.d) Delta-based tumbling window.e) Count-based sliding window.",
	"language": ["SPL"],
	"category": ["transform", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/014_sort_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["sort", " Time-based", " delta based", "time based", " punctuation-based Count based", "sort", " tumbling window", " sliding window", " punctuation based", " sort with windowing", " count-based"]
}, {
	"State": "live",
	"name": "027_java_op_at_work",
	"description": "This example shows an important operator that brings Java into the C++ dominated world of Streams!!! That operator is called JavaOp, which is used to call out to other operators implemented in Java using the Java Operator API. In this example, we will have a tiny Java logic that will calculate the current time and add that time string to a tuple attribute and output that tuple. There is another example that shows the Java primitive operator that is different from the JavaOp operator.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/027_java_op_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in and C++ primitive operators that are NOT fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["dps", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "dps", "c++", "share data"]
}, {
	"State": "live",
	"name": "053_java_primitive_operator_with_complex_output_tuple_types",
	"description": "This example shows important features that can be done via a Java primitive operator. It shows how to do tracing and logging inside a Java operator. It also shows how we can create an output tuple inside a Java primitive operator to have a list of tuple objects carrying complex typed attributes.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT CALLED Java_Complex_Tuple_Type_Submission THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/053_java_primitive_operator_with_complex_output_tuple_types_com_acme_test_java_primitive_operator_with_complex_output_tuple_types_spl",
	"urlLink": "",
	"tags": [" submit tuple from java", "tuple in java operator", "tuple", "complex tuple", " java operator"]
}, {
	"State": "live",
	"name": "035_c++_primitive_operator_at_work",
	"description": "This example shows the steps required to create a C++ primitive operator from scratch. In this application, a C++ primitive operator model XML file can be explored to learn how the different fields in that file are configured. Then, the code generation template header and implementation files (*_h.cgt and *_cpp.cgt) can be browsed to learn about the primitive operator logic. Additionally, this example demonstrates about including a Java operator and a C++ primitive operator as part of the application flow.",
	"language": ["C++"],
	"category": ["Operators & Functions", " Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/035_c++_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["c++ operators", "c++ example", "c++ operator model", " application development"]
}, {
	"State": "live",
	"name": "037_odbc_adapters_for_solid_db_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters for connecting to a SolidDB in-memory database. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test SolidDB database inside IBM. You have to create your own SolidDB database and tables to make this application work in your environment.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/037_odbc_adapters_for_solid_db_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "soliddb"]
}, {
	"State": "live",
	"name": "061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators that are not fused with each other and a C++ native function. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "hsa", "java", "native function", "db", "query"]
}, {
	"State": "live",
	"name": "006_barrier_at_work",
	"description": "This example shows how to synchronize the incoming tuples using a Barrier operator. It uses a bank deposit/debit scenario to split the deposit/debit requests, perform that account activity, and then combine the post-activity result with the incoming requests. Barrier operator does what is needed to accomplish that i.e. it waits for the streams to arrive at all the configured input ports before emitting an output tuple.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/006_barrier_at_work_sample_barrier_at_work_spl",
	"urlLink": "",
	"tags": ["barrier", "functor", "custom", " slow down stream", "delay", "create tuple", "slow down tuples", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "015_join_at_work",
	"description": "This example shows one of the power-packed standard toolkit operators; i.e. Join. This operator is so versatile that it is hard to do justice in explaining it thoroughly in a simple example such as this one.  This example provides coverage to the following Join operator features.a) Inner Join,b) Inner (Equi) Join,c) Left Outer Join,d) Right Outer Join,e) Full Outer Join",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/015_join_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["join", " inner join", "merge stream", "join", " join stream"]
}, {
	"State": "live",
	"name": "031_spl_mixed_mode_at_work",
	"description": "This example shows a cool SPL feature called mixed-mode support. In this, developers can mix PERL code islands inside of an SPL application. Mixed-mode enables the easy parameterization of SPL applications. This example gives a slight flavor of how a PERL code snippet inter-mixed with SPL allows us to parameterize the SPL Stream names and the number of output stream definitions for an SPL operator. ",
	"language": ["perl"],
	"category": ["Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/031_spl_mixed_mode_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["mixed mode", "spl", "mixed mode", "code generation"]
}, {
	"State": "live",
	"name": "047_streams_host_tags_at_work",
	"description": "This example shows how to create host tags for a given Streams instance and then use those host tags inside an SPL application. By using host tags, it is possible to avoid hard-coding the host names inside the SPL application code. Detailed instructions about creating and using host tags are explained in this example.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/047_streams_host_tags_at_work_host_tags_streams_host_tags_at_work_spl",
	"urlLink": "",
	"tags": ["tcpsink", "tcpsource", "host tags", "operator placement", "tcpsink", "tcpsource", "config clause", "host pools"]
}, {
	"State": "live",
	"name": "049_json_to_tuple_to_json_using_java",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished via two Java primitive operators that make use of the JSON (Java) libraries shipped as part of the Streams product. Those two Java operators are JSONToTuple and TupleToJSON.Note: Performance of the JSON<-->Tuple conversion in this example will be limited by the speed of your Java environment. If you want to get better performance, C++ code would help. There is a separate example (055_json_to_tuple_to_json_using_c++) that shows how to do this conversion using C++.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/049_json_to_tuple_to_json_using_java_sample_Main_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "json", " parse json"]
}, {
	"State": "live",
	"name": "046_launching_external_apps_in_spl",
	"description": "This example shows how to launch/execute an external application within the Streams SPL code. In this case, we defined a simple C++ native function in which we have the required C++ code to launch an external application. That C++ code uses pipes to execute a given application. This function would be useful to launch any custom script within the Streams application logic when certain application specific conditions arise.",
	"language": ["C++"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/046_launching_external_apps_in_spl_launch_external_apps_launching_external_apps_spl",
	"urlLink": "",
	"tags": ["launch an external app", " spl utility functions", "launch a program", "execute program"]
}, {
	"State": "live",
	"name": "059_dynamic_scaleout_of_streams_application",
	"description": "This example shows a particular style of writing Streams applications that can be scaled up or scaled down as the application input workload changes. It uses a familiar scenario from the Financial Services Sector, where the price calculation engines will require scaling up when the market data load increases. Code written in this example uses a pattern for starting more instances of an analytic operator to increase parallelism. New instances of such analytic operators can be started on demand without disrupting the already running application flow. As soon as the newly started operator instances are ready, application load will be promptly distributed across the existing and the newly started instances of that operator. In the same way, when the application data load is not high, some of the most recently started operator instances can be stopped to release the CPU cores for other use. This technique is one of many ways to design Streams applications that will scale up and down dynamically according to the changing input data workload.",
	"language": ["C++"],
	"category": ["Tips,Best Practices,Microservices,Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/059_dynamic_scaleout_of_streams_application_com_ibm_streams_pricing_test_DynamicScaleOut_spl",
	"urlLink": "",
	"tags": ["import", "export", "ingest"]
}, {
	"State": "live",
	"name": "009_custom_operator_using_get_submission_time_value",
	"description": "This example demonstrates how to assign tuple attributes at the time of job submission inside a custom operator. When the incoming tuples arrive at the Custom operator in this example, values entered by the user at the application startup are assigned to the tuple attributes.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/009_custom_operator_using_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["custom", "getsubmissiontimevalue", "get submission time value", " submission time", "parameter lists", " parameters", " custom", "create tuple"]
}, {
	"State": "live",
	"name": "012_filter_functor_at_work",
	"description": "This example puts the two commonly used standard toolkit operators to work. They are Filter and Functor. Filter allows you to route tuples based on conditional checks. It provides two output ports to send the matched tuples on the first output port and the unmatched tuples on the second output port. Functor operator allows us to transform the incoming tuple attributes and then to send it on many different output ports with different stream schemas.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/012_filter_functor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["functor", "filter", "filter tuples", "remove tuples"]
}, {
	"State": "live",
	"name": "022_deduplicate_at_work",
	"description": "This example describes the use of an important operator that is highly applicable in many Telco scenarios. That operator is called DeDuplicate, which eliminates duplicate tuples for a specified duration of time. It also has an optional second output port on which duplicate tuples could be sent out for additional processing.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/022_deduplicate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["deduplicate", "separate two streams", "remove duplicates", "split streams"]
}, {
	"State": "live",
	"name": "013_punctor_at_work",
	"description": "This example shows how a Punctor operator could be used in an application. Punctor operator allows us to transform the input tuples and then inject puncuation markers either before or after the output tuple as configured.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/013_punctor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["punctor", "custom logic", " generate punctuation", " punctuation"]
}, {
	"State": "live",
	"name": "036_shared_lib_primitive_operator_at_work",
	"description": "This example demonstrates two important techniques that will be commonly used in real-world use cases.1) Creating a C++ primitive operator.2) Calling a function available inside a .so shared library from the C++ primitive operator logic.Application logic here is to receive input tuples as hostnames and then make the C++ primitive operator logic invoke a shared library function that does a name server lookup.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED PrimitiveOperatorLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/036_shared_lib_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" c++", " operator dependencies", " library", "shared library", " application development"]
}, {
	"State": "live",
	"name": "003_sink_at_work",
	"description": "This example shows how FileSink and Custom sinks can be employed in applications. It also shows how a Beacon operator can be used to customize tuple attributes. In addition, it introduces the Filter operator to route the incoming tuples by inspecting their attributes using a conditional statement specified in the filter parameter. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/003_sink_at_work_sample_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "read", "files", "write"]
}, {
	"State": "live",
	"name": "023_union_at_work",
	"description": "This example demonstrates an utility operator called Union. This operator combines all the tuples from several input ports as they arrive and emits a single output stream. All the input ports must have a schema that contains attributes of the same name and type as those of the output port. The order of the attributes in the input ports need not match the order in the output port.",
	"language": ["SPL"],
	"category": ["enrich", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/023_union_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["union", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "044_streams_checkpointing_at_work",
	"description": "This example shows a key feature of Streams by which an operator's state variables can be preserved when a PE fails and gets restarted. This is done through a combination of the SPL configuration directives named 'checkpointing' and 'restartable'. Developers can protect their critical operator data by taking advantage of this built-in checkpointing feature. When you run this example, you will see data flows without any gaps or interruption, when a PE is killed manually and then gets restored automatically by the Streams runtime.",
	"language": ["SPL"],
	"category": ["performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/044_streams_checkpointing_at_work_checkpointing_example_streams_checkpointing_at_work_spl",
	"urlLink": "",
	"tags": ["checkpoint config clause", " data consistency", "automatic checkpointing", " fail over", "checkpoint"]
}, {
	"State": "live",
	"name": "001_hello_world_in_spl",
	"description": "This example is the simplest possible SPL application. It uses a Beacon operator to generate tuples that carry Hello World' messages. A custom sink operator receives the tuples from Beacon and displays it on the console.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/001_hello_world_in_spl_HelloWorld_spl",
	"urlLink": "",
	"tags": ["custom"]
}, {
	"State": "live",
	"name": "038_spl_built_in_functions_at_work",
	"description": "This is a very simple example that showcases a random collection of powerful built-in SPL functions that are available out of the box. This application demonstrates how time, math, and collection type functions can be used inside of an SPL application.",
	"language": ["SPL"],
	"category": ["Best Practices", "Collections and Data Types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/038_spl_built_in_functions_at_work_test_scratch_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "data types", " spl functions", "list", " mutable", " convert time stamp", "map", " convert timestamp", " timestamps", " utility functions"]
}, {
	"State": "live",
	"name": "056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example shows a particular implementation about how data can be shared across multiple FUSED operators using an SPL map based in-memory store. Here, we are simply showing a way to use the SPL native function facility to perform data sharing via an SPL map based in-memory store that will serve multiple SPL standard toolkit operators and C++ primitive operators. As mentioned above, this example shows data sharing between multiple operators that are fused inside a single PE (Processing Element). This technical approach is called Process Store (ps). This data sharing mechanism will NOT work between operators that are on different PEs. This example depends on the com.ibm.streamsx.ps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "db", "query"]
}, {
	"State": "live",
	"name": "034_odbc_adapters_for_db2_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test DB2 database inside IBM. You have to create your own DB2 database and tables to make this application work in your environment. After creating your own database and tables, you have to change the etc/connections.xml file in this application's directory to match your database/table names, userid, and password. You also have to make changes in the SPL code using your database information for all the three ODBC operator invocations.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/034_odbc_adapters_for_db2_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "db2"]
}, {
	"State": "live",
	"name": "051_native_functions_with_collection_types",
	"description": "This example shows an important feature of Streams. In Streams applications, it may be necessary to accept and return collection types in and out of the C++ native functions. This will require native function code that can directly deal with types such as list, map, and tuple. Streams provides C++ reflection APIs to directly deal with such collection types. In this example, developers can learn how to build native functions inside of a C++ class and then pass list, map, and tuple types to those native functions. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionsWithCollectionTypesLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/051_native_functions_with_collection_types_com_ibm_nf_test_native_functions_with_collection_types_spl",
	"urlLink": "",
	"tags": [" data types", "native functions", "collections", "list", "c++ native functions example", "c++", "map", " collections", "application development", "tuple"]
}, {
	"State": "live",
	"name": "040_ingest_data_generation_in_spl",
	"description": "This example shows how SPL provides rich features to generate synthetic data required for large scale testing. Many real-life applications in the Telco and the Retail Banking sectors consume large amounts of daily business data through CSV formatted text files. There could be huge amounts of CDR data from several telecom circles or daily transaction data for millions of accounts in a retail bank.While building and testing the SPL applications, it will become necessary to generate such ingest data files with artificial data that is close enough to be realistic. This application shows how such large amounts of data in several thousands of files can be created very quickly using the SPL standard toolkit operators as well as the SPL file IO and math random built-in functions.",
	"language": ["SPL"],
	"category": ["Collections & Data types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/040_ingest_data_generation_in_spl_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["test data generation", "data types", " test data generation", "sample data", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "025_dynamic_filter_at_work",
	"description": "This example deals with an interesting standard toolkit operator called DynamicFilter. This operator is a special version of the Filter operator that you have already seen in another example; it decides at runtime which input tuples will be passed through, based on the control input it receives. This operator is applicable in many real-life scenarios. This example also demonstrates using a second composite operator to perform a sub-task that the main composite will make use of. There is also coverage to show how the second composite can take its own operator parameters.  ",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/025_dynamic_filter_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["dynamicfilter", " reusable composite", "composite operators", " filter based on input", " dynamic filter", "filter"]
}, {
	"State": "live",
	"name": "062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators and a Java primitive operator that are not fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples. In this SPL project, you will find a Java primitive operator that exercises all the dps APIs in a very comprehensive manner. In order to get access to the dps APIs, this project's build path is added with dps-helper.jar available inside the com.ibm.streamsx.dps toolkit directory (i.e. impl/java/bin). Please read at the top of this project's SPL file and the TickerIdGenerator.java primitive operator file for an extensive commentary about how to run this example.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["java database", "database", "redis", "hsa", "java", "mongo", "db", "query"]
}, {
	"State": "live",
	"name": "063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators",
	"description": "This example shows how to create a tuple on the fly inside a Java primitive operator. In addition, this example also shows how to convert a tuple into a blob (Java byte buffer) and how to convert a blob (Java byte buffer) in to a tuple. It is an interesting concept that a Java primitive operator developer can put into use in certain situations that warrant dynamic tuple creation, tuple encoding and decoding all inside Java.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators_application_Main_spl",
	"urlLink": "",
	"tags": ["create tuple in java", "java", "blob", "blob java", "create tuple"]
}, {
	"State": "live",
	"name": "064_using_spl_composite_params",
	"description": "This example shows different ways in which parameters can be passed to SPL composites. It is very useful to pass parameters as attributes, expressions, functions, operators, and types. These different ways of passing parameters to the composites is the focus of this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/064_using_spl_composite_params_com_acme_test_CompositeParams_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "065_using_multiple_threads_in_java_operator",
	"description": "This example shows how to spawn multiple threads within a Java primitive operator and then submit tuples from within those threads concurrently.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/065_using_multiple_threads_in_java_operator_com_acme_test_JavaOpSubmitFromMultipleThreads_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "066_load_balancing_using_gate",
	"description": "As documented in the Streams Info Center for a ThreadedSplit, if the processing time of a tuple varies considerably depending on the tuple data, it may cause problems where a tuple with a long processing time may cause subsequent tuples to be backed up in the stream. This example shows how a Gate operator can be combined with the ThreadedSplit can be used to ensure load balancing.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/066_load_balancing_using_gate_com_acme_test_LoadBalancingUsingGate_spl",
	"urlLink": "",
	"tags": ["gate"]
}, {
	"State": "live",
	"name": "067_simple_java_source_operator",
	"description": "This example shows a basic source operator implemented in Java. There are specific steps required for implementing a source operator and it can be learned in this example.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/067_simple_java_source_operator_com_acme_test_Temp1_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "068_tuple_introspection_inside_java_operator",
	"description": "This example shows how a tuple can be introspected to learn about its structure and its attribute names and their types. Inside a Java operator, this example illustrates how it is possible to recursively look through a tuple to understand its composition.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/068_tuple_introspection_inside_java_operator_com_acme_test_Temp2_spl",
	"urlLink": "",
	"tags": ["parse tuple in java", "tuples", " collections", "tuples java", " java operator", "spl data types"]
}, {
	"State": "live",
	"name": "069_changing_map_value_during_iteration",
	"description": "Until the release of Streams version 3.2.1, it was not possible to modify the value of a map inside an iteration loop. This example shows a new feature available in Streams version 3.2.1 that permits the value of a map to be modified inside a for loop.",
	"language": ["SPL"],
	"category": ["Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/069_changing_map_value_during_iteration_com_acme_test_ChangeCollectionValue_spl",
	"urlLink": "",
	"tags": ["iterate over map", "iteration", "change map value", "change map"]
}, {
	"State": "live",
	"name": "070_convert_block_data_into_tuples_using_parse",
	"description": "This example shows how a block of data ingested as a blob type can be converted into individual tuples using the Parse operator.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/070_convert_block_data_into_tuples_using_parse_com_acme_test_ConvertBlockDataWithParse_spl",
	"urlLink": "",
	"tags": ["parse", "parse operator", "parse blob", " convert blob to tuple", "tuples"]
}, {
	"State": "live",
	"name": "071_java_native_functions",
	"description": "Java native functions provide a cool way to add user-defined functions in Java and then call them directly within the SPL code. This example shows how easy it is to create java native functions.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/071_java_native_functions_com_acme_test_JavaNativeFunctions_spl",
	"urlLink": "",
	"tags": ["create java native function", "java function"]
}, {
	"State": "live",
	"name": "072_using_streams_rest_apis",
	"description": "Streams provides REST APIs to query different kinds of metrics about the instances, jobs, resources during the runtime operation. It is a comprehensive set of APIs that can be used with proper security configuration. This example shows a few different REST APIs in action by invoking them within Java code.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/072_using_streams_rest_apis_com_acme_test_UsingStreamsRestApis_spl",
	"urlLink": "",
	"tags": ["get job info", "monitoring", "rest", "rest api example", "jobs"]
}, {
	"State": "live",
	"name": "073_java_operator_fusion",
	"description": "This example shows how two different Java operators one performing the Sink operation and the other performing the analytics operation can be fused to operate within a single PE.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/073_java_operator_fusion_com_acme_test_JavaFusion_spl",
	"urlLink": "",
	"tags": ["java operator fusion", " ", "fuse multiple operators"]
}, {
	"State": "live",
	"name": "074_user_defined_parallelism_01",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/074_user_defined_parallelism_01_com_acme_test_UDP1_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "075_user_defined_parallelism_02",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/075_user_defined_parallelism_02_com_acme_test_UDP2_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "076_user_defined_parallelism_03",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/076_user_defined_parallelism_03_com_acme_test_UDP3_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "077_user_defined_parallelism_04",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/077_user_defined_parallelism_04_com_acme_test_UDP4_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "078_user_defined_parallelism_05",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/078_user_defined_parallelism_05_com_acme_test_UDP5_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "079_user_defined_parallelism_06",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/079_user_defined_parallelism_06_com_acme_test_UDP6_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "080_user_defined_parallelism_07",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/080_user_defined_parallelism_07_com_acme_test_UDP7_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "081_user_defined_parallelism_08",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/081_user_defined_parallelism_08_com_acme_test_UDP8_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "083_user_defined_parallelism_10",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/083_user_defined_parallelism_10_com_acme_test_UDP10_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "084_user_defined_parallelism_11",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/084_user_defined_parallelism_11_com_acme_test_UDP11_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "085_user_defined_parallelism_12",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/085_user_defined_parallelism_12_com_acme_test_UDP12_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "086_jms_source_sink_using_activemq",
	"description": "This example shows how the JMSSource and JMSSink operators from the Streams standard toolkit can be put to use for sending messages from Streams into the Apache ActiveMQ queues and topics as well as reading messages from there into Streams.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/086_jms_source_sink_using_activemq_com_acme_test_JMSSourceSink_spl",
	"urlLink": "",
	"tags": ["jmssource", "jmssink", "activemq", "jms", "read from activemq", "messaging server", "messaging"]
}, {
	"State": "live",
	"name": "087_email_alerts_via_java_native_function",
	"description": "This example shows a way to send email alerts from an SPL application. It is done via a Java native function by using the email API available in the standard Java platform. If an SMTP server is present in the same   network where Streams servers are connected, the technique shown in this example can be put to use for sending email alerts.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/087_email_alerts_via_java_native_function_com_acme_test_EmailAlerts_spl",
	"urlLink": "",
	"tags": ["send email", "email", "send email java"]
}, {
	"State": "live",
	"name": "088_java_operator_params_and_multiple_input_output_ports",
	"description": "This example demonstrates two different features of the Java primitive operator framework. It first shows how operator parameters can be easily processed inside the Java operators via the @Parameter annotations. Then, it shows how multiple input and output ports can be accessed inside the Java operators. As a bonus, it also shows a better approach for on the fly creation of the output tuples made with complex nested types.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/088_java_operator_params_and_multiple_input_output_ports_com_acme_test_JavaOperatorParams_spl",
	"urlLink": "",
	"tags": [" complex tuple", "java operator", "java operator parameters", "java", "java operator", "multiple input ports", "create tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "089_integrating_streams_apps_with_web_apps",
	"description": "This example demonstrates one of the Streams open source toolkits (com.ibm.streamsx.inet). Using this toolkit one can integrate Streams applications with web applications. Please read the comments in the SPL file for this example project to download that toolkit, install it, and then use that toolkit inside a simple SPL application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/089_integrating_streams_apps_with_web_apps_com_acme_test_WebCalculator_spl",
	"urlLink": "",
	"tags": ["httptupleinjection", "httptupleview", "send tuples to browser", "rest", "post to streams app", "streams web app"]
}, {
	"State": "live",
	"name": "090_consistent_region_spl_01",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/090_consistent_region_spl_01_com_acme_test_ConsistentRegion1_spl",
	"urlLink": "",
	"tags": ["filesource"]
}, {
	"State": "live",
	"name": "091_consistent_region_spl_02",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a FileSource with a periodic checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/091_consistent_region_spl_02_com_acme_test_ConsistentRegion2_spl",
	"urlLink": "",
	"tags": ["beacon"]
}, {
	"State": "live",
	"name": "092_consistent_region_spl_03",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the Aggregate operators in this application is forcefully aborted inside the application multiple times to prove that application survive those multiple crashes at different times and yet will continue processing tuples normally after an automatic restart of that failed operator. In addition, during those crashes Streams will preserve the windows contents of that Aggregate operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/092_consistent_region_spl_03_com_acme_test_ConsistentRegion3_spl",
	"urlLink": "",
	"tags": ["aggregate", "consistent region window", "consistent region"]
}, {
	"State": "live",
	"name": "093_consistent_region_spl_04",
	"description": "This example demonstrates how a consistent region can be defined for two different composites acting as sources for this application. These consistent regions have a periodic checkpoint trigger. Couple of different Custom operators connected to those sources are forcefully aborted inside the application. Output streams of those operators will be combined using a Join operator. This application will ensure that the application will continue normally without losing any tuples by withstanding the random crash of those two Custom operators.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/093_consistent_region_spl_04_com_acme_test_ConsistentRegion4_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "094_consistent_region_spl_05",
	"description": "This particular example shows how only a portion of the topology will take part in the consistent region by having an autonomous section in the application graph. This example simulates the operator failure by aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Join operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration. At the same time, parts of the application that is in the autonomous area will get duplicate tuples during a crash recovery happening in the consistent region of this application graph. This example's purpose is to make the users aware of this fact. In the autonomous area, measures need to be taken to do deduplication.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/094_consistent_region_spl_05_com_acme_test_ConsistentRegion5_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "095_consistent_region_spl_06",
	"description": "This particular example shows how a non-replay capable Source operator will not be a show stopper when it comes to employing the consistent region feature in such applications. When using sources (such as TCPSource) that can't realistically replay data, there is way to configure your application with consistent region by using an utility operator called ReplaybleStart (shipped with the Streams product). In this example, we will use a topology that uses TCPSource along with ReplayableStart to achieve application-level fault tolerance.  This example simulates the operator failure by  aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Aggregate operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/095_consistent_region_spl_06_com_acme_test_ConsistentRegion6_spl",
	"urlLink": "",
	"tags": ["replayablestart", "enabling consistent regions when the source operator deos not support it", "failure", "crash", "high availability", "guaranteed processing", "replayablestart"]
}, {
	"State": "live",
	"name": "100_using_jmx_api_01",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to query information about the Streams domain and the Streams instance.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/100_using_jmx_api_01",
	"urlLink": "",
	"tags": ["jmx api", " jmx", " monitoring", "domains"]
}, {
	"State": "live",
	"name": "101_using_jmx_api_02",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to fetch the bulk contents from a log file for a given domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/101_using_jmx_api_02",
	"urlLink": "",
	"tags": ["jmx api", "monitoring", "get log file using jmx"]
}, {
	"State": "live",
	"name": "102_using_jmx_api_03",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX API notifications to get alerted via callback functions about an inactivity timeout in a given Streams domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/102_using_jmx_api_03",
	"urlLink": "",
	"tags": [" use jmx to get alerts", " monitoring", "jmx"]
}, {
	"State": "live",
	"name": "103_view_annotation_at_work",
	"description": "This is a simple SPL application that explains the steps required to use the view annotation and then how to visualize the view annotated stream in the Streams web console. Detailed steps to view the annotated stream are shown in the commentary section of this SPL file.",
	"language": ["SPL"],
	"category": ["Visualization and Reporting"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/103_view_annotation_at_work_com_acme_test_ViewAnnotationAtWork_spl",
	"urlLink": "",
	"tags": ["microsoft excel", "console", "view annotation", "views example", "reporting", "views", "visualization", "visualize", "application development"]
}, {
	"State": "live",
	"name": "901_cat_example",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/901_cat_example_NumberedCat_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "902_word_count",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/902_word_count_word_count_WordCount_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "903_unique",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/903_unique_Main_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "904_primitive_round_robin_split",
	"description": "SPL Introductory Tutorial sample",
	"language": ["C++"],
	"category": ["Beginner/General", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/904_primitive_round_robin_split_Main_spl",
	"urlLink": "",
	"tags": ["pair", "spl"]
}, {
	"State": "live",
	"name": "905_gate_load_balancer",
	"description": "SPL Introductory Tutorial sample\"",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/905_gate_load_balancer_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "gate", "improve performance", " gate operator", "threadedsplit", " threadedsplit operator", "gate"]
}
,{
	"State": "live",
	"name": "021_pair_at_work",
	"description": "This example shows off the Pair operator that is used for pairing tuples arriving on different input ports. Only when all the tuples arrive at all the input ports, this operator will emit them one after the other in their order of arrival.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/021_pair_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["pair", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "'096_consistent_region_spl_07",
	"description": "This particular example shows how a C++ primitive operator can play a role inside a consistent region.  It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/096_consistent_region_cpp_07_com_acme_test_ConsistentRegion7_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "097_consistent_region_spl_08",
	"description": "This particular example shows how a C++ primitive operator can be the start of a consistent region.   It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/097_consistent_region_cpp_08_com_acme_test_ConsistentRegion8_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "098_consistent_region_spl_09",
	"description": "This particular example shows how a Java primitive operator can be the start of a consistent region. ",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/098_consistent_region_java_09_com_acme_test_ConsistentRegion9_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "099_consistent_region_spl_10",
	"description": "This particular example shows how a Java primitive operator can play a role inside a consistent region. It demonstrates how to implement the necessary callback functions to support checkpoint and reset.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/099_consistent_region_java_10_com_acme_test_ConsistentRegion10_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "052_streams_to_python",
	"description": "This example shows a powerful feature of Streams to wrap existing code assets written using the Python programming language. This example teaches developers how to use the Streams C++ native functions to call any arbitrary Python function and return the results back to SPL code. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory. You can also read a very detailed IBM developerWorks technical article about this example:  http://tinyurl.com/c3s56fq. [THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED StreamsToPythonLib THAT IS DESCRIBED BELOW.]",
	"language": ["Python"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/052_streams_to_python_python_wrapper_example_streams_to_python_spl",
	"urlLink": "",
	"tags": ["call python from streams", "call python from cpp", " python"]
}, {
	"State": "live",
	"name": "042_dynamic_import_export_api_at_work",
	"description": "This example shows how to use the SPL APIs for dynamically importing and exporting streams. This is achieved by changing the import and export properties on the fly. This powerful feature in Streams provides a way to change the streams producing and consuming operators to change the way in which they publish and subscribe to streams while the application is running.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/042_dynamic_import_export_api_at_work_dynamic_importing_exporting_dynamic_import_spl",
	"urlLink": "",
	"tags": ["import", "export", "dynamic import", "microservices", "export stream", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "045_file_source_using_spl_custom_operator",
	"description": "This example shows how to create source operators using the Custom operator available in the SPL standard toolkit. Starting in Streams 3.x, it is possible to create source operators without writing primitive source operators in C++ or Java. Simple source operators can be written using the built-in SPL Custom operator. This will come handy for those who don't want to do an extra layer of C++ or Java code for satisfying simple needs for a source operator. You will see a function of a file source operator being implemented all using SPL code in this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions,Ingest & Store Data", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/045_file_source_using_spl_custom_operator_my_file_source_file_source_using_spl_custom_operator_spl",
	"urlLink": "",
	"tags": ["read a file using a custom", "custom", "read a file", "filesource", "open a file", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "032_native_function_at_work",
	"description": "This application shows how native functions written in C++ can be called within an SPL application.There are two ways in which native functions can be written in C++.1) Code for the C++ functions can be written in a C++ header file.2) C++ functions can be written outside of the SPL project and packaged into a shared library (.so) file. All the SPL developer will have to work with are an .so file and a C++ header file.This application demonstrates incorporating native functions built in both of those ways.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/032_native_function_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["native functions", " c++", "native functions", " native function model"]
}, {
	"State": "live",
	"name": "018_directory_scan_at_work",
	"description": "This example demonstrates one of the important features desired in the real world (mostly in the Retail banking and in the Telco industries). In many real-world scenarios, they still work via files and such files get dropped into a directory for processing. It is shown here how the DirectoryScan operator picks up a new file as soon as it appears inside an input directory. (Apply caution if huge files are copied to the watch directory. DirectoryScan may detect that big file copy as multiple new files and output multiple tuples with the same file name.)",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/018_directory_scan_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["directoryscan", "read directory repeatedly", "scan directory", "list directory"]
}, {
	"State": "live",
	"name": "011_compiler_intrinsic_functions",
	"description": "Streams compiler provides several intrinsic functions to query the SPL filename, file path, absolute path of the directory, source code line number, composite instance name etc. This example shows the use of the compiler intrinsic functions inside of a Functor operator.",
	"language": ["SPL"],
	"category": ["troubleshooting", " Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/011_compiler_intrinsic_functions_Main_spl",
	"urlLink": "",
	"tags": ["compiler functions", " utility", "print line number", " current line number", " print line number", " print file name", " get file name", " print debug info"]
}, {
	"State": "live",
	"name": "041_real_time_streams_merger",
	"description": "This example shows how two or more incoming streams with a common schema can be merged to flow in a sequence one after the other. This merger is done using a common tuple attribute in those multiple incoming streams as a key. We will use a C++ primitive operator called OrderedMerger that is included in this project. In order for the OrderedMerger to work correctly, it is assumed that multiple input streams for this primitive operator should already be in sorted order based on the key used to merge and sequence them together. ",
	"language": ["C++"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/041_real_time_streams_merger_real_time_merger_real_time_streams_merger_spl",
	"urlLink": "",
	"tags": ["ordered merge of multiple streams ", "c++ example", "merge  streams", " join streams", " c++ operator model", " application development", " ordered merge"]
}, {
	"State": "live",
	"name": "060_simple_pe_failover_technique_at_work",
	"description": "This example shows a way to protect the logic in an analytic operator  when its PE (Processing Element) or its host machine crashes. It uses a well-known fail-over technique that is done through a primary/secondary pair configured for an operator that will need safety from PE or machine crash. This example outlines a scheme for protecting the analytic logic written inside an SPL Custom operator against failures. When such failures occur, a specific fail-over technique employed here will continue the business logic without any interruption. This is done by making a secondary PE to takeover the tasks of the failed primary PE. Thus, the secondary PE does the detection of the primary PE's failure and then changes its role from a secondary PE to a new primary PE. All of this is done without losing any data during the fail-over. At the same time, the failed primary PE will be automatically restarted to do its work as a new secondary PE. This particular fail-over technique ensures that there is always a primary/secondary pair working in concert to provide high availability for a business-critical operator that is coded and configured in this manner.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/060_simple_pe_failover_technique_at_work_com_acme_failover_test_simple_pe_failover_technique_at_work_spl",
	"urlLink": "",
	"tags": ["recovery", " fail over", " crash", "redundancy"]
}, {
	"State": "live",
	"name": "030_spl_config_at_work",
	"description": "This example introduces one of the must-learn features of the SPL language. SPL language offers an extensive list of options to do configuration at the operator level as well as at the composite level. This application attempts to sprinkle many of the available configuration parameters as shown below.a) host,b) hostColocation,c) partitionColocation,d) placement,e) threadedPort and queue,f) relocatable and many more.In addition, this example shows how to make this application toolkit dependent on another (025_dynamic_filter_at_work) SPL toolkit project.",
	"language": ["SPL"],
	"category": ["Tips", "Configuration", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/030_spl_config_at_work_my_sample3_Main_spl",
	"urlLink": "",
	"tags": ["spl config clause", "spl", "concurrency", " threading", "operator fusion", "threading", "host exlocation", "job submission", "load balancing", "host colocation", " spl config clause", "threaded port", "resource allocation", "application deployment"]
}, {
	"State": "live",
	"name": "048_source_operator_with_control_port",
	"description": "This example shows a way to create a C++ primitive source operator and then provide a control input port for it. Certain classes of applications can make use of this facility to control the kind of data a source operator generates. In addition, this example shows how to pass one or more string literals to the C++ primitive operator as invocation time parameters. As a bonus, this example also shows a simple way to do performance measurement inside the SPL code using the built-in SPL high precision timestamp functions.",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/048_source_operator_with_control_port_source_op_with_control_port_source_operator_with_control_port_spl",
	"urlLink": "",
	"tags": ["customized source operator in c++", " control port", "custom", "read a file", "filesource", "open a file", "c++ primitive operator", " custom source operator", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "055_json_to_tuple_to_json_using_c++",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished using an open source C++ JSON API. In order to run this application, you will be required to download an open source component that carries a BSD license. Please read the detailed instructions available in the SPL file for this project. There is also another SPL project that does similar conversion using Java (049_json_to_tuple_to_json_using_java).",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "ttp://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/055_json_to_tuple_to_json_using_c++_com_acme_test_json_to_tuple_to_json_using_cpp_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "parse json from c++", "jsontotuple", "c++ native function"]
}, {
	"State": "live",
	"name": "029_spl_functions_at_work",
	"description": "This example shows how helper and utility functions can be written using the SPL language. It also shows how such SPL functions can be put to use inside the context of an application. Learning this simple concept will go a long way in doing a lot of neat stuff in real-world applications.",
	"language": ["SPL"],
	"category": [" Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/029_spl_functions_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "007_split_at_work",
	"description": "This example shows how a Split operator can be used to split the incoming tuples based on a key. In this example, the split condition (which tuples comes out on which port) is pre configured through a text file. Alternatively, one can compute the index of the output port on the fly inside the Split operator parameter section.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/007_split_at_work_sample_split_at_work_spl",
	"urlLink": "",
	"tags": ["split", "split", " split stream", " divide stream"]
}, {
	"State": "live",
	"name": "028_multiple_composites_at_work",
	"description": "This example shows the use of multiple composites in a single application. There is a main composite that in turn uses two other composites. This application shows how the additional composites in different namespaces get included into the main composite via the 'use' directive. It also demonstrates how the additional composites can accept their own operator parameters. It teaches the basics of an important feature that will come handy when big applications need to be componentized. ",
	"language": ["SPL"],
	"category": ["Best Practices", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/028_multiple_composites_at_work_my_sample1_Main_spl",
	"urlLink": "",
	"tags": ["multiple composites", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "024_threaded_split_at_work",
	"description": "This example demonstrates an important standard toolkit operator named ThreadedSplit. It is a multi-threaded split that is different from the other content-based Split operator. ThreadedSplit uses its own algorithm to split the incoming tuples to the available output ports to improve concurrency. This will speed up the distribution of tuples by using individual threads assigned to each of the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "performance"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/024_threaded_split_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "split stream", "threaded split"]
}, {
	"State": "live",
	"name": "057_reading_nested_tuple_data_via_file_source",
	"description": "This example shows how to ingest nested tuple data via input files specified in a CSV format. There are certain syntactical rules that need to be followed in specifying data for nested tuples inside a CSV formatted input file. This example is a good one for developers to get an idea about how to do this.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/057_reading_nested_tuple_data_via_file_source_com_acme_test_Test1_spl",
	"urlLink": "",
	"tags": ["filesource", "parse", " nested tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "016_aggregate_at_work",
	"description": "This example shows off yet another powerful standard toolkit operator named the Aggregate. It is very good in computing on the fly aggregate values after collecting a set of tuples. Tuples are grouped based on tumbling and sliding windows with partitioned variants. This example also shows how to use the built-in assignment functions provided by this operator to compute regular statistical calculations such as min, max, average, standard deviation etc.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/016_aggregate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["aggregate", "aggregate", "rolling average", "windowing", "average", "window"]
}, {
	"State": "live",
	"name": "020_metrics_sink_at_work",
	"description": "This example shows how one can use the MetricsSink standard toolkit operator to create application-specific custom metrics that can be viewed in real-time when the application is running. Viewing of custom metrics is typically done inside Streams Explorer view of the Streams Studio or by using the capturestate option in streamtool.",
	"language": ["SPL"],
	"category": ["Monitoring", "metrics"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/020_metrics_sink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["metricssink", "metrics", "custom metrics", "application monitoring", "custom statistics"]
}, {
	"State": "live",
	"name": "002_source_sink_at_work",
	"description": "This example shows how a FileSource operator can be used to read CSV formatted records from a file and then receive those tuples in a FileSink to be written to a file in the data directory of this application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/002_source_sink_at_work_sample_source_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", " ", "filesink"]
}, {
	"State": "live",
	"name": "026_gate_at_work",
	"description": "This is an example that uses the Gate operator from the standard toolkit. This operator delays the incoming tuples until a downstream operator signals with an acknowledgment to receive any further tuples. This is a great way to have a feedback through which we can control the rate at which tuples are passed through. (Please refer to another example named 905_gate_load_balancer that shows the effectiveness of the Gate operator in combination with the ThreadedSplit operator to provide load balancing the incoming tuples.)",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/026_gate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["gate", "wait", " hold tuples until signal", "control tuple flow", "wait for tuples"]
}, {
	"State": "live",
	"name": "050_recursive_dir_scan",
	"description": "This example shows how to use the Streams C++ native function facility to recursively scan a given directory and obtain the names of the files present. The logic for the recursive directory scan polls the specified directory periodically and notifies the downstream operator with a new file that just appeared. There is a companion C++ project for this SPL project. Please refer to the RecursiveDirScanLib project for the C++ logic.Important sequence of logic for this application: 1) SPL code resolves the C++ native function in its native.function/function.xml file.2) A call from the SPL code to the native function lands in the wrapper inline C++ function defined in the RecursiveDirScanWrappers.h file of the companion C++ project.3) From that wrapper function, it gets access to a singleton C++ object of the RecursiveDirScan class and then invokes the getFileNamesInDirectory C++ method.4) When that C++ method returns, it will have the results stored in a list<string> reference that was passed to it.5) Back in the SPL code, there is additional logic to cache the already seen files and to filter only the newly found files to send to the downstream operator.In order to test this application, please refer to the commentary at the top of the SPL file in this project.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED RecursiveDirScanLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/050_recursive_dir_scan_recursive_dir_scan_recursive_dir_scan_spl",
	"urlLink": "",
	"tags": ["recursive directory scan in c++", "c++ native functions example", "c++", "application development"]
}, {
	"State": "live",
	"name": "005_throttle_at_work",
	"description": "This example shows how a stream can be throttled to flow at a specified rate. This example also mixes other operators such as Beacon, Custom, and FileSink.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/005_throttle_at_work_sample_throttle_at_work_spl",
	"urlLink": "",
	"tags": ["custom", " throttle", " slow down", "delay", " create tuple", " custom", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "004_delay_at_work",
	"description": "This example shows how a Delay standard toolkit operator can be used to delay a stream. This example also introduces the Custom operator that can be used to perform custom logic. You can also notice the use of a state variable that is mutable inside the Custom operator. It also shows how to create a new tuple on the fly and do your own submissions onto the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/004_delay_at_work_sample_delay_at_work_spl",
	"urlLink": "",
	"tags": ["custom", "delay", "filesink"]
}, {
	"State": "live",
	"name": "019_import_export_at_work",
	"description": "This example demonstrates how two different SPL applications can share streams between them. This is an important feature that is elegantly done using two pseudo operators called Export and Import. This application also shows how two different main composites can be part of the same application by using two different namespaces. As an aside, there is also a demonstration of using a Custom operator to customize the Beacon generated tuples by involving state variables. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/019_import_export_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["import", "export", "microservices", "export stream", "import stream"]
}, {
	"State": "live",
	"name": "033_java_primitive_operator_at_work",
	"description": "This example shows how a Java primitive operator is created from scratch. Java primitive operator is different from JavaOp that you have seen earlier in a different example. Java primitive operator is a first class operator in SPL, whereas JavaOp only permits a callout to another Java operator. In addition, Java primitive operator has the advantage of keeping its name as the operator\u2019s runtime instance name.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT NAMED RSS_Reader_Primitive THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/033_java_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["java operator", " primitive java operator", "java operators", " application development"]
}, {
	"State": "live",
	"name": "043_import_export_filter_at_work",
	"description": "This example shows how to use the SPL feature to apply a filter for what gets exported and what gets imported. This powerful feature lets the downstream import operators to specify what kind of tuples they want to receive by specifying conditional expressions involving tuple attributes. That lets the Streams runtime to apply content-based filtering at the point of export. Those who need such a feature to control what information should be sent downstream based on the tuple contents can make use of this flexible feature. This can be done on the fly without stopping and restarting the application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/043_import_export_filter_at_work_importing_exporting_filter_import_with_filter_spl",
	"urlLink": "",
	"tags": ["import", "export", "filtered import", "dynamic import", "microservices", "export stream", " filter imports", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "017_filesource_filesink_at_work",
	"description": "We have used the FileSource and the FileSink operators in other examples before. However, this example shows off the following intriguing features that will become handy in a lot of practical situations.a) Automatic deletion of a file after the FileSource finishes reading all the records.b) Flushing the sink file on demand after writing a certain number of tuples.c) Ability of the FileSource to move the file once it reads all the content in that file.d) Creating a fresh and new output sink file after writing a certain number of tuples.e) Ability of the FileSource to keep reading from a hot file as new CSV records get written to the end of that file.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/017_filesource_filesink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "advanced file operations", " reread file", "move file", " hot file", "flushing", " automatic deletion", "delete a file"]
}, {
	"State": "live",
	"name": "008_get_submission_time_value",
	"description": "This example shows how the tuple attributes can be assigned values that were supplied by the user at the application/job submission time. It employs the getSubmissionTimeValue function to obtain different values made of different SPL data types. ",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/008_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["functor", "getsubmissiontimevalue", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "014_sort_at_work",
	"description": "This example shows the use of the Sort operator in the context of an application. Sort operator is highly configurable with all kinds of windowing support. In this example, the following window configurations are applied for sorting the incoming tuples:a) Count-based tumbling window.b) Time-based tumbling window.c) Punctuation-based tumbling window.d) Delta-based tumbling window.e) Count-based sliding window.",
	"language": ["SPL"],
	"category": ["transform", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/014_sort_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["sort", " Time-based", " delta based", "time based", " punctuation-based Count based", "sort", " tumbling window", " sliding window", " punctuation based", " sort with windowing", " count-based"]
}, {
	"State": "live",
	"name": "027_java_op_at_work",
	"description": "This example shows an important operator that brings Java into the C++ dominated world of Streams!!! That operator is called JavaOp, which is used to call out to other operators implemented in Java using the Java Operator API. In this example, we will have a tiny Java logic that will calculate the current time and add that time string to a tuple attribute and output that tuple. There is another example that shows the Java primitive operator that is different from the JavaOp operator.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/027_java_op_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in and C++ primitive operators that are NOT fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["dps", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "dps", "c++", "share data"]
}, {
	"State": "live",
	"name": "053_java_primitive_operator_with_complex_output_tuple_types",
	"description": "This example shows important features that can be done via a Java primitive operator. It shows how to do tracing and logging inside a Java operator. It also shows how we can create an output tuple inside a Java primitive operator to have a list of tuple objects carrying complex typed attributes.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT CALLED Java_Complex_Tuple_Type_Submission THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/053_java_primitive_operator_with_complex_output_tuple_types_com_acme_test_java_primitive_operator_with_complex_output_tuple_types_spl",
	"urlLink": "",
	"tags": [" submit tuple from java", "tuple in java operator", "tuple", "complex tuple", " java operator"]
}, {
	"State": "live",
	"name": "035_c++_primitive_operator_at_work",
	"description": "This example shows the steps required to create a C++ primitive operator from scratch. In this application, a C++ primitive operator model XML file can be explored to learn how the different fields in that file are configured. Then, the code generation template header and implementation files (*_h.cgt and *_cpp.cgt) can be browsed to learn about the primitive operator logic. Additionally, this example demonstrates about including a Java operator and a C++ primitive operator as part of the application flow.",
	"language": ["C++"],
	"category": ["Operators & Functions", " Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/035_c++_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["c++ operators", "c++ example", "c++ operator model", " application development"]
}, {
	"State": "live",
	"name": "037_odbc_adapters_for_solid_db_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters for connecting to a SolidDB in-memory database. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test SolidDB database inside IBM. You have to create your own SolidDB database and tables to make this application work in your environment.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/037_odbc_adapters_for_solid_db_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "soliddb"]
}, {
	"State": "live",
	"name": "061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators that are not fused with each other and a C++ native function. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "hsa", "java", "native function", "db", "query"]
}, {
	"State": "live",
	"name": "006_barrier_at_work",
	"description": "This example shows how to synchronize the incoming tuples using a Barrier operator. It uses a bank deposit/debit scenario to split the deposit/debit requests, perform that account activity, and then combine the post-activity result with the incoming requests. Barrier operator does what is needed to accomplish that i.e. it waits for the streams to arrive at all the configured input ports before emitting an output tuple.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/006_barrier_at_work_sample_barrier_at_work_spl",
	"urlLink": "",
	"tags": ["barrier", "functor", "custom", " slow down stream", "delay", "create tuple", "slow down tuples", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "015_join_at_work",
	"description": "This example shows one of the power-packed standard toolkit operators; i.e. Join. This operator is so versatile that it is hard to do justice in explaining it thoroughly in a simple example such as this one.  This example provides coverage to the following Join operator features.a) Inner Join,b) Inner (Equi) Join,c) Left Outer Join,d) Right Outer Join,e) Full Outer Join",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/015_join_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["join", " inner join", "merge stream", "join", " join stream"]
}, {
	"State": "live",
	"name": "031_spl_mixed_mode_at_work",
	"description": "This example shows a cool SPL feature called mixed-mode support. In this, developers can mix PERL code islands inside of an SPL application. Mixed-mode enables the easy parameterization of SPL applications. This example gives a slight flavor of how a PERL code snippet inter-mixed with SPL allows us to parameterize the SPL Stream names and the number of output stream definitions for an SPL operator. ",
	"language": ["perl"],
	"category": ["Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/031_spl_mixed_mode_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["mixed mode", "spl", "mixed mode", "code generation"]
}, {
	"State": "live",
	"name": "047_streams_host_tags_at_work",
	"description": "This example shows how to create host tags for a given Streams instance and then use those host tags inside an SPL application. By using host tags, it is possible to avoid hard-coding the host names inside the SPL application code. Detailed instructions about creating and using host tags are explained in this example.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/047_streams_host_tags_at_work_host_tags_streams_host_tags_at_work_spl",
	"urlLink": "",
	"tags": ["tcpsink", "tcpsource", "host tags", "operator placement", "tcpsink", "tcpsource", "config clause", "host pools"]
}, {
	"State": "live",
	"name": "049_json_to_tuple_to_json_using_java",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished via two Java primitive operators that make use of the JSON (Java) libraries shipped as part of the Streams product. Those two Java operators are JSONToTuple and TupleToJSON.Note: Performance of the JSON<-->Tuple conversion in this example will be limited by the speed of your Java environment. If you want to get better performance, C++ code would help. There is a separate example (055_json_to_tuple_to_json_using_c++) that shows how to do this conversion using C++.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/049_json_to_tuple_to_json_using_java_sample_Main_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "json", " parse json"]
}, {
	"State": "live",
	"name": "046_launching_external_apps_in_spl",
	"description": "This example shows how to launch/execute an external application within the Streams SPL code. In this case, we defined a simple C++ native function in which we have the required C++ code to launch an external application. That C++ code uses pipes to execute a given application. This function would be useful to launch any custom script within the Streams application logic when certain application specific conditions arise.",
	"language": ["C++"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/046_launching_external_apps_in_spl_launch_external_apps_launching_external_apps_spl",
	"urlLink": "",
	"tags": ["launch an external app", " spl utility functions", "launch a program", "execute program"]
}, {
	"State": "live",
	"name": "059_dynamic_scaleout_of_streams_application",
	"description": "This example shows a particular style of writing Streams applications that can be scaled up or scaled down as the application input workload changes. It uses a familiar scenario from the Financial Services Sector, where the price calculation engines will require scaling up when the market data load increases. Code written in this example uses a pattern for starting more instances of an analytic operator to increase parallelism. New instances of such analytic operators can be started on demand without disrupting the already running application flow. As soon as the newly started operator instances are ready, application load will be promptly distributed across the existing and the newly started instances of that operator. In the same way, when the application data load is not high, some of the most recently started operator instances can be stopped to release the CPU cores for other use. This technique is one of many ways to design Streams applications that will scale up and down dynamically according to the changing input data workload.",
	"language": ["C++"],
	"category": ["Tips,Best Practices,Microservices,Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/059_dynamic_scaleout_of_streams_application_com_ibm_streams_pricing_test_DynamicScaleOut_spl",
	"urlLink": "",
	"tags": ["import", "export", "ingest"]
}, {
	"State": "live",
	"name": "009_custom_operator_using_get_submission_time_value",
	"description": "This example demonstrates how to assign tuple attributes at the time of job submission inside a custom operator. When the incoming tuples arrive at the Custom operator in this example, values entered by the user at the application startup are assigned to the tuple attributes.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/009_custom_operator_using_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["custom", "getsubmissiontimevalue", "get submission time value", " submission time", "parameter lists", " parameters", " custom", "create tuple"]
}, {
	"State": "live",
	"name": "012_filter_functor_at_work",
	"description": "This example puts the two commonly used standard toolkit operators to work. They are Filter and Functor. Filter allows you to route tuples based on conditional checks. It provides two output ports to send the matched tuples on the first output port and the unmatched tuples on the second output port. Functor operator allows us to transform the incoming tuple attributes and then to send it on many different output ports with different stream schemas.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/012_filter_functor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["functor", "filter", "filter tuples", "remove tuples"]
}, {
	"State": "live",
	"name": "022_deduplicate_at_work",
	"description": "This example describes the use of an important operator that is highly applicable in many Telco scenarios. That operator is called DeDuplicate, which eliminates duplicate tuples for a specified duration of time. It also has an optional second output port on which duplicate tuples could be sent out for additional processing.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/022_deduplicate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["deduplicate", "separate two streams", "remove duplicates", "split streams"]
}, {
	"State": "live",
	"name": "013_punctor_at_work",
	"description": "This example shows how a Punctor operator could be used in an application. Punctor operator allows us to transform the input tuples and then inject puncuation markers either before or after the output tuple as configured.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/013_punctor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["punctor", "custom logic", " generate punctuation", " punctuation"]
}, {
	"State": "live",
	"name": "036_shared_lib_primitive_operator_at_work",
	"description": "This example demonstrates two important techniques that will be commonly used in real-world use cases.1) Creating a C++ primitive operator.2) Calling a function available inside a .so shared library from the C++ primitive operator logic.Application logic here is to receive input tuples as hostnames and then make the C++ primitive operator logic invoke a shared library function that does a name server lookup.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED PrimitiveOperatorLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/036_shared_lib_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" c++", " operator dependencies", " library", "shared library", " application development"]
}, {
	"State": "live",
	"name": "003_sink_at_work",
	"description": "This example shows how FileSink and Custom sinks can be employed in applications. It also shows how a Beacon operator can be used to customize tuple attributes. In addition, it introduces the Filter operator to route the incoming tuples by inspecting their attributes using a conditional statement specified in the filter parameter. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/003_sink_at_work_sample_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "read", "files", "write"]
}, {
	"State": "live",
	"name": "023_union_at_work",
	"description": "This example demonstrates an utility operator called Union. This operator combines all the tuples from several input ports as they arrive and emits a single output stream. All the input ports must have a schema that contains attributes of the same name and type as those of the output port. The order of the attributes in the input ports need not match the order in the output port.",
	"language": ["SPL"],
	"category": ["enrich", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/023_union_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["union", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "044_streams_checkpointing_at_work",
	"description": "This example shows a key feature of Streams by which an operator's state variables can be preserved when a PE fails and gets restarted. This is done through a combination of the SPL configuration directives named 'checkpointing' and 'restartable'. Developers can protect their critical operator data by taking advantage of this built-in checkpointing feature. When you run this example, you will see data flows without any gaps or interruption, when a PE is killed manually and then gets restored automatically by the Streams runtime.",
	"language": ["SPL"],
	"category": ["performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/044_streams_checkpointing_at_work_checkpointing_example_streams_checkpointing_at_work_spl",
	"urlLink": "",
	"tags": ["checkpoint config clause", " data consistency", "automatic checkpointing", " fail over", "checkpoint"]
}, {
	"State": "live",
	"name": "001_hello_world_in_spl",
	"description": "This example is the simplest possible SPL application. It uses a Beacon operator to generate tuples that carry Hello World' messages. A custom sink operator receives the tuples from Beacon and displays it on the console.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/001_hello_world_in_spl_HelloWorld_spl",
	"urlLink": "",
	"tags": ["custom"]
}, {
	"State": "live",
	"name": "038_spl_built_in_functions_at_work",
	"description": "This is a very simple example that showcases a random collection of powerful built-in SPL functions that are available out of the box. This application demonstrates how time, math, and collection type functions can be used inside of an SPL application.",
	"language": ["SPL"],
	"category": ["Best Practices", "Collections and Data Types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/038_spl_built_in_functions_at_work_test_scratch_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "data types", " spl functions", "list", " mutable", " convert time stamp", "map", " convert timestamp", " timestamps", " utility functions"]
}, {
	"State": "live",
	"name": "056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example shows a particular implementation about how data can be shared across multiple FUSED operators using an SPL map based in-memory store. Here, we are simply showing a way to use the SPL native function facility to perform data sharing via an SPL map based in-memory store that will serve multiple SPL standard toolkit operators and C++ primitive operators. As mentioned above, this example shows data sharing between multiple operators that are fused inside a single PE (Processing Element). This technical approach is called Process Store (ps). This data sharing mechanism will NOT work between operators that are on different PEs. This example depends on the com.ibm.streamsx.ps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "db", "query"]
}, {
	"State": "live",
	"name": "034_odbc_adapters_for_db2_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test DB2 database inside IBM. You have to create your own DB2 database and tables to make this application work in your environment. After creating your own database and tables, you have to change the etc/connections.xml file in this application's directory to match your database/table names, userid, and password. You also have to make changes in the SPL code using your database information for all the three ODBC operator invocations.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/034_odbc_adapters_for_db2_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "db2"]
}, {
	"State": "live",
	"name": "051_native_functions_with_collection_types",
	"description": "This example shows an important feature of Streams. In Streams applications, it may be necessary to accept and return collection types in and out of the C++ native functions. This will require native function code that can directly deal with types such as list, map, and tuple. Streams provides C++ reflection APIs to directly deal with such collection types. In this example, developers can learn how to build native functions inside of a C++ class and then pass list, map, and tuple types to those native functions. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionsWithCollectionTypesLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/051_native_functions_with_collection_types_com_ibm_nf_test_native_functions_with_collection_types_spl",
	"urlLink": "",
	"tags": [" data types", "native functions", "collections", "list", "c++ native functions example", "c++", "map", " collections", "application development", "tuple"]
}, {
	"State": "live",
	"name": "040_ingest_data_generation_in_spl",
	"description": "This example shows how SPL provides rich features to generate synthetic data required for large scale testing. Many real-life applications in the Telco and the Retail Banking sectors consume large amounts of daily business data through CSV formatted text files. There could be huge amounts of CDR data from several telecom circles or daily transaction data for millions of accounts in a retail bank.While building and testing the SPL applications, it will become necessary to generate such ingest data files with artificial data that is close enough to be realistic. This application shows how such large amounts of data in several thousands of files can be created very quickly using the SPL standard toolkit operators as well as the SPL file IO and math random built-in functions.",
	"language": ["SPL"],
	"category": ["Collections & Data types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/040_ingest_data_generation_in_spl_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["test data generation", "data types", " test data generation", "sample data", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "025_dynamic_filter_at_work",
	"description": "This example deals with an interesting standard toolkit operator called DynamicFilter. This operator is a special version of the Filter operator that you have already seen in another example; it decides at runtime which input tuples will be passed through, based on the control input it receives. This operator is applicable in many real-life scenarios. This example also demonstrates using a second composite operator to perform a sub-task that the main composite will make use of. There is also coverage to show how the second composite can take its own operator parameters.  ",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/025_dynamic_filter_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["dynamicfilter", " reusable composite", "composite operators", " filter based on input", " dynamic filter", "filter"]
}, {
	"State": "live",
	"name": "062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators and a Java primitive operator that are not fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples. In this SPL project, you will find a Java primitive operator that exercises all the dps APIs in a very comprehensive manner. In order to get access to the dps APIs, this project's build path is added with dps-helper.jar available inside the com.ibm.streamsx.dps toolkit directory (i.e. impl/java/bin). Please read at the top of this project's SPL file and the TickerIdGenerator.java primitive operator file for an extensive commentary about how to run this example.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["java database", "database", "redis", "hsa", "java", "mongo", "db", "query"]
}, {
	"State": "live",
	"name": "063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators",
	"description": "This example shows how to create a tuple on the fly inside a Java primitive operator. In addition, this example also shows how to convert a tuple into a blob (Java byte buffer) and how to convert a blob (Java byte buffer) in to a tuple. It is an interesting concept that a Java primitive operator developer can put into use in certain situations that warrant dynamic tuple creation, tuple encoding and decoding all inside Java.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators_application_Main_spl",
	"urlLink": "",
	"tags": ["create tuple in java", "java", "blob", "blob java", "create tuple"]
}, {
	"State": "live",
	"name": "064_using_spl_composite_params",
	"description": "This example shows different ways in which parameters can be passed to SPL composites. It is very useful to pass parameters as attributes, expressions, functions, operators, and types. These different ways of passing parameters to the composites is the focus of this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/064_using_spl_composite_params_com_acme_test_CompositeParams_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "065_using_multiple_threads_in_java_operator",
	"description": "This example shows how to spawn multiple threads within a Java primitive operator and then submit tuples from within those threads concurrently.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/065_using_multiple_threads_in_java_operator_com_acme_test_JavaOpSubmitFromMultipleThreads_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "066_load_balancing_using_gate",
	"description": "As documented in the Streams Info Center for a ThreadedSplit, if the processing time of a tuple varies considerably depending on the tuple data, it may cause problems where a tuple with a long processing time may cause subsequent tuples to be backed up in the stream. This example shows how a Gate operator can be combined with the ThreadedSplit can be used to ensure load balancing.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/066_load_balancing_using_gate_com_acme_test_LoadBalancingUsingGate_spl",
	"urlLink": "",
	"tags": ["gate"]
}, {
	"State": "live",
	"name": "067_simple_java_source_operator",
	"description": "This example shows a basic source operator implemented in Java. There are specific steps required for implementing a source operator and it can be learned in this example.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/067_simple_java_source_operator_com_acme_test_Temp1_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "068_tuple_introspection_inside_java_operator",
	"description": "This example shows how a tuple can be introspected to learn about its structure and its attribute names and their types. Inside a Java operator, this example illustrates how it is possible to recursively look through a tuple to understand its composition.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/068_tuple_introspection_inside_java_operator_com_acme_test_Temp2_spl",
	"urlLink": "",
	"tags": ["parse tuple in java", "tuples", " collections", "tuples java", " java operator", "spl data types"]
}, {
	"State": "live",
	"name": "069_changing_map_value_during_iteration",
	"description": "Until the release of Streams version 3.2.1, it was not possible to modify the value of a map inside an iteration loop. This example shows a new feature available in Streams version 3.2.1 that permits the value of a map to be modified inside a for loop.",
	"language": ["SPL"],
	"category": ["Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/069_changing_map_value_during_iteration_com_acme_test_ChangeCollectionValue_spl",
	"urlLink": "",
	"tags": ["iterate over map", "iteration", "change map value", "change map"]
}, {
	"State": "live",
	"name": "070_convert_block_data_into_tuples_using_parse",
	"description": "This example shows how a block of data ingested as a blob type can be converted into individual tuples using the Parse operator.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/070_convert_block_data_into_tuples_using_parse_com_acme_test_ConvertBlockDataWithParse_spl",
	"urlLink": "",
	"tags": ["parse", "parse operator", "parse blob", " convert blob to tuple", "tuples"]
}, {
	"State": "live",
	"name": "071_java_native_functions",
	"description": "Java native functions provide a cool way to add user-defined functions in Java and then call them directly within the SPL code. This example shows how easy it is to create java native functions.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/071_java_native_functions_com_acme_test_JavaNativeFunctions_spl",
	"urlLink": "",
	"tags": ["create java native function", "java function"]
}, {
	"State": "live",
	"name": "072_using_streams_rest_apis",
	"description": "Streams provides REST APIs to query different kinds of metrics about the instances, jobs, resources during the runtime operation. It is a comprehensive set of APIs that can be used with proper security configuration. This example shows a few different REST APIs in action by invoking them within Java code.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/072_using_streams_rest_apis_com_acme_test_UsingStreamsRestApis_spl",
	"urlLink": "",
	"tags": ["get job info", "monitoring", "rest", "rest api example", "jobs"]
}, {
	"State": "live",
	"name": "073_java_operator_fusion",
	"description": "This example shows how two different Java operators one performing the Sink operation and the other performing the analytics operation can be fused to operate within a single PE.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/073_java_operator_fusion_com_acme_test_JavaFusion_spl",
	"urlLink": "",
	"tags": ["java operator fusion", " ", "fuse multiple operators"]
}, {
	"State": "live",
	"name": "074_user_defined_parallelism_01",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/074_user_defined_parallelism_01_com_acme_test_UDP1_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "075_user_defined_parallelism_02",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/075_user_defined_parallelism_02_com_acme_test_UDP2_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "076_user_defined_parallelism_03",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/076_user_defined_parallelism_03_com_acme_test_UDP3_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "077_user_defined_parallelism_04",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/077_user_defined_parallelism_04_com_acme_test_UDP4_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "078_user_defined_parallelism_05",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/078_user_defined_parallelism_05_com_acme_test_UDP5_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "079_user_defined_parallelism_06",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/079_user_defined_parallelism_06_com_acme_test_UDP6_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "080_user_defined_parallelism_07",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/080_user_defined_parallelism_07_com_acme_test_UDP7_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "081_user_defined_parallelism_08",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/081_user_defined_parallelism_08_com_acme_test_UDP8_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "083_user_defined_parallelism_10",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/083_user_defined_parallelism_10_com_acme_test_UDP10_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "084_user_defined_parallelism_11",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/084_user_defined_parallelism_11_com_acme_test_UDP11_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "085_user_defined_parallelism_12",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/085_user_defined_parallelism_12_com_acme_test_UDP12_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "086_jms_source_sink_using_activemq",
	"description": "This example shows how the JMSSource and JMSSink operators from the Streams standard toolkit can be put to use for sending messages from Streams into the Apache ActiveMQ queues and topics as well as reading messages from there into Streams.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/086_jms_source_sink_using_activemq_com_acme_test_JMSSourceSink_spl",
	"urlLink": "",
	"tags": ["jmssource", "jmssink", "activemq", "jms", "read from activemq", "messaging server", "messaging"]
}, {
	"State": "live",
	"name": "087_email_alerts_via_java_native_function",
	"description": "This example shows a way to send email alerts from an SPL application. It is done via a Java native function by using the email API available in the standard Java platform. If an SMTP server is present in the same   network where Streams servers are connected, the technique shown in this example can be put to use for sending email alerts.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/087_email_alerts_via_java_native_function_com_acme_test_EmailAlerts_spl",
	"urlLink": "",
	"tags": ["send email", "email", "send email java"]
}, {
	"State": "live",
	"name": "088_java_operator_params_and_multiple_input_output_ports",
	"description": "This example demonstrates two different features of the Java primitive operator framework. It first shows how operator parameters can be easily processed inside the Java operators via the @Parameter annotations. Then, it shows how multiple input and output ports can be accessed inside the Java operators. As a bonus, it also shows a better approach for on the fly creation of the output tuples made with complex nested types.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/088_java_operator_params_and_multiple_input_output_ports_com_acme_test_JavaOperatorParams_spl",
	"urlLink": "",
	"tags": [" complex tuple", "java operator", "java operator parameters", "java", "java operator", "multiple input ports", "create tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "089_integrating_streams_apps_with_web_apps",
	"description": "This example demonstrates one of the Streams open source toolkits (com.ibm.streamsx.inet). Using this toolkit one can integrate Streams applications with web applications. Please read the comments in the SPL file for this example project to download that toolkit, install it, and then use that toolkit inside a simple SPL application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/089_integrating_streams_apps_with_web_apps_com_acme_test_WebCalculator_spl",
	"urlLink": "",
	"tags": ["httptupleinjection", "httptupleview", "send tuples to browser", "rest", "post to streams app", "streams web app"]
}, {
	"State": "live",
	"name": "090_consistent_region_spl_01",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/090_consistent_region_spl_01_com_acme_test_ConsistentRegion1_spl",
	"urlLink": "",
	"tags": ["filesource"]
}, {
	"State": "live",
	"name": "091_consistent_region_spl_02",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a FileSource with a periodic checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/091_consistent_region_spl_02_com_acme_test_ConsistentRegion2_spl",
	"urlLink": "",
	"tags": ["beacon"]
}, {
	"State": "live",
	"name": "092_consistent_region_spl_03",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the Aggregate operators in this application is forcefully aborted inside the application multiple times to prove that application survive those multiple crashes at different times and yet will continue processing tuples normally after an automatic restart of that failed operator. In addition, during those crashes Streams will preserve the windows contents of that Aggregate operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/092_consistent_region_spl_03_com_acme_test_ConsistentRegion3_spl",
	"urlLink": "",
	"tags": ["aggregate", "consistent region window", "consistent region"]
}, {
	"State": "live",
	"name": "093_consistent_region_spl_04",
	"description": "This example demonstrates how a consistent region can be defined for two different composites acting as sources for this application. These consistent regions have a periodic checkpoint trigger. Couple of different Custom operators connected to those sources are forcefully aborted inside the application. Output streams of those operators will be combined using a Join operator. This application will ensure that the application will continue normally without losing any tuples by withstanding the random crash of those two Custom operators.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/093_consistent_region_spl_04_com_acme_test_ConsistentRegion4_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "094_consistent_region_spl_05",
	"description": "This particular example shows how only a portion of the topology will take part in the consistent region by having an autonomous section in the application graph. This example simulates the operator failure by aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Join operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration. At the same time, parts of the application that is in the autonomous area will get duplicate tuples during a crash recovery happening in the consistent region of this application graph. This example's purpose is to make the users aware of this fact. In the autonomous area, measures need to be taken to do deduplication.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/094_consistent_region_spl_05_com_acme_test_ConsistentRegion5_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "095_consistent_region_spl_06",
	"description": "This particular example shows how a non-replay capable Source operator will not be a show stopper when it comes to employing the consistent region feature in such applications. When using sources (such as TCPSource) that can't realistically replay data, there is way to configure your application with consistent region by using an utility operator called ReplaybleStart (shipped with the Streams product). In this example, we will use a topology that uses TCPSource along with ReplayableStart to achieve application-level fault tolerance.  This example simulates the operator failure by  aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Aggregate operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/095_consistent_region_spl_06_com_acme_test_ConsistentRegion6_spl",
	"urlLink": "",
	"tags": ["replayablestart", "enabling consistent regions when the source operator deos not support it", "failure", "crash", "high availability", "guaranteed processing", "replayablestart"]
}, {
	"State": "live",
	"name": "100_using_jmx_api_01",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to query information about the Streams domain and the Streams instance.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/100_using_jmx_api_01",
	"urlLink": "",
	"tags": ["jmx api", " jmx", " monitoring", "domains"]
}, {
	"State": "live",
	"name": "101_using_jmx_api_02",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to fetch the bulk contents from a log file for a given domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/101_using_jmx_api_02",
	"urlLink": "",
	"tags": ["jmx api", "monitoring", "get log file using jmx"]
}, {
	"State": "live",
	"name": "102_using_jmx_api_03",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX API notifications to get alerted via callback functions about an inactivity timeout in a given Streams domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/102_using_jmx_api_03",
	"urlLink": "",
	"tags": [" use jmx to get alerts", " monitoring", "jmx"]
}, {
	"State": "live",
	"name": "103_view_annotation_at_work",
	"description": "This is a simple SPL application that explains the steps required to use the view annotation and then how to visualize the view annotated stream in the Streams web console. Detailed steps to view the annotated stream are shown in the commentary section of this SPL file.",
	"language": ["SPL"],
	"category": ["Visualization and Reporting"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/103_view_annotation_at_work_com_acme_test_ViewAnnotationAtWork_spl",
	"urlLink": "",
	"tags": ["microsoft excel", "console", "view annotation", "views example", "reporting", "views", "visualization", "visualize", "application development"]
}, {
	"State": "live",
	"name": "901_cat_example",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/901_cat_example_NumberedCat_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "902_word_count",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/902_word_count_word_count_WordCount_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "903_unique",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/903_unique_Main_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "904_primitive_round_robin_split",
	"description": "SPL Introductory Tutorial sample",
	"language": ["C++"],
	"category": ["Beginner/General", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/904_primitive_round_robin_split_Main_spl",
	"urlLink": "",
	"tags": ["pair", "spl"]
}, {
	"State": "live",
	"name": "905_gate_load_balancer",
	"description": "SPL Introductory Tutorial sample\"",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/905_gate_load_balancer_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "gate", "improve performance", " gate operator", "threadedsplit", " threadedsplit operator", "gate"]
},
{
	"State": "live",
	"name": "021_pair_at_work",
	"description": "This example shows off the Pair operator that is used for pairing tuples arriving on different input ports. Only when all the tuples arrive at all the input ports, this operator will emit them one after the other in their order of arrival.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/021_pair_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["pair", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "'096_consistent_region_spl_07",
	"description": "This particular example shows how a C++ primitive operator can play a role inside a consistent region.  It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/096_consistent_region_cpp_07_com_acme_test_ConsistentRegion7_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "097_consistent_region_spl_08",
	"description": "This particular example shows how a C++ primitive operator can be the start of a consistent region.   It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/097_consistent_region_cpp_08_com_acme_test_ConsistentRegion8_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "098_consistent_region_spl_09",
	"description": "This particular example shows how a Java primitive operator can be the start of a consistent region. ",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/098_consistent_region_java_09_com_acme_test_ConsistentRegion9_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "099_consistent_region_spl_10",
	"description": "This particular example shows how a Java primitive operator can play a role inside a consistent region. It demonstrates how to implement the necessary callback functions to support checkpoint and reset.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/099_consistent_region_java_10_com_acme_test_ConsistentRegion10_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "052_streams_to_python",
	"description": "This example shows a powerful feature of Streams to wrap existing code assets written using the Python programming language. This example teaches developers how to use the Streams C++ native functions to call any arbitrary Python function and return the results back to SPL code. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory. You can also read a very detailed IBM developerWorks technical article about this example:  http://tinyurl.com/c3s56fq. [THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED StreamsToPythonLib THAT IS DESCRIBED BELOW.]",
	"language": ["Python"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/052_streams_to_python_python_wrapper_example_streams_to_python_spl",
	"urlLink": "",
	"tags": ["call python from streams", "call python from cpp", " python"]
}, {
	"State": "live",
	"name": "042_dynamic_import_export_api_at_work",
	"description": "This example shows how to use the SPL APIs for dynamically importing and exporting streams. This is achieved by changing the import and export properties on the fly. This powerful feature in Streams provides a way to change the streams producing and consuming operators to change the way in which they publish and subscribe to streams while the application is running.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/042_dynamic_import_export_api_at_work_dynamic_importing_exporting_dynamic_import_spl",
	"urlLink": "",
	"tags": ["import", "export", "dynamic import", "microservices", "export stream", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "045_file_source_using_spl_custom_operator",
	"description": "This example shows how to create source operators using the Custom operator available in the SPL standard toolkit. Starting in Streams 3.x, it is possible to create source operators without writing primitive source operators in C++ or Java. Simple source operators can be written using the built-in SPL Custom operator. This will come handy for those who don't want to do an extra layer of C++ or Java code for satisfying simple needs for a source operator. You will see a function of a file source operator being implemented all using SPL code in this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions,Ingest & Store Data", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/045_file_source_using_spl_custom_operator_my_file_source_file_source_using_spl_custom_operator_spl",
	"urlLink": "",
	"tags": ["read a file using a custom", "custom", "read a file", "filesource", "open a file", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "032_native_function_at_work",
	"description": "This application shows how native functions written in C++ can be called within an SPL application.There are two ways in which native functions can be written in C++.1) Code for the C++ functions can be written in a C++ header file.2) C++ functions can be written outside of the SPL project and packaged into a shared library (.so) file. All the SPL developer will have to work with are an .so file and a C++ header file.This application demonstrates incorporating native functions built in both of those ways.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/032_native_function_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["native functions", " c++", "native functions", " native function model"]
}, {
	"State": "live",
	"name": "018_directory_scan_at_work",
	"description": "This example demonstrates one of the important features desired in the real world (mostly in the Retail banking and in the Telco industries). In many real-world scenarios, they still work via files and such files get dropped into a directory for processing. It is shown here how the DirectoryScan operator picks up a new file as soon as it appears inside an input directory. (Apply caution if huge files are copied to the watch directory. DirectoryScan may detect that big file copy as multiple new files and output multiple tuples with the same file name.)",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/018_directory_scan_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["directoryscan", "read directory repeatedly", "scan directory", "list directory"]
}, {
	"State": "live",
	"name": "011_compiler_intrinsic_functions",
	"description": "Streams compiler provides several intrinsic functions to query the SPL filename, file path, absolute path of the directory, source code line number, composite instance name etc. This example shows the use of the compiler intrinsic functions inside of a Functor operator.",
	"language": ["SPL"],
	"category": ["troubleshooting", " Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/011_compiler_intrinsic_functions_Main_spl",
	"urlLink": "",
	"tags": ["compiler functions", " utility", "print line number", " current line number", " print line number", " print file name", " get file name", " print debug info"]
}, {
	"State": "live",
	"name": "041_real_time_streams_merger",
	"description": "This example shows how two or more incoming streams with a common schema can be merged to flow in a sequence one after the other. This merger is done using a common tuple attribute in those multiple incoming streams as a key. We will use a C++ primitive operator called OrderedMerger that is included in this project. In order for the OrderedMerger to work correctly, it is assumed that multiple input streams for this primitive operator should already be in sorted order based on the key used to merge and sequence them together. ",
	"language": ["C++"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/041_real_time_streams_merger_real_time_merger_real_time_streams_merger_spl",
	"urlLink": "",
	"tags": ["ordered merge of multiple streams ", "c++ example", "merge  streams", " join streams", " c++ operator model", " application development", " ordered merge"]
}, {
	"State": "live",
	"name": "060_simple_pe_failover_technique_at_work",
	"description": "This example shows a way to protect the logic in an analytic operator  when its PE (Processing Element) or its host machine crashes. It uses a well-known fail-over technique that is done through a primary/secondary pair configured for an operator that will need safety from PE or machine crash. This example outlines a scheme for protecting the analytic logic written inside an SPL Custom operator against failures. When such failures occur, a specific fail-over technique employed here will continue the business logic without any interruption. This is done by making a secondary PE to takeover the tasks of the failed primary PE. Thus, the secondary PE does the detection of the primary PE's failure and then changes its role from a secondary PE to a new primary PE. All of this is done without losing any data during the fail-over. At the same time, the failed primary PE will be automatically restarted to do its work as a new secondary PE. This particular fail-over technique ensures that there is always a primary/secondary pair working in concert to provide high availability for a business-critical operator that is coded and configured in this manner.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/060_simple_pe_failover_technique_at_work_com_acme_failover_test_simple_pe_failover_technique_at_work_spl",
	"urlLink": "",
	"tags": ["recovery", " fail over", " crash", "redundancy"]
}, {
	"State": "live",
	"name": "030_spl_config_at_work",
	"description": "This example introduces one of the must-learn features of the SPL language. SPL language offers an extensive list of options to do configuration at the operator level as well as at the composite level. This application attempts to sprinkle many of the available configuration parameters as shown below.a) host,b) hostColocation,c) partitionColocation,d) placement,e) threadedPort and queue,f) relocatable and many more.In addition, this example shows how to make this application toolkit dependent on another (025_dynamic_filter_at_work) SPL toolkit project.",
	"language": ["SPL"],
	"category": ["Tips", "Configuration", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/030_spl_config_at_work_my_sample3_Main_spl",
	"urlLink": "",
	"tags": ["spl config clause", "spl", "concurrency", " threading", "operator fusion", "threading", "host exlocation", "job submission", "load balancing", "host colocation", " spl config clause", "threaded port", "resource allocation", "application deployment"]
}, {
	"State": "live",
	"name": "048_source_operator_with_control_port",
	"description": "This example shows a way to create a C++ primitive source operator and then provide a control input port for it. Certain classes of applications can make use of this facility to control the kind of data a source operator generates. In addition, this example shows how to pass one or more string literals to the C++ primitive operator as invocation time parameters. As a bonus, this example also shows a simple way to do performance measurement inside the SPL code using the built-in SPL high precision timestamp functions.",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/048_source_operator_with_control_port_source_op_with_control_port_source_operator_with_control_port_spl",
	"urlLink": "",
	"tags": ["customized source operator in c++", " control port", "custom", "read a file", "filesource", "open a file", "c++ primitive operator", " custom source operator", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "055_json_to_tuple_to_json_using_c++",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished using an open source C++ JSON API. In order to run this application, you will be required to download an open source component that carries a BSD license. Please read the detailed instructions available in the SPL file for this project. There is also another SPL project that does similar conversion using Java (049_json_to_tuple_to_json_using_java).",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "ttp://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/055_json_to_tuple_to_json_using_c++_com_acme_test_json_to_tuple_to_json_using_cpp_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "parse json from c++", "jsontotuple", "c++ native function"]
}, {
	"State": "live",
	"name": "029_spl_functions_at_work",
	"description": "This example shows how helper and utility functions can be written using the SPL language. It also shows how such SPL functions can be put to use inside the context of an application. Learning this simple concept will go a long way in doing a lot of neat stuff in real-world applications.",
	"language": ["SPL"],
	"category": [" Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/029_spl_functions_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "007_split_at_work",
	"description": "This example shows how a Split operator can be used to split the incoming tuples based on a key. In this example, the split condition (which tuples comes out on which port) is pre configured through a text file. Alternatively, one can compute the index of the output port on the fly inside the Split operator parameter section.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/007_split_at_work_sample_split_at_work_spl",
	"urlLink": "",
	"tags": ["split", "split", " split stream", " divide stream"]
}, {
	"State": "live",
	"name": "028_multiple_composites_at_work",
	"description": "This example shows the use of multiple composites in a single application. There is a main composite that in turn uses two other composites. This application shows how the additional composites in different namespaces get included into the main composite via the 'use' directive. It also demonstrates how the additional composites can accept their own operator parameters. It teaches the basics of an important feature that will come handy when big applications need to be componentized. ",
	"language": ["SPL"],
	"category": ["Best Practices", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/028_multiple_composites_at_work_my_sample1_Main_spl",
	"urlLink": "",
	"tags": ["multiple composites", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "024_threaded_split_at_work",
	"description": "This example demonstrates an important standard toolkit operator named ThreadedSplit. It is a multi-threaded split that is different from the other content-based Split operator. ThreadedSplit uses its own algorithm to split the incoming tuples to the available output ports to improve concurrency. This will speed up the distribution of tuples by using individual threads assigned to each of the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "performance"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/024_threaded_split_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "split stream", "threaded split"]
}, {
	"State": "live",
	"name": "057_reading_nested_tuple_data_via_file_source",
	"description": "This example shows how to ingest nested tuple data via input files specified in a CSV format. There are certain syntactical rules that need to be followed in specifying data for nested tuples inside a CSV formatted input file. This example is a good one for developers to get an idea about how to do this.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/057_reading_nested_tuple_data_via_file_source_com_acme_test_Test1_spl",
	"urlLink": "",
	"tags": ["filesource", "parse", " nested tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "016_aggregate_at_work",
	"description": "This example shows off yet another powerful standard toolkit operator named the Aggregate. It is very good in computing on the fly aggregate values after collecting a set of tuples. Tuples are grouped based on tumbling and sliding windows with partitioned variants. This example also shows how to use the built-in assignment functions provided by this operator to compute regular statistical calculations such as min, max, average, standard deviation etc.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/016_aggregate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["aggregate", "aggregate", "rolling average", "windowing", "average", "window"]
}, {
	"State": "live",
	"name": "020_metrics_sink_at_work",
	"description": "This example shows how one can use the MetricsSink standard toolkit operator to create application-specific custom metrics that can be viewed in real-time when the application is running. Viewing of custom metrics is typically done inside Streams Explorer view of the Streams Studio or by using the capturestate option in streamtool.",
	"language": ["SPL"],
	"category": ["Monitoring", "metrics"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/020_metrics_sink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["metricssink", "metrics", "custom metrics", "application monitoring", "custom statistics"]
}, {
	"State": "live",
	"name": "002_source_sink_at_work",
	"description": "This example shows how a FileSource operator can be used to read CSV formatted records from a file and then receive those tuples in a FileSink to be written to a file in the data directory of this application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/002_source_sink_at_work_sample_source_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", " ", "filesink"]
}, {
	"State": "live",
	"name": "026_gate_at_work",
	"description": "This is an example that uses the Gate operator from the standard toolkit. This operator delays the incoming tuples until a downstream operator signals with an acknowledgment to receive any further tuples. This is a great way to have a feedback through which we can control the rate at which tuples are passed through. (Please refer to another example named 905_gate_load_balancer that shows the effectiveness of the Gate operator in combination with the ThreadedSplit operator to provide load balancing the incoming tuples.)",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/026_gate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["gate", "wait", " hold tuples until signal", "control tuple flow", "wait for tuples"]
}, {
	"State": "live",
	"name": "050_recursive_dir_scan",
	"description": "This example shows how to use the Streams C++ native function facility to recursively scan a given directory and obtain the names of the files present. The logic for the recursive directory scan polls the specified directory periodically and notifies the downstream operator with a new file that just appeared. There is a companion C++ project for this SPL project. Please refer to the RecursiveDirScanLib project for the C++ logic.Important sequence of logic for this application: 1) SPL code resolves the C++ native function in its native.function/function.xml file.2) A call from the SPL code to the native function lands in the wrapper inline C++ function defined in the RecursiveDirScanWrappers.h file of the companion C++ project.3) From that wrapper function, it gets access to a singleton C++ object of the RecursiveDirScan class and then invokes the getFileNamesInDirectory C++ method.4) When that C++ method returns, it will have the results stored in a list<string> reference that was passed to it.5) Back in the SPL code, there is additional logic to cache the already seen files and to filter only the newly found files to send to the downstream operator.In order to test this application, please refer to the commentary at the top of the SPL file in this project.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED RecursiveDirScanLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/050_recursive_dir_scan_recursive_dir_scan_recursive_dir_scan_spl",
	"urlLink": "",
	"tags": ["recursive directory scan in c++", "c++ native functions example", "c++", "application development"]
}, {
	"State": "live",
	"name": "005_throttle_at_work",
	"description": "This example shows how a stream can be throttled to flow at a specified rate. This example also mixes other operators such as Beacon, Custom, and FileSink.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/005_throttle_at_work_sample_throttle_at_work_spl",
	"urlLink": "",
	"tags": ["custom", " throttle", " slow down", "delay", " create tuple", " custom", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "004_delay_at_work",
	"description": "This example shows how a Delay standard toolkit operator can be used to delay a stream. This example also introduces the Custom operator that can be used to perform custom logic. You can also notice the use of a state variable that is mutable inside the Custom operator. It also shows how to create a new tuple on the fly and do your own submissions onto the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/004_delay_at_work_sample_delay_at_work_spl",
	"urlLink": "",
	"tags": ["custom", "delay", "filesink"]
}, {
	"State": "live",
	"name": "019_import_export_at_work",
	"description": "This example demonstrates how two different SPL applications can share streams between them. This is an important feature that is elegantly done using two pseudo operators called Export and Import. This application also shows how two different main composites can be part of the same application by using two different namespaces. As an aside, there is also a demonstration of using a Custom operator to customize the Beacon generated tuples by involving state variables. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/019_import_export_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["import", "export", "microservices", "export stream", "import stream"]
}, {
	"State": "live",
	"name": "033_java_primitive_operator_at_work",
	"description": "This example shows how a Java primitive operator is created from scratch. Java primitive operator is different from JavaOp that you have seen earlier in a different example. Java primitive operator is a first class operator in SPL, whereas JavaOp only permits a callout to another Java operator. In addition, Java primitive operator has the advantage of keeping its name as the operator\u2019s runtime instance name.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT NAMED RSS_Reader_Primitive THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/033_java_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["java operator", " primitive java operator", "java operators", " application development"]
}, {
	"State": "live",
	"name": "043_import_export_filter_at_work",
	"description": "This example shows how to use the SPL feature to apply a filter for what gets exported and what gets imported. This powerful feature lets the downstream import operators to specify what kind of tuples they want to receive by specifying conditional expressions involving tuple attributes. That lets the Streams runtime to apply content-based filtering at the point of export. Those who need such a feature to control what information should be sent downstream based on the tuple contents can make use of this flexible feature. This can be done on the fly without stopping and restarting the application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/043_import_export_filter_at_work_importing_exporting_filter_import_with_filter_spl",
	"urlLink": "",
	"tags": ["import", "export", "filtered import", "dynamic import", "microservices", "export stream", " filter imports", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "017_filesource_filesink_at_work",
	"description": "We have used the FileSource and the FileSink operators in other examples before. However, this example shows off the following intriguing features that will become handy in a lot of practical situations.a) Automatic deletion of a file after the FileSource finishes reading all the records.b) Flushing the sink file on demand after writing a certain number of tuples.c) Ability of the FileSource to move the file once it reads all the content in that file.d) Creating a fresh and new output sink file after writing a certain number of tuples.e) Ability of the FileSource to keep reading from a hot file as new CSV records get written to the end of that file.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/017_filesource_filesink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "advanced file operations", " reread file", "move file", " hot file", "flushing", " automatic deletion", "delete a file"]
}, {
	"State": "live",
	"name": "008_get_submission_time_value",
	"description": "This example shows how the tuple attributes can be assigned values that were supplied by the user at the application/job submission time. It employs the getSubmissionTimeValue function to obtain different values made of different SPL data types. ",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/008_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["functor", "getsubmissiontimevalue", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "014_sort_at_work",
	"description": "This example shows the use of the Sort operator in the context of an application. Sort operator is highly configurable with all kinds of windowing support. In this example, the following window configurations are applied for sorting the incoming tuples:a) Count-based tumbling window.b) Time-based tumbling window.c) Punctuation-based tumbling window.d) Delta-based tumbling window.e) Count-based sliding window.",
	"language": ["SPL"],
	"category": ["transform", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/014_sort_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["sort", " Time-based", " delta based", "time based", " punctuation-based Count based", "sort", " tumbling window", " sliding window", " punctuation based", " sort with windowing", " count-based"]
}, {
	"State": "live",
	"name": "027_java_op_at_work",
	"description": "This example shows an important operator that brings Java into the C++ dominated world of Streams!!! That operator is called JavaOp, which is used to call out to other operators implemented in Java using the Java Operator API. In this example, we will have a tiny Java logic that will calculate the current time and add that time string to a tuple attribute and output that tuple. There is another example that shows the Java primitive operator that is different from the JavaOp operator.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/027_java_op_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in and C++ primitive operators that are NOT fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["dps", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "dps", "c++", "share data"]
}, {
	"State": "live",
	"name": "053_java_primitive_operator_with_complex_output_tuple_types",
	"description": "This example shows important features that can be done via a Java primitive operator. It shows how to do tracing and logging inside a Java operator. It also shows how we can create an output tuple inside a Java primitive operator to have a list of tuple objects carrying complex typed attributes.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT CALLED Java_Complex_Tuple_Type_Submission THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/053_java_primitive_operator_with_complex_output_tuple_types_com_acme_test_java_primitive_operator_with_complex_output_tuple_types_spl",
	"urlLink": "",
	"tags": [" submit tuple from java", "tuple in java operator", "tuple", "complex tuple", " java operator"]
}, {
	"State": "live",
	"name": "035_c++_primitive_operator_at_work",
	"description": "This example shows the steps required to create a C++ primitive operator from scratch. In this application, a C++ primitive operator model XML file can be explored to learn how the different fields in that file are configured. Then, the code generation template header and implementation files (*_h.cgt and *_cpp.cgt) can be browsed to learn about the primitive operator logic. Additionally, this example demonstrates about including a Java operator and a C++ primitive operator as part of the application flow.",
	"language": ["C++"],
	"category": ["Operators & Functions", " Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/035_c++_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["c++ operators", "c++ example", "c++ operator model", " application development"]
}, {
	"State": "live",
	"name": "037_odbc_adapters_for_solid_db_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters for connecting to a SolidDB in-memory database. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test SolidDB database inside IBM. You have to create your own SolidDB database and tables to make this application work in your environment.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/037_odbc_adapters_for_solid_db_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "soliddb"]
}, {
	"State": "live",
	"name": "061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators that are not fused with each other and a C++ native function. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "hsa", "java", "native function", "db", "query"]
}, {
	"State": "live",
	"name": "006_barrier_at_work",
	"description": "This example shows how to synchronize the incoming tuples using a Barrier operator. It uses a bank deposit/debit scenario to split the deposit/debit requests, perform that account activity, and then combine the post-activity result with the incoming requests. Barrier operator does what is needed to accomplish that i.e. it waits for the streams to arrive at all the configured input ports before emitting an output tuple.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/006_barrier_at_work_sample_barrier_at_work_spl",
	"urlLink": "",
	"tags": ["barrier", "functor", "custom", " slow down stream", "delay", "create tuple", "slow down tuples", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "015_join_at_work",
	"description": "This example shows one of the power-packed standard toolkit operators; i.e. Join. This operator is so versatile that it is hard to do justice in explaining it thoroughly in a simple example such as this one.  This example provides coverage to the following Join operator features.a) Inner Join,b) Inner (Equi) Join,c) Left Outer Join,d) Right Outer Join,e) Full Outer Join",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/015_join_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["join", " inner join", "merge stream", "join", " join stream"]
}, {
	"State": "live",
	"name": "031_spl_mixed_mode_at_work",
	"description": "This example shows a cool SPL feature called mixed-mode support. In this, developers can mix PERL code islands inside of an SPL application. Mixed-mode enables the easy parameterization of SPL applications. This example gives a slight flavor of how a PERL code snippet inter-mixed with SPL allows us to parameterize the SPL Stream names and the number of output stream definitions for an SPL operator. ",
	"language": ["perl"],
	"category": ["Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/031_spl_mixed_mode_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["mixed mode", "spl", "mixed mode", "code generation"]
}, {
	"State": "live",
	"name": "047_streams_host_tags_at_work",
	"description": "This example shows how to create host tags for a given Streams instance and then use those host tags inside an SPL application. By using host tags, it is possible to avoid hard-coding the host names inside the SPL application code. Detailed instructions about creating and using host tags are explained in this example.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/047_streams_host_tags_at_work_host_tags_streams_host_tags_at_work_spl",
	"urlLink": "",
	"tags": ["tcpsink", "tcpsource", "host tags", "operator placement", "tcpsink", "tcpsource", "config clause", "host pools"]
}, {
	"State": "live",
	"name": "049_json_to_tuple_to_json_using_java",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished via two Java primitive operators that make use of the JSON (Java) libraries shipped as part of the Streams product. Those two Java operators are JSONToTuple and TupleToJSON.Note: Performance of the JSON<-->Tuple conversion in this example will be limited by the speed of your Java environment. If you want to get better performance, C++ code would help. There is a separate example (055_json_to_tuple_to_json_using_c++) that shows how to do this conversion using C++.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/049_json_to_tuple_to_json_using_java_sample_Main_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "json", " parse json"]
}, {
	"State": "live",
	"name": "046_launching_external_apps_in_spl",
	"description": "This example shows how to launch/execute an external application within the Streams SPL code. In this case, we defined a simple C++ native function in which we have the required C++ code to launch an external application. That C++ code uses pipes to execute a given application. This function would be useful to launch any custom script within the Streams application logic when certain application specific conditions arise.",
	"language": ["C++"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/046_launching_external_apps_in_spl_launch_external_apps_launching_external_apps_spl",
	"urlLink": "",
	"tags": ["launch an external app", " spl utility functions", "launch a program", "execute program"]
}, {
	"State": "live",
	"name": "059_dynamic_scaleout_of_streams_application",
	"description": "This example shows a particular style of writing Streams applications that can be scaled up or scaled down as the application input workload changes. It uses a familiar scenario from the Financial Services Sector, where the price calculation engines will require scaling up when the market data load increases. Code written in this example uses a pattern for starting more instances of an analytic operator to increase parallelism. New instances of such analytic operators can be started on demand without disrupting the already running application flow. As soon as the newly started operator instances are ready, application load will be promptly distributed across the existing and the newly started instances of that operator. In the same way, when the application data load is not high, some of the most recently started operator instances can be stopped to release the CPU cores for other use. This technique is one of many ways to design Streams applications that will scale up and down dynamically according to the changing input data workload.",
	"language": ["C++"],
	"category": ["Tips,Best Practices,Microservices,Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/059_dynamic_scaleout_of_streams_application_com_ibm_streams_pricing_test_DynamicScaleOut_spl",
	"urlLink": "",
	"tags": ["import", "export", "ingest"]
}, {
	"State": "live",
	"name": "009_custom_operator_using_get_submission_time_value",
	"description": "This example demonstrates how to assign tuple attributes at the time of job submission inside a custom operator. When the incoming tuples arrive at the Custom operator in this example, values entered by the user at the application startup are assigned to the tuple attributes.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/009_custom_operator_using_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["custom", "getsubmissiontimevalue", "get submission time value", " submission time", "parameter lists", " parameters", " custom", "create tuple"]
}, {
	"State": "live",
	"name": "012_filter_functor_at_work",
	"description": "This example puts the two commonly used standard toolkit operators to work. They are Filter and Functor. Filter allows you to route tuples based on conditional checks. It provides two output ports to send the matched tuples on the first output port and the unmatched tuples on the second output port. Functor operator allows us to transform the incoming tuple attributes and then to send it on many different output ports with different stream schemas.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/012_filter_functor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["functor", "filter", "filter tuples", "remove tuples"]
}, {
	"State": "live",
	"name": "022_deduplicate_at_work",
	"description": "This example describes the use of an important operator that is highly applicable in many Telco scenarios. That operator is called DeDuplicate, which eliminates duplicate tuples for a specified duration of time. It also has an optional second output port on which duplicate tuples could be sent out for additional processing.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/022_deduplicate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["deduplicate", "separate two streams", "remove duplicates", "split streams"]
}, {
	"State": "live",
	"name": "013_punctor_at_work",
	"description": "This example shows how a Punctor operator could be used in an application. Punctor operator allows us to transform the input tuples and then inject puncuation markers either before or after the output tuple as configured.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/013_punctor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["punctor", "custom logic", " generate punctuation", " punctuation"]
}, {
	"State": "live",
	"name": "036_shared_lib_primitive_operator_at_work",
	"description": "This example demonstrates two important techniques that will be commonly used in real-world use cases.1) Creating a C++ primitive operator.2) Calling a function available inside a .so shared library from the C++ primitive operator logic.Application logic here is to receive input tuples as hostnames and then make the C++ primitive operator logic invoke a shared library function that does a name server lookup.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED PrimitiveOperatorLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/036_shared_lib_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" c++", " operator dependencies", " library", "shared library", " application development"]
}, {
	"State": "live",
	"name": "003_sink_at_work",
	"description": "This example shows how FileSink and Custom sinks can be employed in applications. It also shows how a Beacon operator can be used to customize tuple attributes. In addition, it introduces the Filter operator to route the incoming tuples by inspecting their attributes using a conditional statement specified in the filter parameter. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/003_sink_at_work_sample_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "read", "files", "write"]
}, {
	"State": "live",
	"name": "023_union_at_work",
	"description": "This example demonstrates an utility operator called Union. This operator combines all the tuples from several input ports as they arrive and emits a single output stream. All the input ports must have a schema that contains attributes of the same name and type as those of the output port. The order of the attributes in the input ports need not match the order in the output port.",
	"language": ["SPL"],
	"category": ["enrich", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/023_union_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["union", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "044_streams_checkpointing_at_work",
	"description": "This example shows a key feature of Streams by which an operator's state variables can be preserved when a PE fails and gets restarted. This is done through a combination of the SPL configuration directives named 'checkpointing' and 'restartable'. Developers can protect their critical operator data by taking advantage of this built-in checkpointing feature. When you run this example, you will see data flows without any gaps or interruption, when a PE is killed manually and then gets restored automatically by the Streams runtime.",
	"language": ["SPL"],
	"category": ["performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/044_streams_checkpointing_at_work_checkpointing_example_streams_checkpointing_at_work_spl",
	"urlLink": "",
	"tags": ["checkpoint config clause", " data consistency", "automatic checkpointing", " fail over", "checkpoint"]
}, {
	"State": "live",
	"name": "001_hello_world_in_spl",
	"description": "This example is the simplest possible SPL application. It uses a Beacon operator to generate tuples that carry Hello World' messages. A custom sink operator receives the tuples from Beacon and displays it on the console.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/001_hello_world_in_spl_HelloWorld_spl",
	"urlLink": "",
	"tags": ["custom"]
}, {
	"State": "live",
	"name": "038_spl_built_in_functions_at_work",
	"description": "This is a very simple example that showcases a random collection of powerful built-in SPL functions that are available out of the box. This application demonstrates how time, math, and collection type functions can be used inside of an SPL application.",
	"language": ["SPL"],
	"category": ["Best Practices", "Collections and Data Types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/038_spl_built_in_functions_at_work_test_scratch_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "data types", " spl functions", "list", " mutable", " convert time stamp", "map", " convert timestamp", " timestamps", " utility functions"]
}, {
	"State": "live",
	"name": "056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example shows a particular implementation about how data can be shared across multiple FUSED operators using an SPL map based in-memory store. Here, we are simply showing a way to use the SPL native function facility to perform data sharing via an SPL map based in-memory store that will serve multiple SPL standard toolkit operators and C++ primitive operators. As mentioned above, this example shows data sharing between multiple operators that are fused inside a single PE (Processing Element). This technical approach is called Process Store (ps). This data sharing mechanism will NOT work between operators that are on different PEs. This example depends on the com.ibm.streamsx.ps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "db", "query"]
}, {
	"State": "live",
	"name": "034_odbc_adapters_for_db2_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test DB2 database inside IBM. You have to create your own DB2 database and tables to make this application work in your environment. After creating your own database and tables, you have to change the etc/connections.xml file in this application's directory to match your database/table names, userid, and password. You also have to make changes in the SPL code using your database information for all the three ODBC operator invocations.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/034_odbc_adapters_for_db2_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "db2"]
}, {
	"State": "live",
	"name": "051_native_functions_with_collection_types",
	"description": "This example shows an important feature of Streams. In Streams applications, it may be necessary to accept and return collection types in and out of the C++ native functions. This will require native function code that can directly deal with types such as list, map, and tuple. Streams provides C++ reflection APIs to directly deal with such collection types. In this example, developers can learn how to build native functions inside of a C++ class and then pass list, map, and tuple types to those native functions. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionsWithCollectionTypesLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/051_native_functions_with_collection_types_com_ibm_nf_test_native_functions_with_collection_types_spl",
	"urlLink": "",
	"tags": [" data types", "native functions", "collections", "list", "c++ native functions example", "c++", "map", " collections", "application development", "tuple"]
}, {
	"State": "live",
	"name": "040_ingest_data_generation_in_spl",
	"description": "This example shows how SPL provides rich features to generate synthetic data required for large scale testing. Many real-life applications in the Telco and the Retail Banking sectors consume large amounts of daily business data through CSV formatted text files. There could be huge amounts of CDR data from several telecom circles or daily transaction data for millions of accounts in a retail bank.While building and testing the SPL applications, it will become necessary to generate such ingest data files with artificial data that is close enough to be realistic. This application shows how such large amounts of data in several thousands of files can be created very quickly using the SPL standard toolkit operators as well as the SPL file IO and math random built-in functions.",
	"language": ["SPL"],
	"category": ["Collections & Data types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/040_ingest_data_generation_in_spl_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["test data generation", "data types", " test data generation", "sample data", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "025_dynamic_filter_at_work",
	"description": "This example deals with an interesting standard toolkit operator called DynamicFilter. This operator is a special version of the Filter operator that you have already seen in another example; it decides at runtime which input tuples will be passed through, based on the control input it receives. This operator is applicable in many real-life scenarios. This example also demonstrates using a second composite operator to perform a sub-task that the main composite will make use of. There is also coverage to show how the second composite can take its own operator parameters.  ",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/025_dynamic_filter_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["dynamicfilter", " reusable composite", "composite operators", " filter based on input", " dynamic filter", "filter"]
}, {
	"State": "live",
	"name": "062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators and a Java primitive operator that are not fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples. In this SPL project, you will find a Java primitive operator that exercises all the dps APIs in a very comprehensive manner. In order to get access to the dps APIs, this project's build path is added with dps-helper.jar available inside the com.ibm.streamsx.dps toolkit directory (i.e. impl/java/bin). Please read at the top of this project's SPL file and the TickerIdGenerator.java primitive operator file for an extensive commentary about how to run this example.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["java database", "database", "redis", "hsa", "java", "mongo", "db", "query"]
}, {
	"State": "live",
	"name": "063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators",
	"description": "This example shows how to create a tuple on the fly inside a Java primitive operator. In addition, this example also shows how to convert a tuple into a blob (Java byte buffer) and how to convert a blob (Java byte buffer) in to a tuple. It is an interesting concept that a Java primitive operator developer can put into use in certain situations that warrant dynamic tuple creation, tuple encoding and decoding all inside Java.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators_application_Main_spl",
	"urlLink": "",
	"tags": ["create tuple in java", "java", "blob", "blob java", "create tuple"]
}, {
	"State": "live",
	"name": "064_using_spl_composite_params",
	"description": "This example shows different ways in which parameters can be passed to SPL composites. It is very useful to pass parameters as attributes, expressions, functions, operators, and types. These different ways of passing parameters to the composites is the focus of this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/064_using_spl_composite_params_com_acme_test_CompositeParams_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "065_using_multiple_threads_in_java_operator",
	"description": "This example shows how to spawn multiple threads within a Java primitive operator and then submit tuples from within those threads concurrently.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/065_using_multiple_threads_in_java_operator_com_acme_test_JavaOpSubmitFromMultipleThreads_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "066_load_balancing_using_gate",
	"description": "As documented in the Streams Info Center for a ThreadedSplit, if the processing time of a tuple varies considerably depending on the tuple data, it may cause problems where a tuple with a long processing time may cause subsequent tuples to be backed up in the stream. This example shows how a Gate operator can be combined with the ThreadedSplit can be used to ensure load balancing.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/066_load_balancing_using_gate_com_acme_test_LoadBalancingUsingGate_spl",
	"urlLink": "",
	"tags": ["gate"]
}, {
	"State": "live",
	"name": "067_simple_java_source_operator",
	"description": "This example shows a basic source operator implemented in Java. There are specific steps required for implementing a source operator and it can be learned in this example.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/067_simple_java_source_operator_com_acme_test_Temp1_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "068_tuple_introspection_inside_java_operator",
	"description": "This example shows how a tuple can be introspected to learn about its structure and its attribute names and their types. Inside a Java operator, this example illustrates how it is possible to recursively look through a tuple to understand its composition.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/068_tuple_introspection_inside_java_operator_com_acme_test_Temp2_spl",
	"urlLink": "",
	"tags": ["parse tuple in java", "tuples", " collections", "tuples java", " java operator", "spl data types"]
}, {
	"State": "live",
	"name": "069_changing_map_value_during_iteration",
	"description": "Until the release of Streams version 3.2.1, it was not possible to modify the value of a map inside an iteration loop. This example shows a new feature available in Streams version 3.2.1 that permits the value of a map to be modified inside a for loop.",
	"language": ["SPL"],
	"category": ["Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/069_changing_map_value_during_iteration_com_acme_test_ChangeCollectionValue_spl",
	"urlLink": "",
	"tags": ["iterate over map", "iteration", "change map value", "change map"]
}, {
	"State": "live",
	"name": "070_convert_block_data_into_tuples_using_parse",
	"description": "This example shows how a block of data ingested as a blob type can be converted into individual tuples using the Parse operator.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/070_convert_block_data_into_tuples_using_parse_com_acme_test_ConvertBlockDataWithParse_spl",
	"urlLink": "",
	"tags": ["parse", "parse operator", "parse blob", " convert blob to tuple", "tuples"]
}, {
	"State": "live",
	"name": "071_java_native_functions",
	"description": "Java native functions provide a cool way to add user-defined functions in Java and then call them directly within the SPL code. This example shows how easy it is to create java native functions.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/071_java_native_functions_com_acme_test_JavaNativeFunctions_spl",
	"urlLink": "",
	"tags": ["create java native function", "java function"]
}, {
	"State": "live",
	"name": "072_using_streams_rest_apis",
	"description": "Streams provides REST APIs to query different kinds of metrics about the instances, jobs, resources during the runtime operation. It is a comprehensive set of APIs that can be used with proper security configuration. This example shows a few different REST APIs in action by invoking them within Java code.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/072_using_streams_rest_apis_com_acme_test_UsingStreamsRestApis_spl",
	"urlLink": "",
	"tags": ["get job info", "monitoring", "rest", "rest api example", "jobs"]
}, {
	"State": "live",
	"name": "073_java_operator_fusion",
	"description": "This example shows how two different Java operators one performing the Sink operation and the other performing the analytics operation can be fused to operate within a single PE.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/073_java_operator_fusion_com_acme_test_JavaFusion_spl",
	"urlLink": "",
	"tags": ["java operator fusion", " ", "fuse multiple operators"]
}, {
	"State": "live",
	"name": "074_user_defined_parallelism_01",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/074_user_defined_parallelism_01_com_acme_test_UDP1_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "075_user_defined_parallelism_02",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/075_user_defined_parallelism_02_com_acme_test_UDP2_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "076_user_defined_parallelism_03",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/076_user_defined_parallelism_03_com_acme_test_UDP3_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "077_user_defined_parallelism_04",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/077_user_defined_parallelism_04_com_acme_test_UDP4_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "078_user_defined_parallelism_05",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/078_user_defined_parallelism_05_com_acme_test_UDP5_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "079_user_defined_parallelism_06",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/079_user_defined_parallelism_06_com_acme_test_UDP6_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "080_user_defined_parallelism_07",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/080_user_defined_parallelism_07_com_acme_test_UDP7_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "081_user_defined_parallelism_08",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/081_user_defined_parallelism_08_com_acme_test_UDP8_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "083_user_defined_parallelism_10",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/083_user_defined_parallelism_10_com_acme_test_UDP10_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "084_user_defined_parallelism_11",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/084_user_defined_parallelism_11_com_acme_test_UDP11_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "085_user_defined_parallelism_12",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/085_user_defined_parallelism_12_com_acme_test_UDP12_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "086_jms_source_sink_using_activemq",
	"description": "This example shows how the JMSSource and JMSSink operators from the Streams standard toolkit can be put to use for sending messages from Streams into the Apache ActiveMQ queues and topics as well as reading messages from there into Streams.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/086_jms_source_sink_using_activemq_com_acme_test_JMSSourceSink_spl",
	"urlLink": "",
	"tags": ["jmssource", "jmssink", "activemq", "jms", "read from activemq", "messaging server", "messaging"]
}, {
	"State": "live",
	"name": "087_email_alerts_via_java_native_function",
	"description": "This example shows a way to send email alerts from an SPL application. It is done via a Java native function by using the email API available in the standard Java platform. If an SMTP server is present in the same   network where Streams servers are connected, the technique shown in this example can be put to use for sending email alerts.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/087_email_alerts_via_java_native_function_com_acme_test_EmailAlerts_spl",
	"urlLink": "",
	"tags": ["send email", "email", "send email java"]
}, {
	"State": "live",
	"name": "088_java_operator_params_and_multiple_input_output_ports",
	"description": "This example demonstrates two different features of the Java primitive operator framework. It first shows how operator parameters can be easily processed inside the Java operators via the @Parameter annotations. Then, it shows how multiple input and output ports can be accessed inside the Java operators. As a bonus, it also shows a better approach for on the fly creation of the output tuples made with complex nested types.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/088_java_operator_params_and_multiple_input_output_ports_com_acme_test_JavaOperatorParams_spl",
	"urlLink": "",
	"tags": [" complex tuple", "java operator", "java operator parameters", "java", "java operator", "multiple input ports", "create tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "089_integrating_streams_apps_with_web_apps",
	"description": "This example demonstrates one of the Streams open source toolkits (com.ibm.streamsx.inet). Using this toolkit one can integrate Streams applications with web applications. Please read the comments in the SPL file for this example project to download that toolkit, install it, and then use that toolkit inside a simple SPL application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/089_integrating_streams_apps_with_web_apps_com_acme_test_WebCalculator_spl",
	"urlLink": "",
	"tags": ["httptupleinjection", "httptupleview", "send tuples to browser", "rest", "post to streams app", "streams web app"]
}, {
	"State": "live",
	"name": "090_consistent_region_spl_01",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/090_consistent_region_spl_01_com_acme_test_ConsistentRegion1_spl",
	"urlLink": "",
	"tags": ["filesource"]
}, {
	"State": "live",
	"name": "091_consistent_region_spl_02",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a FileSource with a periodic checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/091_consistent_region_spl_02_com_acme_test_ConsistentRegion2_spl",
	"urlLink": "",
	"tags": ["beacon"]
}, {
	"State": "live",
	"name": "092_consistent_region_spl_03",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the Aggregate operators in this application is forcefully aborted inside the application multiple times to prove that application survive those multiple crashes at different times and yet will continue processing tuples normally after an automatic restart of that failed operator. In addition, during those crashes Streams will preserve the windows contents of that Aggregate operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/092_consistent_region_spl_03_com_acme_test_ConsistentRegion3_spl",
	"urlLink": "",
	"tags": ["aggregate", "consistent region window", "consistent region"]
}, {
	"State": "live",
	"name": "093_consistent_region_spl_04",
	"description": "This example demonstrates how a consistent region can be defined for two different composites acting as sources for this application. These consistent regions have a periodic checkpoint trigger. Couple of different Custom operators connected to those sources are forcefully aborted inside the application. Output streams of those operators will be combined using a Join operator. This application will ensure that the application will continue normally without losing any tuples by withstanding the random crash of those two Custom operators.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/093_consistent_region_spl_04_com_acme_test_ConsistentRegion4_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "094_consistent_region_spl_05",
	"description": "This particular example shows how only a portion of the topology will take part in the consistent region by having an autonomous section in the application graph. This example simulates the operator failure by aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Join operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration. At the same time, parts of the application that is in the autonomous area will get duplicate tuples during a crash recovery happening in the consistent region of this application graph. This example's purpose is to make the users aware of this fact. In the autonomous area, measures need to be taken to do deduplication.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/094_consistent_region_spl_05_com_acme_test_ConsistentRegion5_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "095_consistent_region_spl_06",
	"description": "This particular example shows how a non-replay capable Source operator will not be a show stopper when it comes to employing the consistent region feature in such applications. When using sources (such as TCPSource) that can't realistically replay data, there is way to configure your application with consistent region by using an utility operator called ReplaybleStart (shipped with the Streams product). In this example, we will use a topology that uses TCPSource along with ReplayableStart to achieve application-level fault tolerance.  This example simulates the operator failure by  aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Aggregate operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/095_consistent_region_spl_06_com_acme_test_ConsistentRegion6_spl",
	"urlLink": "",
	"tags": ["replayablestart", "enabling consistent regions when the source operator deos not support it", "failure", "crash", "high availability", "guaranteed processing", "replayablestart"]
}, {
	"State": "live",
	"name": "100_using_jmx_api_01",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to query information about the Streams domain and the Streams instance.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/100_using_jmx_api_01",
	"urlLink": "",
	"tags": ["jmx api", " jmx", " monitoring", "domains"]
}, {
	"State": "live",
	"name": "101_using_jmx_api_02",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to fetch the bulk contents from a log file for a given domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/101_using_jmx_api_02",
	"urlLink": "",
	"tags": ["jmx api", "monitoring", "get log file using jmx"]
}, {
	"State": "live",
	"name": "102_using_jmx_api_03",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX API notifications to get alerted via callback functions about an inactivity timeout in a given Streams domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/102_using_jmx_api_03",
	"urlLink": "",
	"tags": [" use jmx to get alerts", " monitoring", "jmx"]
}, {
	"State": "live",
	"name": "103_view_annotation_at_work",
	"description": "This is a simple SPL application that explains the steps required to use the view annotation and then how to visualize the view annotated stream in the Streams web console. Detailed steps to view the annotated stream are shown in the commentary section of this SPL file.",
	"language": ["SPL"],
	"category": ["Visualization and Reporting"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/103_view_annotation_at_work_com_acme_test_ViewAnnotationAtWork_spl",
	"urlLink": "",
	"tags": ["microsoft excel", "console", "view annotation", "views example", "reporting", "views", "visualization", "visualize", "application development"]
}, {
	"State": "live",
	"name": "901_cat_example",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/901_cat_example_NumberedCat_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "902_word_count",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/902_word_count_word_count_WordCount_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "903_unique",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/903_unique_Main_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "904_primitive_round_robin_split",
	"description": "SPL Introductory Tutorial sample",
	"language": ["C++"],
	"category": ["Beginner/General", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/904_primitive_round_robin_split_Main_spl",
	"urlLink": "",
	"tags": ["pair", "spl"]
}, {
	"State": "live",
	"name": "905_gate_load_balancer",
	"description": "SPL Introductory Tutorial sample\"",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/905_gate_load_balancer_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "gate", "improve performance", " gate operator", "threadedsplit", " threadedsplit operator", "gate"]
}
,{
	"State": "live",
	"name": "021_pair_at_work",
	"description": "This example shows off the Pair operator that is used for pairing tuples arriving on different input ports. Only when all the tuples arrive at all the input ports, this operator will emit them one after the other in their order of arrival.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/021_pair_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["pair", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "'096_consistent_region_spl_07",
	"description": "This particular example shows how a C++ primitive operator can play a role inside a consistent region.  It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/096_consistent_region_cpp_07_com_acme_test_ConsistentRegion7_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "097_consistent_region_spl_08",
	"description": "This particular example shows how a C++ primitive operator can be the start of a consistent region.   It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/097_consistent_region_cpp_08_com_acme_test_ConsistentRegion8_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "098_consistent_region_spl_09",
	"description": "This particular example shows how a Java primitive operator can be the start of a consistent region. ",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/098_consistent_region_java_09_com_acme_test_ConsistentRegion9_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "099_consistent_region_spl_10",
	"description": "This particular example shows how a Java primitive operator can play a role inside a consistent region. It demonstrates how to implement the necessary callback functions to support checkpoint and reset.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/099_consistent_region_java_10_com_acme_test_ConsistentRegion10_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "052_streams_to_python",
	"description": "This example shows a powerful feature of Streams to wrap existing code assets written using the Python programming language. This example teaches developers how to use the Streams C++ native functions to call any arbitrary Python function and return the results back to SPL code. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory. You can also read a very detailed IBM developerWorks technical article about this example:  http://tinyurl.com/c3s56fq. [THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED StreamsToPythonLib THAT IS DESCRIBED BELOW.]",
	"language": ["Python"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/052_streams_to_python_python_wrapper_example_streams_to_python_spl",
	"urlLink": "",
	"tags": ["call python from streams", "call python from cpp", " python"]
}, {
	"State": "live",
	"name": "042_dynamic_import_export_api_at_work",
	"description": "This example shows how to use the SPL APIs for dynamically importing and exporting streams. This is achieved by changing the import and export properties on the fly. This powerful feature in Streams provides a way to change the streams producing and consuming operators to change the way in which they publish and subscribe to streams while the application is running.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/042_dynamic_import_export_api_at_work_dynamic_importing_exporting_dynamic_import_spl",
	"urlLink": "",
	"tags": ["import", "export", "dynamic import", "microservices", "export stream", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "045_file_source_using_spl_custom_operator",
	"description": "This example shows how to create source operators using the Custom operator available in the SPL standard toolkit. Starting in Streams 3.x, it is possible to create source operators without writing primitive source operators in C++ or Java. Simple source operators can be written using the built-in SPL Custom operator. This will come handy for those who don't want to do an extra layer of C++ or Java code for satisfying simple needs for a source operator. You will see a function of a file source operator being implemented all using SPL code in this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions,Ingest & Store Data", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/045_file_source_using_spl_custom_operator_my_file_source_file_source_using_spl_custom_operator_spl",
	"urlLink": "",
	"tags": ["read a file using a custom", "custom", "read a file", "filesource", "open a file", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "032_native_function_at_work",
	"description": "This application shows how native functions written in C++ can be called within an SPL application.There are two ways in which native functions can be written in C++.1) Code for the C++ functions can be written in a C++ header file.2) C++ functions can be written outside of the SPL project and packaged into a shared library (.so) file. All the SPL developer will have to work with are an .so file and a C++ header file.This application demonstrates incorporating native functions built in both of those ways.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/032_native_function_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["native functions", " c++", "native functions", " native function model"]
}, {
	"State": "live",
	"name": "018_directory_scan_at_work",
	"description": "This example demonstrates one of the important features desired in the real world (mostly in the Retail banking and in the Telco industries). In many real-world scenarios, they still work via files and such files get dropped into a directory for processing. It is shown here how the DirectoryScan operator picks up a new file as soon as it appears inside an input directory. (Apply caution if huge files are copied to the watch directory. DirectoryScan may detect that big file copy as multiple new files and output multiple tuples with the same file name.)",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/018_directory_scan_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["directoryscan", "read directory repeatedly", "scan directory", "list directory"]
}, {
	"State": "live",
	"name": "011_compiler_intrinsic_functions",
	"description": "Streams compiler provides several intrinsic functions to query the SPL filename, file path, absolute path of the directory, source code line number, composite instance name etc. This example shows the use of the compiler intrinsic functions inside of a Functor operator.",
	"language": ["SPL"],
	"category": ["troubleshooting", " Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/011_compiler_intrinsic_functions_Main_spl",
	"urlLink": "",
	"tags": ["compiler functions", " utility", "print line number", " current line number", " print line number", " print file name", " get file name", " print debug info"]
}, {
	"State": "live",
	"name": "041_real_time_streams_merger",
	"description": "This example shows how two or more incoming streams with a common schema can be merged to flow in a sequence one after the other. This merger is done using a common tuple attribute in those multiple incoming streams as a key. We will use a C++ primitive operator called OrderedMerger that is included in this project. In order for the OrderedMerger to work correctly, it is assumed that multiple input streams for this primitive operator should already be in sorted order based on the key used to merge and sequence them together. ",
	"language": ["C++"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/041_real_time_streams_merger_real_time_merger_real_time_streams_merger_spl",
	"urlLink": "",
	"tags": ["ordered merge of multiple streams ", "c++ example", "merge  streams", " join streams", " c++ operator model", " application development", " ordered merge"]
}, {
	"State": "live",
	"name": "060_simple_pe_failover_technique_at_work",
	"description": "This example shows a way to protect the logic in an analytic operator  when its PE (Processing Element) or its host machine crashes. It uses a well-known fail-over technique that is done through a primary/secondary pair configured for an operator that will need safety from PE or machine crash. This example outlines a scheme for protecting the analytic logic written inside an SPL Custom operator against failures. When such failures occur, a specific fail-over technique employed here will continue the business logic without any interruption. This is done by making a secondary PE to takeover the tasks of the failed primary PE. Thus, the secondary PE does the detection of the primary PE's failure and then changes its role from a secondary PE to a new primary PE. All of this is done without losing any data during the fail-over. At the same time, the failed primary PE will be automatically restarted to do its work as a new secondary PE. This particular fail-over technique ensures that there is always a primary/secondary pair working in concert to provide high availability for a business-critical operator that is coded and configured in this manner.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/060_simple_pe_failover_technique_at_work_com_acme_failover_test_simple_pe_failover_technique_at_work_spl",
	"urlLink": "",
	"tags": ["recovery", " fail over", " crash", "redundancy"]
}, {
	"State": "live",
	"name": "030_spl_config_at_work",
	"description": "This example introduces one of the must-learn features of the SPL language. SPL language offers an extensive list of options to do configuration at the operator level as well as at the composite level. This application attempts to sprinkle many of the available configuration parameters as shown below.a) host,b) hostColocation,c) partitionColocation,d) placement,e) threadedPort and queue,f) relocatable and many more.In addition, this example shows how to make this application toolkit dependent on another (025_dynamic_filter_at_work) SPL toolkit project.",
	"language": ["SPL"],
	"category": ["Tips", "Configuration", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/030_spl_config_at_work_my_sample3_Main_spl",
	"urlLink": "",
	"tags": ["spl config clause", "spl", "concurrency", " threading", "operator fusion", "threading", "host exlocation", "job submission", "load balancing", "host colocation", " spl config clause", "threaded port", "resource allocation", "application deployment"]
}, {
	"State": "live",
	"name": "048_source_operator_with_control_port",
	"description": "This example shows a way to create a C++ primitive source operator and then provide a control input port for it. Certain classes of applications can make use of this facility to control the kind of data a source operator generates. In addition, this example shows how to pass one or more string literals to the C++ primitive operator as invocation time parameters. As a bonus, this example also shows a simple way to do performance measurement inside the SPL code using the built-in SPL high precision timestamp functions.",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/048_source_operator_with_control_port_source_op_with_control_port_source_operator_with_control_port_spl",
	"urlLink": "",
	"tags": ["customized source operator in c++", " control port", "custom", "read a file", "filesource", "open a file", "c++ primitive operator", " custom source operator", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "055_json_to_tuple_to_json_using_c++",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished using an open source C++ JSON API. In order to run this application, you will be required to download an open source component that carries a BSD license. Please read the detailed instructions available in the SPL file for this project. There is also another SPL project that does similar conversion using Java (049_json_to_tuple_to_json_using_java).",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "ttp://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/055_json_to_tuple_to_json_using_c++_com_acme_test_json_to_tuple_to_json_using_cpp_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "parse json from c++", "jsontotuple", "c++ native function"]
}, {
	"State": "live",
	"name": "029_spl_functions_at_work",
	"description": "This example shows how helper and utility functions can be written using the SPL language. It also shows how such SPL functions can be put to use inside the context of an application. Learning this simple concept will go a long way in doing a lot of neat stuff in real-world applications.",
	"language": ["SPL"],
	"category": [" Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/029_spl_functions_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "007_split_at_work",
	"description": "This example shows how a Split operator can be used to split the incoming tuples based on a key. In this example, the split condition (which tuples comes out on which port) is pre configured through a text file. Alternatively, one can compute the index of the output port on the fly inside the Split operator parameter section.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/007_split_at_work_sample_split_at_work_spl",
	"urlLink": "",
	"tags": ["split", "split", " split stream", " divide stream"]
}, {
	"State": "live",
	"name": "028_multiple_composites_at_work",
	"description": "This example shows the use of multiple composites in a single application. There is a main composite that in turn uses two other composites. This application shows how the additional composites in different namespaces get included into the main composite via the 'use' directive. It also demonstrates how the additional composites can accept their own operator parameters. It teaches the basics of an important feature that will come handy when big applications need to be componentized. ",
	"language": ["SPL"],
	"category": ["Best Practices", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/028_multiple_composites_at_work_my_sample1_Main_spl",
	"urlLink": "",
	"tags": ["multiple composites", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "024_threaded_split_at_work",
	"description": "This example demonstrates an important standard toolkit operator named ThreadedSplit. It is a multi-threaded split that is different from the other content-based Split operator. ThreadedSplit uses its own algorithm to split the incoming tuples to the available output ports to improve concurrency. This will speed up the distribution of tuples by using individual threads assigned to each of the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "performance"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/024_threaded_split_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "split stream", "threaded split"]
}, {
	"State": "live",
	"name": "057_reading_nested_tuple_data_via_file_source",
	"description": "This example shows how to ingest nested tuple data via input files specified in a CSV format. There are certain syntactical rules that need to be followed in specifying data for nested tuples inside a CSV formatted input file. This example is a good one for developers to get an idea about how to do this.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/057_reading_nested_tuple_data_via_file_source_com_acme_test_Test1_spl",
	"urlLink": "",
	"tags": ["filesource", "parse", " nested tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "016_aggregate_at_work",
	"description": "This example shows off yet another powerful standard toolkit operator named the Aggregate. It is very good in computing on the fly aggregate values after collecting a set of tuples. Tuples are grouped based on tumbling and sliding windows with partitioned variants. This example also shows how to use the built-in assignment functions provided by this operator to compute regular statistical calculations such as min, max, average, standard deviation etc.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/016_aggregate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["aggregate", "aggregate", "rolling average", "windowing", "average", "window"]
}, {
	"State": "live",
	"name": "020_metrics_sink_at_work",
	"description": "This example shows how one can use the MetricsSink standard toolkit operator to create application-specific custom metrics that can be viewed in real-time when the application is running. Viewing of custom metrics is typically done inside Streams Explorer view of the Streams Studio or by using the capturestate option in streamtool.",
	"language": ["SPL"],
	"category": ["Monitoring", "metrics"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/020_metrics_sink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["metricssink", "metrics", "custom metrics", "application monitoring", "custom statistics"]
}, {
	"State": "live",
	"name": "002_source_sink_at_work",
	"description": "This example shows how a FileSource operator can be used to read CSV formatted records from a file and then receive those tuples in a FileSink to be written to a file in the data directory of this application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/002_source_sink_at_work_sample_source_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", " ", "filesink"]
}, {
	"State": "live",
	"name": "026_gate_at_work",
	"description": "This is an example that uses the Gate operator from the standard toolkit. This operator delays the incoming tuples until a downstream operator signals with an acknowledgment to receive any further tuples. This is a great way to have a feedback through which we can control the rate at which tuples are passed through. (Please refer to another example named 905_gate_load_balancer that shows the effectiveness of the Gate operator in combination with the ThreadedSplit operator to provide load balancing the incoming tuples.)",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/026_gate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["gate", "wait", " hold tuples until signal", "control tuple flow", "wait for tuples"]
}, {
	"State": "live",
	"name": "050_recursive_dir_scan",
	"description": "This example shows how to use the Streams C++ native function facility to recursively scan a given directory and obtain the names of the files present. The logic for the recursive directory scan polls the specified directory periodically and notifies the downstream operator with a new file that just appeared. There is a companion C++ project for this SPL project. Please refer to the RecursiveDirScanLib project for the C++ logic.Important sequence of logic for this application: 1) SPL code resolves the C++ native function in its native.function/function.xml file.2) A call from the SPL code to the native function lands in the wrapper inline C++ function defined in the RecursiveDirScanWrappers.h file of the companion C++ project.3) From that wrapper function, it gets access to a singleton C++ object of the RecursiveDirScan class and then invokes the getFileNamesInDirectory C++ method.4) When that C++ method returns, it will have the results stored in a list<string> reference that was passed to it.5) Back in the SPL code, there is additional logic to cache the already seen files and to filter only the newly found files to send to the downstream operator.In order to test this application, please refer to the commentary at the top of the SPL file in this project.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED RecursiveDirScanLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/050_recursive_dir_scan_recursive_dir_scan_recursive_dir_scan_spl",
	"urlLink": "",
	"tags": ["recursive directory scan in c++", "c++ native functions example", "c++", "application development"]
}, {
	"State": "live",
	"name": "005_throttle_at_work",
	"description": "This example shows how a stream can be throttled to flow at a specified rate. This example also mixes other operators such as Beacon, Custom, and FileSink.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/005_throttle_at_work_sample_throttle_at_work_spl",
	"urlLink": "",
	"tags": ["custom", " throttle", " slow down", "delay", " create tuple", " custom", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "004_delay_at_work",
	"description": "This example shows how a Delay standard toolkit operator can be used to delay a stream. This example also introduces the Custom operator that can be used to perform custom logic. You can also notice the use of a state variable that is mutable inside the Custom operator. It also shows how to create a new tuple on the fly and do your own submissions onto the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/004_delay_at_work_sample_delay_at_work_spl",
	"urlLink": "",
	"tags": ["custom", "delay", "filesink"]
}, {
	"State": "live",
	"name": "019_import_export_at_work",
	"description": "This example demonstrates how two different SPL applications can share streams between them. This is an important feature that is elegantly done using two pseudo operators called Export and Import. This application also shows how two different main composites can be part of the same application by using two different namespaces. As an aside, there is also a demonstration of using a Custom operator to customize the Beacon generated tuples by involving state variables. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/019_import_export_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["import", "export", "microservices", "export stream", "import stream"]
}, {
	"State": "live",
	"name": "033_java_primitive_operator_at_work",
	"description": "This example shows how a Java primitive operator is created from scratch. Java primitive operator is different from JavaOp that you have seen earlier in a different example. Java primitive operator is a first class operator in SPL, whereas JavaOp only permits a callout to another Java operator. In addition, Java primitive operator has the advantage of keeping its name as the operator\u2019s runtime instance name.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT NAMED RSS_Reader_Primitive THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/033_java_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["java operator", " primitive java operator", "java operators", " application development"]
}, {
	"State": "live",
	"name": "043_import_export_filter_at_work",
	"description": "This example shows how to use the SPL feature to apply a filter for what gets exported and what gets imported. This powerful feature lets the downstream import operators to specify what kind of tuples they want to receive by specifying conditional expressions involving tuple attributes. That lets the Streams runtime to apply content-based filtering at the point of export. Those who need such a feature to control what information should be sent downstream based on the tuple contents can make use of this flexible feature. This can be done on the fly without stopping and restarting the application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/043_import_export_filter_at_work_importing_exporting_filter_import_with_filter_spl",
	"urlLink": "",
	"tags": ["import", "export", "filtered import", "dynamic import", "microservices", "export stream", " filter imports", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "017_filesource_filesink_at_work",
	"description": "We have used the FileSource and the FileSink operators in other examples before. However, this example shows off the following intriguing features that will become handy in a lot of practical situations.a) Automatic deletion of a file after the FileSource finishes reading all the records.b) Flushing the sink file on demand after writing a certain number of tuples.c) Ability of the FileSource to move the file once it reads all the content in that file.d) Creating a fresh and new output sink file after writing a certain number of tuples.e) Ability of the FileSource to keep reading from a hot file as new CSV records get written to the end of that file.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/017_filesource_filesink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "advanced file operations", " reread file", "move file", " hot file", "flushing", " automatic deletion", "delete a file"]
}, {
	"State": "live",
	"name": "008_get_submission_time_value",
	"description": "This example shows how the tuple attributes can be assigned values that were supplied by the user at the application/job submission time. It employs the getSubmissionTimeValue function to obtain different values made of different SPL data types. ",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/008_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["functor", "getsubmissiontimevalue", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "014_sort_at_work",
	"description": "This example shows the use of the Sort operator in the context of an application. Sort operator is highly configurable with all kinds of windowing support. In this example, the following window configurations are applied for sorting the incoming tuples:a) Count-based tumbling window.b) Time-based tumbling window.c) Punctuation-based tumbling window.d) Delta-based tumbling window.e) Count-based sliding window.",
	"language": ["SPL"],
	"category": ["transform", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/014_sort_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["sort", " Time-based", " delta based", "time based", " punctuation-based Count based", "sort", " tumbling window", " sliding window", " punctuation based", " sort with windowing", " count-based"]
}, {
	"State": "live",
	"name": "027_java_op_at_work",
	"description": "This example shows an important operator that brings Java into the C++ dominated world of Streams!!! That operator is called JavaOp, which is used to call out to other operators implemented in Java using the Java Operator API. In this example, we will have a tiny Java logic that will calculate the current time and add that time string to a tuple attribute and output that tuple. There is another example that shows the Java primitive operator that is different from the JavaOp operator.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/027_java_op_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in and C++ primitive operators that are NOT fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["dps", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "dps", "c++", "share data"]
}, {
	"State": "live",
	"name": "053_java_primitive_operator_with_complex_output_tuple_types",
	"description": "This example shows important features that can be done via a Java primitive operator. It shows how to do tracing and logging inside a Java operator. It also shows how we can create an output tuple inside a Java primitive operator to have a list of tuple objects carrying complex typed attributes.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT CALLED Java_Complex_Tuple_Type_Submission THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/053_java_primitive_operator_with_complex_output_tuple_types_com_acme_test_java_primitive_operator_with_complex_output_tuple_types_spl",
	"urlLink": "",
	"tags": [" submit tuple from java", "tuple in java operator", "tuple", "complex tuple", " java operator"]
}, {
	"State": "live",
	"name": "035_c++_primitive_operator_at_work",
	"description": "This example shows the steps required to create a C++ primitive operator from scratch. In this application, a C++ primitive operator model XML file can be explored to learn how the different fields in that file are configured. Then, the code generation template header and implementation files (*_h.cgt and *_cpp.cgt) can be browsed to learn about the primitive operator logic. Additionally, this example demonstrates about including a Java operator and a C++ primitive operator as part of the application flow.",
	"language": ["C++"],
	"category": ["Operators & Functions", " Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/035_c++_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["c++ operators", "c++ example", "c++ operator model", " application development"]
}, {
	"State": "live",
	"name": "037_odbc_adapters_for_solid_db_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters for connecting to a SolidDB in-memory database. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test SolidDB database inside IBM. You have to create your own SolidDB database and tables to make this application work in your environment.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/037_odbc_adapters_for_solid_db_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "soliddb"]
}, {
	"State": "live",
	"name": "061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators that are not fused with each other and a C++ native function. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "hsa", "java", "native function", "db", "query"]
}, {
	"State": "live",
	"name": "006_barrier_at_work",
	"description": "This example shows how to synchronize the incoming tuples using a Barrier operator. It uses a bank deposit/debit scenario to split the deposit/debit requests, perform that account activity, and then combine the post-activity result with the incoming requests. Barrier operator does what is needed to accomplish that i.e. it waits for the streams to arrive at all the configured input ports before emitting an output tuple.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/006_barrier_at_work_sample_barrier_at_work_spl",
	"urlLink": "",
	"tags": ["barrier", "functor", "custom", " slow down stream", "delay", "create tuple", "slow down tuples", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "015_join_at_work",
	"description": "This example shows one of the power-packed standard toolkit operators; i.e. Join. This operator is so versatile that it is hard to do justice in explaining it thoroughly in a simple example such as this one.  This example provides coverage to the following Join operator features.a) Inner Join,b) Inner (Equi) Join,c) Left Outer Join,d) Right Outer Join,e) Full Outer Join",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/015_join_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["join", " inner join", "merge stream", "join", " join stream"]
}, {
	"State": "live",
	"name": "031_spl_mixed_mode_at_work",
	"description": "This example shows a cool SPL feature called mixed-mode support. In this, developers can mix PERL code islands inside of an SPL application. Mixed-mode enables the easy parameterization of SPL applications. This example gives a slight flavor of how a PERL code snippet inter-mixed with SPL allows us to parameterize the SPL Stream names and the number of output stream definitions for an SPL operator. ",
	"language": ["perl"],
	"category": ["Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/031_spl_mixed_mode_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["mixed mode", "spl", "mixed mode", "code generation"]
}, {
	"State": "live",
	"name": "047_streams_host_tags_at_work",
	"description": "This example shows how to create host tags for a given Streams instance and then use those host tags inside an SPL application. By using host tags, it is possible to avoid hard-coding the host names inside the SPL application code. Detailed instructions about creating and using host tags are explained in this example.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/047_streams_host_tags_at_work_host_tags_streams_host_tags_at_work_spl",
	"urlLink": "",
	"tags": ["tcpsink", "tcpsource", "host tags", "operator placement", "tcpsink", "tcpsource", "config clause", "host pools"]
}, {
	"State": "live",
	"name": "049_json_to_tuple_to_json_using_java",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished via two Java primitive operators that make use of the JSON (Java) libraries shipped as part of the Streams product. Those two Java operators are JSONToTuple and TupleToJSON.Note: Performance of the JSON<-->Tuple conversion in this example will be limited by the speed of your Java environment. If you want to get better performance, C++ code would help. There is a separate example (055_json_to_tuple_to_json_using_c++) that shows how to do this conversion using C++.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/049_json_to_tuple_to_json_using_java_sample_Main_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "json", " parse json"]
}, {
	"State": "live",
	"name": "046_launching_external_apps_in_spl",
	"description": "This example shows how to launch/execute an external application within the Streams SPL code. In this case, we defined a simple C++ native function in which we have the required C++ code to launch an external application. That C++ code uses pipes to execute a given application. This function would be useful to launch any custom script within the Streams application logic when certain application specific conditions arise.",
	"language": ["C++"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/046_launching_external_apps_in_spl_launch_external_apps_launching_external_apps_spl",
	"urlLink": "",
	"tags": ["launch an external app", " spl utility functions", "launch a program", "execute program"]
}, {
	"State": "live",
	"name": "059_dynamic_scaleout_of_streams_application",
	"description": "This example shows a particular style of writing Streams applications that can be scaled up or scaled down as the application input workload changes. It uses a familiar scenario from the Financial Services Sector, where the price calculation engines will require scaling up when the market data load increases. Code written in this example uses a pattern for starting more instances of an analytic operator to increase parallelism. New instances of such analytic operators can be started on demand without disrupting the already running application flow. As soon as the newly started operator instances are ready, application load will be promptly distributed across the existing and the newly started instances of that operator. In the same way, when the application data load is not high, some of the most recently started operator instances can be stopped to release the CPU cores for other use. This technique is one of many ways to design Streams applications that will scale up and down dynamically according to the changing input data workload.",
	"language": ["C++"],
	"category": ["Tips,Best Practices,Microservices,Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/059_dynamic_scaleout_of_streams_application_com_ibm_streams_pricing_test_DynamicScaleOut_spl",
	"urlLink": "",
	"tags": ["import", "export", "ingest"]
}, {
	"State": "live",
	"name": "009_custom_operator_using_get_submission_time_value",
	"description": "This example demonstrates how to assign tuple attributes at the time of job submission inside a custom operator. When the incoming tuples arrive at the Custom operator in this example, values entered by the user at the application startup are assigned to the tuple attributes.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/009_custom_operator_using_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["custom", "getsubmissiontimevalue", "get submission time value", " submission time", "parameter lists", " parameters", " custom", "create tuple"]
}, {
	"State": "live",
	"name": "012_filter_functor_at_work",
	"description": "This example puts the two commonly used standard toolkit operators to work. They are Filter and Functor. Filter allows you to route tuples based on conditional checks. It provides two output ports to send the matched tuples on the first output port and the unmatched tuples on the second output port. Functor operator allows us to transform the incoming tuple attributes and then to send it on many different output ports with different stream schemas.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/012_filter_functor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["functor", "filter", "filter tuples", "remove tuples"]
}, {
	"State": "live",
	"name": "022_deduplicate_at_work",
	"description": "This example describes the use of an important operator that is highly applicable in many Telco scenarios. That operator is called DeDuplicate, which eliminates duplicate tuples for a specified duration of time. It also has an optional second output port on which duplicate tuples could be sent out for additional processing.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/022_deduplicate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["deduplicate", "separate two streams", "remove duplicates", "split streams"]
}, {
	"State": "live",
	"name": "013_punctor_at_work",
	"description": "This example shows how a Punctor operator could be used in an application. Punctor operator allows us to transform the input tuples and then inject puncuation markers either before or after the output tuple as configured.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/013_punctor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["punctor", "custom logic", " generate punctuation", " punctuation"]
}, {
	"State": "live",
	"name": "036_shared_lib_primitive_operator_at_work",
	"description": "This example demonstrates two important techniques that will be commonly used in real-world use cases.1) Creating a C++ primitive operator.2) Calling a function available inside a .so shared library from the C++ primitive operator logic.Application logic here is to receive input tuples as hostnames and then make the C++ primitive operator logic invoke a shared library function that does a name server lookup.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED PrimitiveOperatorLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/036_shared_lib_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" c++", " operator dependencies", " library", "shared library", " application development"]
}, {
	"State": "live",
	"name": "003_sink_at_work",
	"description": "This example shows how FileSink and Custom sinks can be employed in applications. It also shows how a Beacon operator can be used to customize tuple attributes. In addition, it introduces the Filter operator to route the incoming tuples by inspecting their attributes using a conditional statement specified in the filter parameter. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/003_sink_at_work_sample_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "read", "files", "write"]
}, {
	"State": "live",
	"name": "023_union_at_work",
	"description": "This example demonstrates an utility operator called Union. This operator combines all the tuples from several input ports as they arrive and emits a single output stream. All the input ports must have a schema that contains attributes of the same name and type as those of the output port. The order of the attributes in the input ports need not match the order in the output port.",
	"language": ["SPL"],
	"category": ["enrich", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/023_union_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["union", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "044_streams_checkpointing_at_work",
	"description": "This example shows a key feature of Streams by which an operator's state variables can be preserved when a PE fails and gets restarted. This is done through a combination of the SPL configuration directives named 'checkpointing' and 'restartable'. Developers can protect their critical operator data by taking advantage of this built-in checkpointing feature. When you run this example, you will see data flows without any gaps or interruption, when a PE is killed manually and then gets restored automatically by the Streams runtime.",
	"language": ["SPL"],
	"category": ["performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/044_streams_checkpointing_at_work_checkpointing_example_streams_checkpointing_at_work_spl",
	"urlLink": "",
	"tags": ["checkpoint config clause", " data consistency", "automatic checkpointing", " fail over", "checkpoint"]
}, {
	"State": "live",
	"name": "001_hello_world_in_spl",
	"description": "This example is the simplest possible SPL application. It uses a Beacon operator to generate tuples that carry Hello World' messages. A custom sink operator receives the tuples from Beacon and displays it on the console.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/001_hello_world_in_spl_HelloWorld_spl",
	"urlLink": "",
	"tags": ["custom"]
}, {
	"State": "live",
	"name": "038_spl_built_in_functions_at_work",
	"description": "This is a very simple example that showcases a random collection of powerful built-in SPL functions that are available out of the box. This application demonstrates how time, math, and collection type functions can be used inside of an SPL application.",
	"language": ["SPL"],
	"category": ["Best Practices", "Collections and Data Types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/038_spl_built_in_functions_at_work_test_scratch_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "data types", " spl functions", "list", " mutable", " convert time stamp", "map", " convert timestamp", " timestamps", " utility functions"]
}, {
	"State": "live",
	"name": "056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example shows a particular implementation about how data can be shared across multiple FUSED operators using an SPL map based in-memory store. Here, we are simply showing a way to use the SPL native function facility to perform data sharing via an SPL map based in-memory store that will serve multiple SPL standard toolkit operators and C++ primitive operators. As mentioned above, this example shows data sharing between multiple operators that are fused inside a single PE (Processing Element). This technical approach is called Process Store (ps). This data sharing mechanism will NOT work between operators that are on different PEs. This example depends on the com.ibm.streamsx.ps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "db", "query"]
}, {
	"State": "live",
	"name": "034_odbc_adapters_for_db2_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test DB2 database inside IBM. You have to create your own DB2 database and tables to make this application work in your environment. After creating your own database and tables, you have to change the etc/connections.xml file in this application's directory to match your database/table names, userid, and password. You also have to make changes in the SPL code using your database information for all the three ODBC operator invocations.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/034_odbc_adapters_for_db2_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "db2"]
}, {
	"State": "live",
	"name": "051_native_functions_with_collection_types",
	"description": "This example shows an important feature of Streams. In Streams applications, it may be necessary to accept and return collection types in and out of the C++ native functions. This will require native function code that can directly deal with types such as list, map, and tuple. Streams provides C++ reflection APIs to directly deal with such collection types. In this example, developers can learn how to build native functions inside of a C++ class and then pass list, map, and tuple types to those native functions. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionsWithCollectionTypesLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/051_native_functions_with_collection_types_com_ibm_nf_test_native_functions_with_collection_types_spl",
	"urlLink": "",
	"tags": [" data types", "native functions", "collections", "list", "c++ native functions example", "c++", "map", " collections", "application development", "tuple"]
}, {
	"State": "live",
	"name": "040_ingest_data_generation_in_spl",
	"description": "This example shows how SPL provides rich features to generate synthetic data required for large scale testing. Many real-life applications in the Telco and the Retail Banking sectors consume large amounts of daily business data through CSV formatted text files. There could be huge amounts of CDR data from several telecom circles or daily transaction data for millions of accounts in a retail bank.While building and testing the SPL applications, it will become necessary to generate such ingest data files with artificial data that is close enough to be realistic. This application shows how such large amounts of data in several thousands of files can be created very quickly using the SPL standard toolkit operators as well as the SPL file IO and math random built-in functions.",
	"language": ["SPL"],
	"category": ["Collections & Data types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/040_ingest_data_generation_in_spl_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["test data generation", "data types", " test data generation", "sample data", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "025_dynamic_filter_at_work",
	"description": "This example deals with an interesting standard toolkit operator called DynamicFilter. This operator is a special version of the Filter operator that you have already seen in another example; it decides at runtime which input tuples will be passed through, based on the control input it receives. This operator is applicable in many real-life scenarios. This example also demonstrates using a second composite operator to perform a sub-task that the main composite will make use of. There is also coverage to show how the second composite can take its own operator parameters.  ",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/025_dynamic_filter_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["dynamicfilter", " reusable composite", "composite operators", " filter based on input", " dynamic filter", "filter"]
}, {
	"State": "live",
	"name": "062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators and a Java primitive operator that are not fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples. In this SPL project, you will find a Java primitive operator that exercises all the dps APIs in a very comprehensive manner. In order to get access to the dps APIs, this project's build path is added with dps-helper.jar available inside the com.ibm.streamsx.dps toolkit directory (i.e. impl/java/bin). Please read at the top of this project's SPL file and the TickerIdGenerator.java primitive operator file for an extensive commentary about how to run this example.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["java database", "database", "redis", "hsa", "java", "mongo", "db", "query"]
}, {
	"State": "live",
	"name": "063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators",
	"description": "This example shows how to create a tuple on the fly inside a Java primitive operator. In addition, this example also shows how to convert a tuple into a blob (Java byte buffer) and how to convert a blob (Java byte buffer) in to a tuple. It is an interesting concept that a Java primitive operator developer can put into use in certain situations that warrant dynamic tuple creation, tuple encoding and decoding all inside Java.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators_application_Main_spl",
	"urlLink": "",
	"tags": ["create tuple in java", "java", "blob", "blob java", "create tuple"]
}, {
	"State": "live",
	"name": "064_using_spl_composite_params",
	"description": "This example shows different ways in which parameters can be passed to SPL composites. It is very useful to pass parameters as attributes, expressions, functions, operators, and types. These different ways of passing parameters to the composites is the focus of this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/064_using_spl_composite_params_com_acme_test_CompositeParams_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "065_using_multiple_threads_in_java_operator",
	"description": "This example shows how to spawn multiple threads within a Java primitive operator and then submit tuples from within those threads concurrently.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/065_using_multiple_threads_in_java_operator_com_acme_test_JavaOpSubmitFromMultipleThreads_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "066_load_balancing_using_gate",
	"description": "As documented in the Streams Info Center for a ThreadedSplit, if the processing time of a tuple varies considerably depending on the tuple data, it may cause problems where a tuple with a long processing time may cause subsequent tuples to be backed up in the stream. This example shows how a Gate operator can be combined with the ThreadedSplit can be used to ensure load balancing.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/066_load_balancing_using_gate_com_acme_test_LoadBalancingUsingGate_spl",
	"urlLink": "",
	"tags": ["gate"]
}, {
	"State": "live",
	"name": "067_simple_java_source_operator",
	"description": "This example shows a basic source operator implemented in Java. There are specific steps required for implementing a source operator and it can be learned in this example.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/067_simple_java_source_operator_com_acme_test_Temp1_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "068_tuple_introspection_inside_java_operator",
	"description": "This example shows how a tuple can be introspected to learn about its structure and its attribute names and their types. Inside a Java operator, this example illustrates how it is possible to recursively look through a tuple to understand its composition.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/068_tuple_introspection_inside_java_operator_com_acme_test_Temp2_spl",
	"urlLink": "",
	"tags": ["parse tuple in java", "tuples", " collections", "tuples java", " java operator", "spl data types"]
}, {
	"State": "live",
	"name": "069_changing_map_value_during_iteration",
	"description": "Until the release of Streams version 3.2.1, it was not possible to modify the value of a map inside an iteration loop. This example shows a new feature available in Streams version 3.2.1 that permits the value of a map to be modified inside a for loop.",
	"language": ["SPL"],
	"category": ["Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/069_changing_map_value_during_iteration_com_acme_test_ChangeCollectionValue_spl",
	"urlLink": "",
	"tags": ["iterate over map", "iteration", "change map value", "change map"]
}, {
	"State": "live",
	"name": "070_convert_block_data_into_tuples_using_parse",
	"description": "This example shows how a block of data ingested as a blob type can be converted into individual tuples using the Parse operator.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/070_convert_block_data_into_tuples_using_parse_com_acme_test_ConvertBlockDataWithParse_spl",
	"urlLink": "",
	"tags": ["parse", "parse operator", "parse blob", " convert blob to tuple", "tuples"]
}, {
	"State": "live",
	"name": "071_java_native_functions",
	"description": "Java native functions provide a cool way to add user-defined functions in Java and then call them directly within the SPL code. This example shows how easy it is to create java native functions.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/071_java_native_functions_com_acme_test_JavaNativeFunctions_spl",
	"urlLink": "",
	"tags": ["create java native function", "java function"]
}, {
	"State": "live",
	"name": "072_using_streams_rest_apis",
	"description": "Streams provides REST APIs to query different kinds of metrics about the instances, jobs, resources during the runtime operation. It is a comprehensive set of APIs that can be used with proper security configuration. This example shows a few different REST APIs in action by invoking them within Java code.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/072_using_streams_rest_apis_com_acme_test_UsingStreamsRestApis_spl",
	"urlLink": "",
	"tags": ["get job info", "monitoring", "rest", "rest api example", "jobs"]
}, {
	"State": "live",
	"name": "073_java_operator_fusion",
	"description": "This example shows how two different Java operators one performing the Sink operation and the other performing the analytics operation can be fused to operate within a single PE.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/073_java_operator_fusion_com_acme_test_JavaFusion_spl",
	"urlLink": "",
	"tags": ["java operator fusion", " ", "fuse multiple operators"]
}, {
	"State": "live",
	"name": "074_user_defined_parallelism_01",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/074_user_defined_parallelism_01_com_acme_test_UDP1_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "075_user_defined_parallelism_02",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/075_user_defined_parallelism_02_com_acme_test_UDP2_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "076_user_defined_parallelism_03",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/076_user_defined_parallelism_03_com_acme_test_UDP3_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "077_user_defined_parallelism_04",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/077_user_defined_parallelism_04_com_acme_test_UDP4_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "078_user_defined_parallelism_05",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/078_user_defined_parallelism_05_com_acme_test_UDP5_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "079_user_defined_parallelism_06",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/079_user_defined_parallelism_06_com_acme_test_UDP6_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "080_user_defined_parallelism_07",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/080_user_defined_parallelism_07_com_acme_test_UDP7_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "081_user_defined_parallelism_08",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/081_user_defined_parallelism_08_com_acme_test_UDP8_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "083_user_defined_parallelism_10",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/083_user_defined_parallelism_10_com_acme_test_UDP10_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "084_user_defined_parallelism_11",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/084_user_defined_parallelism_11_com_acme_test_UDP11_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "085_user_defined_parallelism_12",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/085_user_defined_parallelism_12_com_acme_test_UDP12_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "086_jms_source_sink_using_activemq",
	"description": "This example shows how the JMSSource and JMSSink operators from the Streams standard toolkit can be put to use for sending messages from Streams into the Apache ActiveMQ queues and topics as well as reading messages from there into Streams.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/086_jms_source_sink_using_activemq_com_acme_test_JMSSourceSink_spl",
	"urlLink": "",
	"tags": ["jmssource", "jmssink", "activemq", "jms", "read from activemq", "messaging server", "messaging"]
}, {
	"State": "live",
	"name": "087_email_alerts_via_java_native_function",
	"description": "This example shows a way to send email alerts from an SPL application. It is done via a Java native function by using the email API available in the standard Java platform. If an SMTP server is present in the same   network where Streams servers are connected, the technique shown in this example can be put to use for sending email alerts.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/087_email_alerts_via_java_native_function_com_acme_test_EmailAlerts_spl",
	"urlLink": "",
	"tags": ["send email", "email", "send email java"]
}, {
	"State": "live",
	"name": "088_java_operator_params_and_multiple_input_output_ports",
	"description": "This example demonstrates two different features of the Java primitive operator framework. It first shows how operator parameters can be easily processed inside the Java operators via the @Parameter annotations. Then, it shows how multiple input and output ports can be accessed inside the Java operators. As a bonus, it also shows a better approach for on the fly creation of the output tuples made with complex nested types.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/088_java_operator_params_and_multiple_input_output_ports_com_acme_test_JavaOperatorParams_spl",
	"urlLink": "",
	"tags": [" complex tuple", "java operator", "java operator parameters", "java", "java operator", "multiple input ports", "create tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "089_integrating_streams_apps_with_web_apps",
	"description": "This example demonstrates one of the Streams open source toolkits (com.ibm.streamsx.inet). Using this toolkit one can integrate Streams applications with web applications. Please read the comments in the SPL file for this example project to download that toolkit, install it, and then use that toolkit inside a simple SPL application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/089_integrating_streams_apps_with_web_apps_com_acme_test_WebCalculator_spl",
	"urlLink": "",
	"tags": ["httptupleinjection", "httptupleview", "send tuples to browser", "rest", "post to streams app", "streams web app"]
}, {
	"State": "live",
	"name": "090_consistent_region_spl_01",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/090_consistent_region_spl_01_com_acme_test_ConsistentRegion1_spl",
	"urlLink": "",
	"tags": ["filesource"]
}, {
	"State": "live",
	"name": "091_consistent_region_spl_02",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a FileSource with a periodic checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/091_consistent_region_spl_02_com_acme_test_ConsistentRegion2_spl",
	"urlLink": "",
	"tags": ["beacon"]
}, {
	"State": "live",
	"name": "092_consistent_region_spl_03",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the Aggregate operators in this application is forcefully aborted inside the application multiple times to prove that application survive those multiple crashes at different times and yet will continue processing tuples normally after an automatic restart of that failed operator. In addition, during those crashes Streams will preserve the windows contents of that Aggregate operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/092_consistent_region_spl_03_com_acme_test_ConsistentRegion3_spl",
	"urlLink": "",
	"tags": ["aggregate", "consistent region window", "consistent region"]
}, {
	"State": "live",
	"name": "093_consistent_region_spl_04",
	"description": "This example demonstrates how a consistent region can be defined for two different composites acting as sources for this application. These consistent regions have a periodic checkpoint trigger. Couple of different Custom operators connected to those sources are forcefully aborted inside the application. Output streams of those operators will be combined using a Join operator. This application will ensure that the application will continue normally without losing any tuples by withstanding the random crash of those two Custom operators.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/093_consistent_region_spl_04_com_acme_test_ConsistentRegion4_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "094_consistent_region_spl_05",
	"description": "This particular example shows how only a portion of the topology will take part in the consistent region by having an autonomous section in the application graph. This example simulates the operator failure by aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Join operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration. At the same time, parts of the application that is in the autonomous area will get duplicate tuples during a crash recovery happening in the consistent region of this application graph. This example's purpose is to make the users aware of this fact. In the autonomous area, measures need to be taken to do deduplication.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/094_consistent_region_spl_05_com_acme_test_ConsistentRegion5_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "095_consistent_region_spl_06",
	"description": "This particular example shows how a non-replay capable Source operator will not be a show stopper when it comes to employing the consistent region feature in such applications. When using sources (such as TCPSource) that can't realistically replay data, there is way to configure your application with consistent region by using an utility operator called ReplaybleStart (shipped with the Streams product). In this example, we will use a topology that uses TCPSource along with ReplayableStart to achieve application-level fault tolerance.  This example simulates the operator failure by  aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Aggregate operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/095_consistent_region_spl_06_com_acme_test_ConsistentRegion6_spl",
	"urlLink": "",
	"tags": ["replayablestart", "enabling consistent regions when the source operator deos not support it", "failure", "crash", "high availability", "guaranteed processing", "replayablestart"]
}, {
	"State": "live",
	"name": "100_using_jmx_api_01",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to query information about the Streams domain and the Streams instance.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/100_using_jmx_api_01",
	"urlLink": "",
	"tags": ["jmx api", " jmx", " monitoring", "domains"]
}, {
	"State": "live",
	"name": "101_using_jmx_api_02",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to fetch the bulk contents from a log file for a given domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/101_using_jmx_api_02",
	"urlLink": "",
	"tags": ["jmx api", "monitoring", "get log file using jmx"]
}, {
	"State": "live",
	"name": "102_using_jmx_api_03",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX API notifications to get alerted via callback functions about an inactivity timeout in a given Streams domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/102_using_jmx_api_03",
	"urlLink": "",
	"tags": [" use jmx to get alerts", " monitoring", "jmx"]
}, {
	"State": "live",
	"name": "103_view_annotation_at_work",
	"description": "This is a simple SPL application that explains the steps required to use the view annotation and then how to visualize the view annotated stream in the Streams web console. Detailed steps to view the annotated stream are shown in the commentary section of this SPL file.",
	"language": ["SPL"],
	"category": ["Visualization and Reporting"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/103_view_annotation_at_work_com_acme_test_ViewAnnotationAtWork_spl",
	"urlLink": "",
	"tags": ["microsoft excel", "console", "view annotation", "views example", "reporting", "views", "visualization", "visualize", "application development"]
}, {
	"State": "live",
	"name": "901_cat_example",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/901_cat_example_NumberedCat_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "902_word_count",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/902_word_count_word_count_WordCount_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "903_unique",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/903_unique_Main_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "904_primitive_round_robin_split",
	"description": "SPL Introductory Tutorial sample",
	"language": ["C++"],
	"category": ["Beginner/General", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/904_primitive_round_robin_split_Main_spl",
	"urlLink": "",
	"tags": ["pair", "spl"]
}, {
	"State": "live",
	"name": "905_gate_load_balancer",
	"description": "SPL Introductory Tutorial sample\"",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/905_gate_load_balancer_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "gate", "improve performance", " gate operator", "threadedsplit", " threadedsplit operator", "gate"]
}
,{
	"State": "live",
	"name": "021_pair_at_work",
	"description": "This example shows off the Pair operator that is used for pairing tuples arriving on different input ports. Only when all the tuples arrive at all the input ports, this operator will emit them one after the other in their order of arrival.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/021_pair_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["pair", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "'096_consistent_region_spl_07",
	"description": "This particular example shows how a C++ primitive operator can play a role inside a consistent region.  It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/096_consistent_region_cpp_07_com_acme_test_ConsistentRegion7_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "097_consistent_region_spl_08",
	"description": "This particular example shows how a C++ primitive operator can be the start of a consistent region.   It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/097_consistent_region_cpp_08_com_acme_test_ConsistentRegion8_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "098_consistent_region_spl_09",
	"description": "This particular example shows how a Java primitive operator can be the start of a consistent region. ",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/098_consistent_region_java_09_com_acme_test_ConsistentRegion9_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "099_consistent_region_spl_10",
	"description": "This particular example shows how a Java primitive operator can play a role inside a consistent region. It demonstrates how to implement the necessary callback functions to support checkpoint and reset.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/099_consistent_region_java_10_com_acme_test_ConsistentRegion10_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "052_streams_to_python",
	"description": "This example shows a powerful feature of Streams to wrap existing code assets written using the Python programming language. This example teaches developers how to use the Streams C++ native functions to call any arbitrary Python function and return the results back to SPL code. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory. You can also read a very detailed IBM developerWorks technical article about this example:  http://tinyurl.com/c3s56fq. [THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED StreamsToPythonLib THAT IS DESCRIBED BELOW.]",
	"language": ["Python"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/052_streams_to_python_python_wrapper_example_streams_to_python_spl",
	"urlLink": "",
	"tags": ["call python from streams", "call python from cpp", " python"]
}, {
	"State": "live",
	"name": "042_dynamic_import_export_api_at_work",
	"description": "This example shows how to use the SPL APIs for dynamically importing and exporting streams. This is achieved by changing the import and export properties on the fly. This powerful feature in Streams provides a way to change the streams producing and consuming operators to change the way in which they publish and subscribe to streams while the application is running.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/042_dynamic_import_export_api_at_work_dynamic_importing_exporting_dynamic_import_spl",
	"urlLink": "",
	"tags": ["import", "export", "dynamic import", "microservices", "export stream", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "045_file_source_using_spl_custom_operator",
	"description": "This example shows how to create source operators using the Custom operator available in the SPL standard toolkit. Starting in Streams 3.x, it is possible to create source operators without writing primitive source operators in C++ or Java. Simple source operators can be written using the built-in SPL Custom operator. This will come handy for those who don't want to do an extra layer of C++ or Java code for satisfying simple needs for a source operator. You will see a function of a file source operator being implemented all using SPL code in this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions,Ingest & Store Data", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/045_file_source_using_spl_custom_operator_my_file_source_file_source_using_spl_custom_operator_spl",
	"urlLink": "",
	"tags": ["read a file using a custom", "custom", "read a file", "filesource", "open a file", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "032_native_function_at_work",
	"description": "This application shows how native functions written in C++ can be called within an SPL application.There are two ways in which native functions can be written in C++.1) Code for the C++ functions can be written in a C++ header file.2) C++ functions can be written outside of the SPL project and packaged into a shared library (.so) file. All the SPL developer will have to work with are an .so file and a C++ header file.This application demonstrates incorporating native functions built in both of those ways.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/032_native_function_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["native functions", " c++", "native functions", " native function model"]
}, {
	"State": "live",
	"name": "018_directory_scan_at_work",
	"description": "This example demonstrates one of the important features desired in the real world (mostly in the Retail banking and in the Telco industries). In many real-world scenarios, they still work via files and such files get dropped into a directory for processing. It is shown here how the DirectoryScan operator picks up a new file as soon as it appears inside an input directory. (Apply caution if huge files are copied to the watch directory. DirectoryScan may detect that big file copy as multiple new files and output multiple tuples with the same file name.)",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/018_directory_scan_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["directoryscan", "read directory repeatedly", "scan directory", "list directory"]
}, {
	"State": "live",
	"name": "011_compiler_intrinsic_functions",
	"description": "Streams compiler provides several intrinsic functions to query the SPL filename, file path, absolute path of the directory, source code line number, composite instance name etc. This example shows the use of the compiler intrinsic functions inside of a Functor operator.",
	"language": ["SPL"],
	"category": ["troubleshooting", " Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/011_compiler_intrinsic_functions_Main_spl",
	"urlLink": "",
	"tags": ["compiler functions", " utility", "print line number", " current line number", " print line number", " print file name", " get file name", " print debug info"]
}, {
	"State": "live",
	"name": "041_real_time_streams_merger",
	"description": "This example shows how two or more incoming streams with a common schema can be merged to flow in a sequence one after the other. This merger is done using a common tuple attribute in those multiple incoming streams as a key. We will use a C++ primitive operator called OrderedMerger that is included in this project. In order for the OrderedMerger to work correctly, it is assumed that multiple input streams for this primitive operator should already be in sorted order based on the key used to merge and sequence them together. ",
	"language": ["C++"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/041_real_time_streams_merger_real_time_merger_real_time_streams_merger_spl",
	"urlLink": "",
	"tags": ["ordered merge of multiple streams ", "c++ example", "merge  streams", " join streams", " c++ operator model", " application development", " ordered merge"]
}, {
	"State": "live",
	"name": "060_simple_pe_failover_technique_at_work",
	"description": "This example shows a way to protect the logic in an analytic operator  when its PE (Processing Element) or its host machine crashes. It uses a well-known fail-over technique that is done through a primary/secondary pair configured for an operator that will need safety from PE or machine crash. This example outlines a scheme for protecting the analytic logic written inside an SPL Custom operator against failures. When such failures occur, a specific fail-over technique employed here will continue the business logic without any interruption. This is done by making a secondary PE to takeover the tasks of the failed primary PE. Thus, the secondary PE does the detection of the primary PE's failure and then changes its role from a secondary PE to a new primary PE. All of this is done without losing any data during the fail-over. At the same time, the failed primary PE will be automatically restarted to do its work as a new secondary PE. This particular fail-over technique ensures that there is always a primary/secondary pair working in concert to provide high availability for a business-critical operator that is coded and configured in this manner.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/060_simple_pe_failover_technique_at_work_com_acme_failover_test_simple_pe_failover_technique_at_work_spl",
	"urlLink": "",
	"tags": ["recovery", " fail over", " crash", "redundancy"]
}, {
	"State": "live",
	"name": "030_spl_config_at_work",
	"description": "This example introduces one of the must-learn features of the SPL language. SPL language offers an extensive list of options to do configuration at the operator level as well as at the composite level. This application attempts to sprinkle many of the available configuration parameters as shown below.a) host,b) hostColocation,c) partitionColocation,d) placement,e) threadedPort and queue,f) relocatable and many more.In addition, this example shows how to make this application toolkit dependent on another (025_dynamic_filter_at_work) SPL toolkit project.",
	"language": ["SPL"],
	"category": ["Tips", "Configuration", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/030_spl_config_at_work_my_sample3_Main_spl",
	"urlLink": "",
	"tags": ["spl config clause", "spl", "concurrency", " threading", "operator fusion", "threading", "host exlocation", "job submission", "load balancing", "host colocation", " spl config clause", "threaded port", "resource allocation", "application deployment"]
}, {
	"State": "live",
	"name": "048_source_operator_with_control_port",
	"description": "This example shows a way to create a C++ primitive source operator and then provide a control input port for it. Certain classes of applications can make use of this facility to control the kind of data a source operator generates. In addition, this example shows how to pass one or more string literals to the C++ primitive operator as invocation time parameters. As a bonus, this example also shows a simple way to do performance measurement inside the SPL code using the built-in SPL high precision timestamp functions.",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/048_source_operator_with_control_port_source_op_with_control_port_source_operator_with_control_port_spl",
	"urlLink": "",
	"tags": ["customized source operator in c++", " control port", "custom", "read a file", "filesource", "open a file", "c++ primitive operator", " custom source operator", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "055_json_to_tuple_to_json_using_c++",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished using an open source C++ JSON API. In order to run this application, you will be required to download an open source component that carries a BSD license. Please read the detailed instructions available in the SPL file for this project. There is also another SPL project that does similar conversion using Java (049_json_to_tuple_to_json_using_java).",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "ttp://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/055_json_to_tuple_to_json_using_c++_com_acme_test_json_to_tuple_to_json_using_cpp_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "parse json from c++", "jsontotuple", "c++ native function"]
}, {
	"State": "live",
	"name": "029_spl_functions_at_work",
	"description": "This example shows how helper and utility functions can be written using the SPL language. It also shows how such SPL functions can be put to use inside the context of an application. Learning this simple concept will go a long way in doing a lot of neat stuff in real-world applications.",
	"language": ["SPL"],
	"category": [" Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/029_spl_functions_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "007_split_at_work",
	"description": "This example shows how a Split operator can be used to split the incoming tuples based on a key. In this example, the split condition (which tuples comes out on which port) is pre configured through a text file. Alternatively, one can compute the index of the output port on the fly inside the Split operator parameter section.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/007_split_at_work_sample_split_at_work_spl",
	"urlLink": "",
	"tags": ["split", "split", " split stream", " divide stream"]
}, {
	"State": "live",
	"name": "028_multiple_composites_at_work",
	"description": "This example shows the use of multiple composites in a single application. There is a main composite that in turn uses two other composites. This application shows how the additional composites in different namespaces get included into the main composite via the 'use' directive. It also demonstrates how the additional composites can accept their own operator parameters. It teaches the basics of an important feature that will come handy when big applications need to be componentized. ",
	"language": ["SPL"],
	"category": ["Best Practices", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/028_multiple_composites_at_work_my_sample1_Main_spl",
	"urlLink": "",
	"tags": ["multiple composites", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "024_threaded_split_at_work",
	"description": "This example demonstrates an important standard toolkit operator named ThreadedSplit. It is a multi-threaded split that is different from the other content-based Split operator. ThreadedSplit uses its own algorithm to split the incoming tuples to the available output ports to improve concurrency. This will speed up the distribution of tuples by using individual threads assigned to each of the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "performance"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/024_threaded_split_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "split stream", "threaded split"]
}, {
	"State": "live",
	"name": "057_reading_nested_tuple_data_via_file_source",
	"description": "This example shows how to ingest nested tuple data via input files specified in a CSV format. There are certain syntactical rules that need to be followed in specifying data for nested tuples inside a CSV formatted input file. This example is a good one for developers to get an idea about how to do this.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/057_reading_nested_tuple_data_via_file_source_com_acme_test_Test1_spl",
	"urlLink": "",
	"tags": ["filesource", "parse", " nested tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "016_aggregate_at_work",
	"description": "This example shows off yet another powerful standard toolkit operator named the Aggregate. It is very good in computing on the fly aggregate values after collecting a set of tuples. Tuples are grouped based on tumbling and sliding windows with partitioned variants. This example also shows how to use the built-in assignment functions provided by this operator to compute regular statistical calculations such as min, max, average, standard deviation etc.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/016_aggregate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["aggregate", "aggregate", "rolling average", "windowing", "average", "window"]
}, {
	"State": "live",
	"name": "020_metrics_sink_at_work",
	"description": "This example shows how one can use the MetricsSink standard toolkit operator to create application-specific custom metrics that can be viewed in real-time when the application is running. Viewing of custom metrics is typically done inside Streams Explorer view of the Streams Studio or by using the capturestate option in streamtool.",
	"language": ["SPL"],
	"category": ["Monitoring", "metrics"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/020_metrics_sink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["metricssink", "metrics", "custom metrics", "application monitoring", "custom statistics"]
}, {
	"State": "live",
	"name": "002_source_sink_at_work",
	"description": "This example shows how a FileSource operator can be used to read CSV formatted records from a file and then receive those tuples in a FileSink to be written to a file in the data directory of this application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/002_source_sink_at_work_sample_source_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", " ", "filesink"]
}, {
	"State": "live",
	"name": "026_gate_at_work",
	"description": "This is an example that uses the Gate operator from the standard toolkit. This operator delays the incoming tuples until a downstream operator signals with an acknowledgment to receive any further tuples. This is a great way to have a feedback through which we can control the rate at which tuples are passed through. (Please refer to another example named 905_gate_load_balancer that shows the effectiveness of the Gate operator in combination with the ThreadedSplit operator to provide load balancing the incoming tuples.)",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/026_gate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["gate", "wait", " hold tuples until signal", "control tuple flow", "wait for tuples"]
}, {
	"State": "live",
	"name": "050_recursive_dir_scan",
	"description": "This example shows how to use the Streams C++ native function facility to recursively scan a given directory and obtain the names of the files present. The logic for the recursive directory scan polls the specified directory periodically and notifies the downstream operator with a new file that just appeared. There is a companion C++ project for this SPL project. Please refer to the RecursiveDirScanLib project for the C++ logic.Important sequence of logic for this application: 1) SPL code resolves the C++ native function in its native.function/function.xml file.2) A call from the SPL code to the native function lands in the wrapper inline C++ function defined in the RecursiveDirScanWrappers.h file of the companion C++ project.3) From that wrapper function, it gets access to a singleton C++ object of the RecursiveDirScan class and then invokes the getFileNamesInDirectory C++ method.4) When that C++ method returns, it will have the results stored in a list<string> reference that was passed to it.5) Back in the SPL code, there is additional logic to cache the already seen files and to filter only the newly found files to send to the downstream operator.In order to test this application, please refer to the commentary at the top of the SPL file in this project.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED RecursiveDirScanLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/050_recursive_dir_scan_recursive_dir_scan_recursive_dir_scan_spl",
	"urlLink": "",
	"tags": ["recursive directory scan in c++", "c++ native functions example", "c++", "application development"]
}, {
	"State": "live",
	"name": "005_throttle_at_work",
	"description": "This example shows how a stream can be throttled to flow at a specified rate. This example also mixes other operators such as Beacon, Custom, and FileSink.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/005_throttle_at_work_sample_throttle_at_work_spl",
	"urlLink": "",
	"tags": ["custom", " throttle", " slow down", "delay", " create tuple", " custom", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "004_delay_at_work",
	"description": "This example shows how a Delay standard toolkit operator can be used to delay a stream. This example also introduces the Custom operator that can be used to perform custom logic. You can also notice the use of a state variable that is mutable inside the Custom operator. It also shows how to create a new tuple on the fly and do your own submissions onto the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/004_delay_at_work_sample_delay_at_work_spl",
	"urlLink": "",
	"tags": ["custom", "delay", "filesink"]
}, {
	"State": "live",
	"name": "019_import_export_at_work",
	"description": "This example demonstrates how two different SPL applications can share streams between them. This is an important feature that is elegantly done using two pseudo operators called Export and Import. This application also shows how two different main composites can be part of the same application by using two different namespaces. As an aside, there is also a demonstration of using a Custom operator to customize the Beacon generated tuples by involving state variables. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/019_import_export_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["import", "export", "microservices", "export stream", "import stream"]
}, {
	"State": "live",
	"name": "033_java_primitive_operator_at_work",
	"description": "This example shows how a Java primitive operator is created from scratch. Java primitive operator is different from JavaOp that you have seen earlier in a different example. Java primitive operator is a first class operator in SPL, whereas JavaOp only permits a callout to another Java operator. In addition, Java primitive operator has the advantage of keeping its name as the operator\u2019s runtime instance name.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT NAMED RSS_Reader_Primitive THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/033_java_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["java operator", " primitive java operator", "java operators", " application development"]
}, {
	"State": "live",
	"name": "043_import_export_filter_at_work",
	"description": "This example shows how to use the SPL feature to apply a filter for what gets exported and what gets imported. This powerful feature lets the downstream import operators to specify what kind of tuples they want to receive by specifying conditional expressions involving tuple attributes. That lets the Streams runtime to apply content-based filtering at the point of export. Those who need such a feature to control what information should be sent downstream based on the tuple contents can make use of this flexible feature. This can be done on the fly without stopping and restarting the application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/043_import_export_filter_at_work_importing_exporting_filter_import_with_filter_spl",
	"urlLink": "",
	"tags": ["import", "export", "filtered import", "dynamic import", "microservices", "export stream", " filter imports", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "017_filesource_filesink_at_work",
	"description": "We have used the FileSource and the FileSink operators in other examples before. However, this example shows off the following intriguing features that will become handy in a lot of practical situations.a) Automatic deletion of a file after the FileSource finishes reading all the records.b) Flushing the sink file on demand after writing a certain number of tuples.c) Ability of the FileSource to move the file once it reads all the content in that file.d) Creating a fresh and new output sink file after writing a certain number of tuples.e) Ability of the FileSource to keep reading from a hot file as new CSV records get written to the end of that file.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/017_filesource_filesink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "advanced file operations", " reread file", "move file", " hot file", "flushing", " automatic deletion", "delete a file"]
}, {
	"State": "live",
	"name": "008_get_submission_time_value",
	"description": "This example shows how the tuple attributes can be assigned values that were supplied by the user at the application/job submission time. It employs the getSubmissionTimeValue function to obtain different values made of different SPL data types. ",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/008_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["functor", "getsubmissiontimevalue", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "014_sort_at_work",
	"description": "This example shows the use of the Sort operator in the context of an application. Sort operator is highly configurable with all kinds of windowing support. In this example, the following window configurations are applied for sorting the incoming tuples:a) Count-based tumbling window.b) Time-based tumbling window.c) Punctuation-based tumbling window.d) Delta-based tumbling window.e) Count-based sliding window.",
	"language": ["SPL"],
	"category": ["transform", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/014_sort_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["sort", " Time-based", " delta based", "time based", " punctuation-based Count based", "sort", " tumbling window", " sliding window", " punctuation based", " sort with windowing", " count-based"]
}, {
	"State": "live",
	"name": "027_java_op_at_work",
	"description": "This example shows an important operator that brings Java into the C++ dominated world of Streams!!! That operator is called JavaOp, which is used to call out to other operators implemented in Java using the Java Operator API. In this example, we will have a tiny Java logic that will calculate the current time and add that time string to a tuple attribute and output that tuple. There is another example that shows the Java primitive operator that is different from the JavaOp operator.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/027_java_op_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in and C++ primitive operators that are NOT fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["dps", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "dps", "c++", "share data"]
}, {
	"State": "live",
	"name": "053_java_primitive_operator_with_complex_output_tuple_types",
	"description": "This example shows important features that can be done via a Java primitive operator. It shows how to do tracing and logging inside a Java operator. It also shows how we can create an output tuple inside a Java primitive operator to have a list of tuple objects carrying complex typed attributes.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT CALLED Java_Complex_Tuple_Type_Submission THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/053_java_primitive_operator_with_complex_output_tuple_types_com_acme_test_java_primitive_operator_with_complex_output_tuple_types_spl",
	"urlLink": "",
	"tags": [" submit tuple from java", "tuple in java operator", "tuple", "complex tuple", " java operator"]
}, {
	"State": "live",
	"name": "035_c++_primitive_operator_at_work",
	"description": "This example shows the steps required to create a C++ primitive operator from scratch. In this application, a C++ primitive operator model XML file can be explored to learn how the different fields in that file are configured. Then, the code generation template header and implementation files (*_h.cgt and *_cpp.cgt) can be browsed to learn about the primitive operator logic. Additionally, this example demonstrates about including a Java operator and a C++ primitive operator as part of the application flow.",
	"language": ["C++"],
	"category": ["Operators & Functions", " Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/035_c++_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["c++ operators", "c++ example", "c++ operator model", " application development"]
}, {
	"State": "live",
	"name": "037_odbc_adapters_for_solid_db_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters for connecting to a SolidDB in-memory database. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test SolidDB database inside IBM. You have to create your own SolidDB database and tables to make this application work in your environment.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/037_odbc_adapters_for_solid_db_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "soliddb"]
}, {
	"State": "live",
	"name": "061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators that are not fused with each other and a C++ native function. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "hsa", "java", "native function", "db", "query"]
}, {
	"State": "live",
	"name": "006_barrier_at_work",
	"description": "This example shows how to synchronize the incoming tuples using a Barrier operator. It uses a bank deposit/debit scenario to split the deposit/debit requests, perform that account activity, and then combine the post-activity result with the incoming requests. Barrier operator does what is needed to accomplish that i.e. it waits for the streams to arrive at all the configured input ports before emitting an output tuple.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/006_barrier_at_work_sample_barrier_at_work_spl",
	"urlLink": "",
	"tags": ["barrier", "functor", "custom", " slow down stream", "delay", "create tuple", "slow down tuples", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "015_join_at_work",
	"description": "This example shows one of the power-packed standard toolkit operators; i.e. Join. This operator is so versatile that it is hard to do justice in explaining it thoroughly in a simple example such as this one.  This example provides coverage to the following Join operator features.a) Inner Join,b) Inner (Equi) Join,c) Left Outer Join,d) Right Outer Join,e) Full Outer Join",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/015_join_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["join", " inner join", "merge stream", "join", " join stream"]
}, {
	"State": "live",
	"name": "031_spl_mixed_mode_at_work",
	"description": "This example shows a cool SPL feature called mixed-mode support. In this, developers can mix PERL code islands inside of an SPL application. Mixed-mode enables the easy parameterization of SPL applications. This example gives a slight flavor of how a PERL code snippet inter-mixed with SPL allows us to parameterize the SPL Stream names and the number of output stream definitions for an SPL operator. ",
	"language": ["perl"],
	"category": ["Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/031_spl_mixed_mode_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["mixed mode", "spl", "mixed mode", "code generation"]
}, {
	"State": "live",
	"name": "047_streams_host_tags_at_work",
	"description": "This example shows how to create host tags for a given Streams instance and then use those host tags inside an SPL application. By using host tags, it is possible to avoid hard-coding the host names inside the SPL application code. Detailed instructions about creating and using host tags are explained in this example.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/047_streams_host_tags_at_work_host_tags_streams_host_tags_at_work_spl",
	"urlLink": "",
	"tags": ["tcpsink", "tcpsource", "host tags", "operator placement", "tcpsink", "tcpsource", "config clause", "host pools"]
}, {
	"State": "live",
	"name": "049_json_to_tuple_to_json_using_java",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished via two Java primitive operators that make use of the JSON (Java) libraries shipped as part of the Streams product. Those two Java operators are JSONToTuple and TupleToJSON.Note: Performance of the JSON<-->Tuple conversion in this example will be limited by the speed of your Java environment. If you want to get better performance, C++ code would help. There is a separate example (055_json_to_tuple_to_json_using_c++) that shows how to do this conversion using C++.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/049_json_to_tuple_to_json_using_java_sample_Main_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "json", " parse json"]
}, {
	"State": "live",
	"name": "046_launching_external_apps_in_spl",
	"description": "This example shows how to launch/execute an external application within the Streams SPL code. In this case, we defined a simple C++ native function in which we have the required C++ code to launch an external application. That C++ code uses pipes to execute a given application. This function would be useful to launch any custom script within the Streams application logic when certain application specific conditions arise.",
	"language": ["C++"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/046_launching_external_apps_in_spl_launch_external_apps_launching_external_apps_spl",
	"urlLink": "",
	"tags": ["launch an external app", " spl utility functions", "launch a program", "execute program"]
}, {
	"State": "live",
	"name": "059_dynamic_scaleout_of_streams_application",
	"description": "This example shows a particular style of writing Streams applications that can be scaled up or scaled down as the application input workload changes. It uses a familiar scenario from the Financial Services Sector, where the price calculation engines will require scaling up when the market data load increases. Code written in this example uses a pattern for starting more instances of an analytic operator to increase parallelism. New instances of such analytic operators can be started on demand without disrupting the already running application flow. As soon as the newly started operator instances are ready, application load will be promptly distributed across the existing and the newly started instances of that operator. In the same way, when the application data load is not high, some of the most recently started operator instances can be stopped to release the CPU cores for other use. This technique is one of many ways to design Streams applications that will scale up and down dynamically according to the changing input data workload.",
	"language": ["C++"],
	"category": ["Tips,Best Practices,Microservices,Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/059_dynamic_scaleout_of_streams_application_com_ibm_streams_pricing_test_DynamicScaleOut_spl",
	"urlLink": "",
	"tags": ["import", "export", "ingest"]
}, {
	"State": "live",
	"name": "009_custom_operator_using_get_submission_time_value",
	"description": "This example demonstrates how to assign tuple attributes at the time of job submission inside a custom operator. When the incoming tuples arrive at the Custom operator in this example, values entered by the user at the application startup are assigned to the tuple attributes.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/009_custom_operator_using_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["custom", "getsubmissiontimevalue", "get submission time value", " submission time", "parameter lists", " parameters", " custom", "create tuple"]
}, {
	"State": "live",
	"name": "012_filter_functor_at_work",
	"description": "This example puts the two commonly used standard toolkit operators to work. They are Filter and Functor. Filter allows you to route tuples based on conditional checks. It provides two output ports to send the matched tuples on the first output port and the unmatched tuples on the second output port. Functor operator allows us to transform the incoming tuple attributes and then to send it on many different output ports with different stream schemas.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/012_filter_functor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["functor", "filter", "filter tuples", "remove tuples"]
}, {
	"State": "live",
	"name": "022_deduplicate_at_work",
	"description": "This example describes the use of an important operator that is highly applicable in many Telco scenarios. That operator is called DeDuplicate, which eliminates duplicate tuples for a specified duration of time. It also has an optional second output port on which duplicate tuples could be sent out for additional processing.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/022_deduplicate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["deduplicate", "separate two streams", "remove duplicates", "split streams"]
}, {
	"State": "live",
	"name": "013_punctor_at_work",
	"description": "This example shows how a Punctor operator could be used in an application. Punctor operator allows us to transform the input tuples and then inject puncuation markers either before or after the output tuple as configured.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/013_punctor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["punctor", "custom logic", " generate punctuation", " punctuation"]
}, {
	"State": "live",
	"name": "036_shared_lib_primitive_operator_at_work",
	"description": "This example demonstrates two important techniques that will be commonly used in real-world use cases.1) Creating a C++ primitive operator.2) Calling a function available inside a .so shared library from the C++ primitive operator logic.Application logic here is to receive input tuples as hostnames and then make the C++ primitive operator logic invoke a shared library function that does a name server lookup.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED PrimitiveOperatorLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/036_shared_lib_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" c++", " operator dependencies", " library", "shared library", " application development"]
}, {
	"State": "live",
	"name": "003_sink_at_work",
	"description": "This example shows how FileSink and Custom sinks can be employed in applications. It also shows how a Beacon operator can be used to customize tuple attributes. In addition, it introduces the Filter operator to route the incoming tuples by inspecting their attributes using a conditional statement specified in the filter parameter. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/003_sink_at_work_sample_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "read", "files", "write"]
}, {
	"State": "live",
	"name": "023_union_at_work",
	"description": "This example demonstrates an utility operator called Union. This operator combines all the tuples from several input ports as they arrive and emits a single output stream. All the input ports must have a schema that contains attributes of the same name and type as those of the output port. The order of the attributes in the input ports need not match the order in the output port.",
	"language": ["SPL"],
	"category": ["enrich", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/023_union_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["union", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "044_streams_checkpointing_at_work",
	"description": "This example shows a key feature of Streams by which an operator's state variables can be preserved when a PE fails and gets restarted. This is done through a combination of the SPL configuration directives named 'checkpointing' and 'restartable'. Developers can protect their critical operator data by taking advantage of this built-in checkpointing feature. When you run this example, you will see data flows without any gaps or interruption, when a PE is killed manually and then gets restored automatically by the Streams runtime.",
	"language": ["SPL"],
	"category": ["performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/044_streams_checkpointing_at_work_checkpointing_example_streams_checkpointing_at_work_spl",
	"urlLink": "",
	"tags": ["checkpoint config clause", " data consistency", "automatic checkpointing", " fail over", "checkpoint"]
}, {
	"State": "live",
	"name": "001_hello_world_in_spl",
	"description": "This example is the simplest possible SPL application. It uses a Beacon operator to generate tuples that carry Hello World' messages. A custom sink operator receives the tuples from Beacon and displays it on the console.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/001_hello_world_in_spl_HelloWorld_spl",
	"urlLink": "",
	"tags": ["custom"]
}, {
	"State": "live",
	"name": "038_spl_built_in_functions_at_work",
	"description": "This is a very simple example that showcases a random collection of powerful built-in SPL functions that are available out of the box. This application demonstrates how time, math, and collection type functions can be used inside of an SPL application.",
	"language": ["SPL"],
	"category": ["Best Practices", "Collections and Data Types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/038_spl_built_in_functions_at_work_test_scratch_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "data types", " spl functions", "list", " mutable", " convert time stamp", "map", " convert timestamp", " timestamps", " utility functions"]
}, {
	"State": "live",
	"name": "056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example shows a particular implementation about how data can be shared across multiple FUSED operators using an SPL map based in-memory store. Here, we are simply showing a way to use the SPL native function facility to perform data sharing via an SPL map based in-memory store that will serve multiple SPL standard toolkit operators and C++ primitive operators. As mentioned above, this example shows data sharing between multiple operators that are fused inside a single PE (Processing Element). This technical approach is called Process Store (ps). This data sharing mechanism will NOT work between operators that are on different PEs. This example depends on the com.ibm.streamsx.ps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "db", "query"]
}, {
	"State": "live",
	"name": "034_odbc_adapters_for_db2_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test DB2 database inside IBM. You have to create your own DB2 database and tables to make this application work in your environment. After creating your own database and tables, you have to change the etc/connections.xml file in this application's directory to match your database/table names, userid, and password. You also have to make changes in the SPL code using your database information for all the three ODBC operator invocations.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/034_odbc_adapters_for_db2_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "db2"]
}, {
	"State": "live",
	"name": "051_native_functions_with_collection_types",
	"description": "This example shows an important feature of Streams. In Streams applications, it may be necessary to accept and return collection types in and out of the C++ native functions. This will require native function code that can directly deal with types such as list, map, and tuple. Streams provides C++ reflection APIs to directly deal with such collection types. In this example, developers can learn how to build native functions inside of a C++ class and then pass list, map, and tuple types to those native functions. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionsWithCollectionTypesLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/051_native_functions_with_collection_types_com_ibm_nf_test_native_functions_with_collection_types_spl",
	"urlLink": "",
	"tags": [" data types", "native functions", "collections", "list", "c++ native functions example", "c++", "map", " collections", "application development", "tuple"]
}, {
	"State": "live",
	"name": "040_ingest_data_generation_in_spl",
	"description": "This example shows how SPL provides rich features to generate synthetic data required for large scale testing. Many real-life applications in the Telco and the Retail Banking sectors consume large amounts of daily business data through CSV formatted text files. There could be huge amounts of CDR data from several telecom circles or daily transaction data for millions of accounts in a retail bank.While building and testing the SPL applications, it will become necessary to generate such ingest data files with artificial data that is close enough to be realistic. This application shows how such large amounts of data in several thousands of files can be created very quickly using the SPL standard toolkit operators as well as the SPL file IO and math random built-in functions.",
	"language": ["SPL"],
	"category": ["Collections & Data types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/040_ingest_data_generation_in_spl_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["test data generation", "data types", " test data generation", "sample data", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "025_dynamic_filter_at_work",
	"description": "This example deals with an interesting standard toolkit operator called DynamicFilter. This operator is a special version of the Filter operator that you have already seen in another example; it decides at runtime which input tuples will be passed through, based on the control input it receives. This operator is applicable in many real-life scenarios. This example also demonstrates using a second composite operator to perform a sub-task that the main composite will make use of. There is also coverage to show how the second composite can take its own operator parameters.  ",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/025_dynamic_filter_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["dynamicfilter", " reusable composite", "composite operators", " filter based on input", " dynamic filter", "filter"]
}, {
	"State": "live",
	"name": "062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators and a Java primitive operator that are not fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples. In this SPL project, you will find a Java primitive operator that exercises all the dps APIs in a very comprehensive manner. In order to get access to the dps APIs, this project's build path is added with dps-helper.jar available inside the com.ibm.streamsx.dps toolkit directory (i.e. impl/java/bin). Please read at the top of this project's SPL file and the TickerIdGenerator.java primitive operator file for an extensive commentary about how to run this example.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["java database", "database", "redis", "hsa", "java", "mongo", "db", "query"]
}, {
	"State": "live",
	"name": "063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators",
	"description": "This example shows how to create a tuple on the fly inside a Java primitive operator. In addition, this example also shows how to convert a tuple into a blob (Java byte buffer) and how to convert a blob (Java byte buffer) in to a tuple. It is an interesting concept that a Java primitive operator developer can put into use in certain situations that warrant dynamic tuple creation, tuple encoding and decoding all inside Java.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators_application_Main_spl",
	"urlLink": "",
	"tags": ["create tuple in java", "java", "blob", "blob java", "create tuple"]
}, {
	"State": "live",
	"name": "064_using_spl_composite_params",
	"description": "This example shows different ways in which parameters can be passed to SPL composites. It is very useful to pass parameters as attributes, expressions, functions, operators, and types. These different ways of passing parameters to the composites is the focus of this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/064_using_spl_composite_params_com_acme_test_CompositeParams_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "065_using_multiple_threads_in_java_operator",
	"description": "This example shows how to spawn multiple threads within a Java primitive operator and then submit tuples from within those threads concurrently.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/065_using_multiple_threads_in_java_operator_com_acme_test_JavaOpSubmitFromMultipleThreads_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "066_load_balancing_using_gate",
	"description": "As documented in the Streams Info Center for a ThreadedSplit, if the processing time of a tuple varies considerably depending on the tuple data, it may cause problems where a tuple with a long processing time may cause subsequent tuples to be backed up in the stream. This example shows how a Gate operator can be combined with the ThreadedSplit can be used to ensure load balancing.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/066_load_balancing_using_gate_com_acme_test_LoadBalancingUsingGate_spl",
	"urlLink": "",
	"tags": ["gate"]
}, {
	"State": "live",
	"name": "067_simple_java_source_operator",
	"description": "This example shows a basic source operator implemented in Java. There are specific steps required for implementing a source operator and it can be learned in this example.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/067_simple_java_source_operator_com_acme_test_Temp1_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "068_tuple_introspection_inside_java_operator",
	"description": "This example shows how a tuple can be introspected to learn about its structure and its attribute names and their types. Inside a Java operator, this example illustrates how it is possible to recursively look through a tuple to understand its composition.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/068_tuple_introspection_inside_java_operator_com_acme_test_Temp2_spl",
	"urlLink": "",
	"tags": ["parse tuple in java", "tuples", " collections", "tuples java", " java operator", "spl data types"]
}, {
	"State": "live",
	"name": "069_changing_map_value_during_iteration",
	"description": "Until the release of Streams version 3.2.1, it was not possible to modify the value of a map inside an iteration loop. This example shows a new feature available in Streams version 3.2.1 that permits the value of a map to be modified inside a for loop.",
	"language": ["SPL"],
	"category": ["Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/069_changing_map_value_during_iteration_com_acme_test_ChangeCollectionValue_spl",
	"urlLink": "",
	"tags": ["iterate over map", "iteration", "change map value", "change map"]
}, {
	"State": "live",
	"name": "070_convert_block_data_into_tuples_using_parse",
	"description": "This example shows how a block of data ingested as a blob type can be converted into individual tuples using the Parse operator.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/070_convert_block_data_into_tuples_using_parse_com_acme_test_ConvertBlockDataWithParse_spl",
	"urlLink": "",
	"tags": ["parse", "parse operator", "parse blob", " convert blob to tuple", "tuples"]
}, {
	"State": "live",
	"name": "071_java_native_functions",
	"description": "Java native functions provide a cool way to add user-defined functions in Java and then call them directly within the SPL code. This example shows how easy it is to create java native functions.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/071_java_native_functions_com_acme_test_JavaNativeFunctions_spl",
	"urlLink": "",
	"tags": ["create java native function", "java function"]
}, {
	"State": "live",
	"name": "072_using_streams_rest_apis",
	"description": "Streams provides REST APIs to query different kinds of metrics about the instances, jobs, resources during the runtime operation. It is a comprehensive set of APIs that can be used with proper security configuration. This example shows a few different REST APIs in action by invoking them within Java code.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/072_using_streams_rest_apis_com_acme_test_UsingStreamsRestApis_spl",
	"urlLink": "",
	"tags": ["get job info", "monitoring", "rest", "rest api example", "jobs"]
}, {
	"State": "live",
	"name": "073_java_operator_fusion",
	"description": "This example shows how two different Java operators one performing the Sink operation and the other performing the analytics operation can be fused to operate within a single PE.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/073_java_operator_fusion_com_acme_test_JavaFusion_spl",
	"urlLink": "",
	"tags": ["java operator fusion", " ", "fuse multiple operators"]
}, {
	"State": "live",
	"name": "074_user_defined_parallelism_01",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/074_user_defined_parallelism_01_com_acme_test_UDP1_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "075_user_defined_parallelism_02",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/075_user_defined_parallelism_02_com_acme_test_UDP2_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "076_user_defined_parallelism_03",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/076_user_defined_parallelism_03_com_acme_test_UDP3_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "077_user_defined_parallelism_04",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/077_user_defined_parallelism_04_com_acme_test_UDP4_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "078_user_defined_parallelism_05",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/078_user_defined_parallelism_05_com_acme_test_UDP5_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "079_user_defined_parallelism_06",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/079_user_defined_parallelism_06_com_acme_test_UDP6_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "080_user_defined_parallelism_07",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/080_user_defined_parallelism_07_com_acme_test_UDP7_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "081_user_defined_parallelism_08",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/081_user_defined_parallelism_08_com_acme_test_UDP8_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "083_user_defined_parallelism_10",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/083_user_defined_parallelism_10_com_acme_test_UDP10_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "084_user_defined_parallelism_11",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/084_user_defined_parallelism_11_com_acme_test_UDP11_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "085_user_defined_parallelism_12",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/085_user_defined_parallelism_12_com_acme_test_UDP12_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "086_jms_source_sink_using_activemq",
	"description": "This example shows how the JMSSource and JMSSink operators from the Streams standard toolkit can be put to use for sending messages from Streams into the Apache ActiveMQ queues and topics as well as reading messages from there into Streams.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/086_jms_source_sink_using_activemq_com_acme_test_JMSSourceSink_spl",
	"urlLink": "",
	"tags": ["jmssource", "jmssink", "activemq", "jms", "read from activemq", "messaging server", "messaging"]
}, {
	"State": "live",
	"name": "087_email_alerts_via_java_native_function",
	"description": "This example shows a way to send email alerts from an SPL application. It is done via a Java native function by using the email API available in the standard Java platform. If an SMTP server is present in the same   network where Streams servers are connected, the technique shown in this example can be put to use for sending email alerts.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/087_email_alerts_via_java_native_function_com_acme_test_EmailAlerts_spl",
	"urlLink": "",
	"tags": ["send email", "email", "send email java"]
}, {
	"State": "live",
	"name": "088_java_operator_params_and_multiple_input_output_ports",
	"description": "This example demonstrates two different features of the Java primitive operator framework. It first shows how operator parameters can be easily processed inside the Java operators via the @Parameter annotations. Then, it shows how multiple input and output ports can be accessed inside the Java operators. As a bonus, it also shows a better approach for on the fly creation of the output tuples made with complex nested types.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/088_java_operator_params_and_multiple_input_output_ports_com_acme_test_JavaOperatorParams_spl",
	"urlLink": "",
	"tags": [" complex tuple", "java operator", "java operator parameters", "java", "java operator", "multiple input ports", "create tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "089_integrating_streams_apps_with_web_apps",
	"description": "This example demonstrates one of the Streams open source toolkits (com.ibm.streamsx.inet). Using this toolkit one can integrate Streams applications with web applications. Please read the comments in the SPL file for this example project to download that toolkit, install it, and then use that toolkit inside a simple SPL application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/089_integrating_streams_apps_with_web_apps_com_acme_test_WebCalculator_spl",
	"urlLink": "",
	"tags": ["httptupleinjection", "httptupleview", "send tuples to browser", "rest", "post to streams app", "streams web app"]
}, {
	"State": "live",
	"name": "090_consistent_region_spl_01",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/090_consistent_region_spl_01_com_acme_test_ConsistentRegion1_spl",
	"urlLink": "",
	"tags": ["filesource"]
}, {
	"State": "live",
	"name": "091_consistent_region_spl_02",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a FileSource with a periodic checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/091_consistent_region_spl_02_com_acme_test_ConsistentRegion2_spl",
	"urlLink": "",
	"tags": ["beacon"]
}, {
	"State": "live",
	"name": "092_consistent_region_spl_03",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the Aggregate operators in this application is forcefully aborted inside the application multiple times to prove that application survive those multiple crashes at different times and yet will continue processing tuples normally after an automatic restart of that failed operator. In addition, during those crashes Streams will preserve the windows contents of that Aggregate operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/092_consistent_region_spl_03_com_acme_test_ConsistentRegion3_spl",
	"urlLink": "",
	"tags": ["aggregate", "consistent region window", "consistent region"]
}, {
	"State": "live",
	"name": "093_consistent_region_spl_04",
	"description": "This example demonstrates how a consistent region can be defined for two different composites acting as sources for this application. These consistent regions have a periodic checkpoint trigger. Couple of different Custom operators connected to those sources are forcefully aborted inside the application. Output streams of those operators will be combined using a Join operator. This application will ensure that the application will continue normally without losing any tuples by withstanding the random crash of those two Custom operators.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/093_consistent_region_spl_04_com_acme_test_ConsistentRegion4_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "094_consistent_region_spl_05",
	"description": "This particular example shows how only a portion of the topology will take part in the consistent region by having an autonomous section in the application graph. This example simulates the operator failure by aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Join operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration. At the same time, parts of the application that is in the autonomous area will get duplicate tuples during a crash recovery happening in the consistent region of this application graph. This example's purpose is to make the users aware of this fact. In the autonomous area, measures need to be taken to do deduplication.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/094_consistent_region_spl_05_com_acme_test_ConsistentRegion5_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "095_consistent_region_spl_06",
	"description": "This particular example shows how a non-replay capable Source operator will not be a show stopper when it comes to employing the consistent region feature in such applications. When using sources (such as TCPSource) that can't realistically replay data, there is way to configure your application with consistent region by using an utility operator called ReplaybleStart (shipped with the Streams product). In this example, we will use a topology that uses TCPSource along with ReplayableStart to achieve application-level fault tolerance.  This example simulates the operator failure by  aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Aggregate operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/095_consistent_region_spl_06_com_acme_test_ConsistentRegion6_spl",
	"urlLink": "",
	"tags": ["replayablestart", "enabling consistent regions when the source operator deos not support it", "failure", "crash", "high availability", "guaranteed processing", "replayablestart"]
}, {
	"State": "live",
	"name": "100_using_jmx_api_01",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to query information about the Streams domain and the Streams instance.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/100_using_jmx_api_01",
	"urlLink": "",
	"tags": ["jmx api", " jmx", " monitoring", "domains"]
}, {
	"State": "live",
	"name": "101_using_jmx_api_02",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to fetch the bulk contents from a log file for a given domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/101_using_jmx_api_02",
	"urlLink": "",
	"tags": ["jmx api", "monitoring", "get log file using jmx"]
}, {
	"State": "live",
	"name": "102_using_jmx_api_03",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX API notifications to get alerted via callback functions about an inactivity timeout in a given Streams domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/102_using_jmx_api_03",
	"urlLink": "",
	"tags": [" use jmx to get alerts", " monitoring", "jmx"]
}, {
	"State": "live",
	"name": "103_view_annotation_at_work",
	"description": "This is a simple SPL application that explains the steps required to use the view annotation and then how to visualize the view annotated stream in the Streams web console. Detailed steps to view the annotated stream are shown in the commentary section of this SPL file.",
	"language": ["SPL"],
	"category": ["Visualization and Reporting"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/103_view_annotation_at_work_com_acme_test_ViewAnnotationAtWork_spl",
	"urlLink": "",
	"tags": ["microsoft excel", "console", "view annotation", "views example", "reporting", "views", "visualization", "visualize", "application development"]
}, {
	"State": "live",
	"name": "901_cat_example",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/901_cat_example_NumberedCat_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "902_word_count",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/902_word_count_word_count_WordCount_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "903_unique",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/903_unique_Main_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "904_primitive_round_robin_split",
	"description": "SPL Introductory Tutorial sample",
	"language": ["C++"],
	"category": ["Beginner/General", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/904_primitive_round_robin_split_Main_spl",
	"urlLink": "",
	"tags": ["pair", "spl"]
}, {
	"State": "live",
	"name": "905_gate_load_balancer",
	"description": "SPL Introductory Tutorial sample\"",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/905_gate_load_balancer_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "gate", "improve performance", " gate operator", "threadedsplit", " threadedsplit operator", "gate"]
}
,{
	"State": "live",
	"name": "021_pair_at_work",
	"description": "This example shows off the Pair operator that is used for pairing tuples arriving on different input ports. Only when all the tuples arrive at all the input ports, this operator will emit them one after the other in their order of arrival.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/021_pair_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["pair", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "'096_consistent_region_spl_07",
	"description": "This particular example shows how a C++ primitive operator can play a role inside a consistent region.  It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/096_consistent_region_cpp_07_com_acme_test_ConsistentRegion7_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "097_consistent_region_spl_08",
	"description": "This particular example shows how a C++ primitive operator can be the start of a consistent region.   It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/097_consistent_region_cpp_08_com_acme_test_ConsistentRegion8_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "098_consistent_region_spl_09",
	"description": "This particular example shows how a Java primitive operator can be the start of a consistent region. ",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/098_consistent_region_java_09_com_acme_test_ConsistentRegion9_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "099_consistent_region_spl_10",
	"description": "This particular example shows how a Java primitive operator can play a role inside a consistent region. It demonstrates how to implement the necessary callback functions to support checkpoint and reset.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/099_consistent_region_java_10_com_acme_test_ConsistentRegion10_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "052_streams_to_python",
	"description": "This example shows a powerful feature of Streams to wrap existing code assets written using the Python programming language. This example teaches developers how to use the Streams C++ native functions to call any arbitrary Python function and return the results back to SPL code. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory. You can also read a very detailed IBM developerWorks technical article about this example:  http://tinyurl.com/c3s56fq. [THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED StreamsToPythonLib THAT IS DESCRIBED BELOW.]",
	"language": ["Python"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/052_streams_to_python_python_wrapper_example_streams_to_python_spl",
	"urlLink": "",
	"tags": ["call python from streams", "call python from cpp", " python"]
}, {
	"State": "live",
	"name": "042_dynamic_import_export_api_at_work",
	"description": "This example shows how to use the SPL APIs for dynamically importing and exporting streams. This is achieved by changing the import and export properties on the fly. This powerful feature in Streams provides a way to change the streams producing and consuming operators to change the way in which they publish and subscribe to streams while the application is running.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/042_dynamic_import_export_api_at_work_dynamic_importing_exporting_dynamic_import_spl",
	"urlLink": "",
	"tags": ["import", "export", "dynamic import", "microservices", "export stream", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "045_file_source_using_spl_custom_operator",
	"description": "This example shows how to create source operators using the Custom operator available in the SPL standard toolkit. Starting in Streams 3.x, it is possible to create source operators without writing primitive source operators in C++ or Java. Simple source operators can be written using the built-in SPL Custom operator. This will come handy for those who don't want to do an extra layer of C++ or Java code for satisfying simple needs for a source operator. You will see a function of a file source operator being implemented all using SPL code in this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions,Ingest & Store Data", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/045_file_source_using_spl_custom_operator_my_file_source_file_source_using_spl_custom_operator_spl",
	"urlLink": "",
	"tags": ["read a file using a custom", "custom", "read a file", "filesource", "open a file", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "032_native_function_at_work",
	"description": "This application shows how native functions written in C++ can be called within an SPL application.There are two ways in which native functions can be written in C++.1) Code for the C++ functions can be written in a C++ header file.2) C++ functions can be written outside of the SPL project and packaged into a shared library (.so) file. All the SPL developer will have to work with are an .so file and a C++ header file.This application demonstrates incorporating native functions built in both of those ways.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/032_native_function_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["native functions", " c++", "native functions", " native function model"]
}, {
	"State": "live",
	"name": "018_directory_scan_at_work",
	"description": "This example demonstrates one of the important features desired in the real world (mostly in the Retail banking and in the Telco industries). In many real-world scenarios, they still work via files and such files get dropped into a directory for processing. It is shown here how the DirectoryScan operator picks up a new file as soon as it appears inside an input directory. (Apply caution if huge files are copied to the watch directory. DirectoryScan may detect that big file copy as multiple new files and output multiple tuples with the same file name.)",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/018_directory_scan_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["directoryscan", "read directory repeatedly", "scan directory", "list directory"]
}, {
	"State": "live",
	"name": "011_compiler_intrinsic_functions",
	"description": "Streams compiler provides several intrinsic functions to query the SPL filename, file path, absolute path of the directory, source code line number, composite instance name etc. This example shows the use of the compiler intrinsic functions inside of a Functor operator.",
	"language": ["SPL"],
	"category": ["troubleshooting", " Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/011_compiler_intrinsic_functions_Main_spl",
	"urlLink": "",
	"tags": ["compiler functions", " utility", "print line number", " current line number", " print line number", " print file name", " get file name", " print debug info"]
}, {
	"State": "live",
	"name": "041_real_time_streams_merger",
	"description": "This example shows how two or more incoming streams with a common schema can be merged to flow in a sequence one after the other. This merger is done using a common tuple attribute in those multiple incoming streams as a key. We will use a C++ primitive operator called OrderedMerger that is included in this project. In order for the OrderedMerger to work correctly, it is assumed that multiple input streams for this primitive operator should already be in sorted order based on the key used to merge and sequence them together. ",
	"language": ["C++"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/041_real_time_streams_merger_real_time_merger_real_time_streams_merger_spl",
	"urlLink": "",
	"tags": ["ordered merge of multiple streams ", "c++ example", "merge  streams", " join streams", " c++ operator model", " application development", " ordered merge"]
}, {
	"State": "live",
	"name": "060_simple_pe_failover_technique_at_work",
	"description": "This example shows a way to protect the logic in an analytic operator  when its PE (Processing Element) or its host machine crashes. It uses a well-known fail-over technique that is done through a primary/secondary pair configured for an operator that will need safety from PE or machine crash. This example outlines a scheme for protecting the analytic logic written inside an SPL Custom operator against failures. When such failures occur, a specific fail-over technique employed here will continue the business logic without any interruption. This is done by making a secondary PE to takeover the tasks of the failed primary PE. Thus, the secondary PE does the detection of the primary PE's failure and then changes its role from a secondary PE to a new primary PE. All of this is done without losing any data during the fail-over. At the same time, the failed primary PE will be automatically restarted to do its work as a new secondary PE. This particular fail-over technique ensures that there is always a primary/secondary pair working in concert to provide high availability for a business-critical operator that is coded and configured in this manner.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/060_simple_pe_failover_technique_at_work_com_acme_failover_test_simple_pe_failover_technique_at_work_spl",
	"urlLink": "",
	"tags": ["recovery", " fail over", " crash", "redundancy"]
}, {
	"State": "live",
	"name": "030_spl_config_at_work",
	"description": "This example introduces one of the must-learn features of the SPL language. SPL language offers an extensive list of options to do configuration at the operator level as well as at the composite level. This application attempts to sprinkle many of the available configuration parameters as shown below.a) host,b) hostColocation,c) partitionColocation,d) placement,e) threadedPort and queue,f) relocatable and many more.In addition, this example shows how to make this application toolkit dependent on another (025_dynamic_filter_at_work) SPL toolkit project.",
	"language": ["SPL"],
	"category": ["Tips", "Configuration", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/030_spl_config_at_work_my_sample3_Main_spl",
	"urlLink": "",
	"tags": ["spl config clause", "spl", "concurrency", " threading", "operator fusion", "threading", "host exlocation", "job submission", "load balancing", "host colocation", " spl config clause", "threaded port", "resource allocation", "application deployment"]
}, {
	"State": "live",
	"name": "048_source_operator_with_control_port",
	"description": "This example shows a way to create a C++ primitive source operator and then provide a control input port for it. Certain classes of applications can make use of this facility to control the kind of data a source operator generates. In addition, this example shows how to pass one or more string literals to the C++ primitive operator as invocation time parameters. As a bonus, this example also shows a simple way to do performance measurement inside the SPL code using the built-in SPL high precision timestamp functions.",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/048_source_operator_with_control_port_source_op_with_control_port_source_operator_with_control_port_spl",
	"urlLink": "",
	"tags": ["customized source operator in c++", " control port", "custom", "read a file", "filesource", "open a file", "c++ primitive operator", " custom source operator", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "055_json_to_tuple_to_json_using_c++",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished using an open source C++ JSON API. In order to run this application, you will be required to download an open source component that carries a BSD license. Please read the detailed instructions available in the SPL file for this project. There is also another SPL project that does similar conversion using Java (049_json_to_tuple_to_json_using_java).",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "ttp://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/055_json_to_tuple_to_json_using_c++_com_acme_test_json_to_tuple_to_json_using_cpp_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "parse json from c++", "jsontotuple", "c++ native function"]
}, {
	"State": "live",
	"name": "029_spl_functions_at_work",
	"description": "This example shows how helper and utility functions can be written using the SPL language. It also shows how such SPL functions can be put to use inside the context of an application. Learning this simple concept will go a long way in doing a lot of neat stuff in real-world applications.",
	"language": ["SPL"],
	"category": [" Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/029_spl_functions_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "007_split_at_work",
	"description": "This example shows how a Split operator can be used to split the incoming tuples based on a key. In this example, the split condition (which tuples comes out on which port) is pre configured through a text file. Alternatively, one can compute the index of the output port on the fly inside the Split operator parameter section.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/007_split_at_work_sample_split_at_work_spl",
	"urlLink": "",
	"tags": ["split", "split", " split stream", " divide stream"]
}, {
	"State": "live",
	"name": "028_multiple_composites_at_work",
	"description": "This example shows the use of multiple composites in a single application. There is a main composite that in turn uses two other composites. This application shows how the additional composites in different namespaces get included into the main composite via the 'use' directive. It also demonstrates how the additional composites can accept their own operator parameters. It teaches the basics of an important feature that will come handy when big applications need to be componentized. ",
	"language": ["SPL"],
	"category": ["Best Practices", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/028_multiple_composites_at_work_my_sample1_Main_spl",
	"urlLink": "",
	"tags": ["multiple composites", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "024_threaded_split_at_work",
	"description": "This example demonstrates an important standard toolkit operator named ThreadedSplit. It is a multi-threaded split that is different from the other content-based Split operator. ThreadedSplit uses its own algorithm to split the incoming tuples to the available output ports to improve concurrency. This will speed up the distribution of tuples by using individual threads assigned to each of the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "performance"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/024_threaded_split_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "split stream", "threaded split"]
}, {
	"State": "live",
	"name": "057_reading_nested_tuple_data_via_file_source",
	"description": "This example shows how to ingest nested tuple data via input files specified in a CSV format. There are certain syntactical rules that need to be followed in specifying data for nested tuples inside a CSV formatted input file. This example is a good one for developers to get an idea about how to do this.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/057_reading_nested_tuple_data_via_file_source_com_acme_test_Test1_spl",
	"urlLink": "",
	"tags": ["filesource", "parse", " nested tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "016_aggregate_at_work",
	"description": "This example shows off yet another powerful standard toolkit operator named the Aggregate. It is very good in computing on the fly aggregate values after collecting a set of tuples. Tuples are grouped based on tumbling and sliding windows with partitioned variants. This example also shows how to use the built-in assignment functions provided by this operator to compute regular statistical calculations such as min, max, average, standard deviation etc.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/016_aggregate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["aggregate", "aggregate", "rolling average", "windowing", "average", "window"]
}, {
	"State": "live",
	"name": "020_metrics_sink_at_work",
	"description": "This example shows how one can use the MetricsSink standard toolkit operator to create application-specific custom metrics that can be viewed in real-time when the application is running. Viewing of custom metrics is typically done inside Streams Explorer view of the Streams Studio or by using the capturestate option in streamtool.",
	"language": ["SPL"],
	"category": ["Monitoring", "metrics"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/020_metrics_sink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["metricssink", "metrics", "custom metrics", "application monitoring", "custom statistics"]
}, {
	"State": "live",
	"name": "002_source_sink_at_work",
	"description": "This example shows how a FileSource operator can be used to read CSV formatted records from a file and then receive those tuples in a FileSink to be written to a file in the data directory of this application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/002_source_sink_at_work_sample_source_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", " ", "filesink"]
}, {
	"State": "live",
	"name": "026_gate_at_work",
	"description": "This is an example that uses the Gate operator from the standard toolkit. This operator delays the incoming tuples until a downstream operator signals with an acknowledgment to receive any further tuples. This is a great way to have a feedback through which we can control the rate at which tuples are passed through. (Please refer to another example named 905_gate_load_balancer that shows the effectiveness of the Gate operator in combination with the ThreadedSplit operator to provide load balancing the incoming tuples.)",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/026_gate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["gate", "wait", " hold tuples until signal", "control tuple flow", "wait for tuples"]
}, {
	"State": "live",
	"name": "050_recursive_dir_scan",
	"description": "This example shows how to use the Streams C++ native function facility to recursively scan a given directory and obtain the names of the files present. The logic for the recursive directory scan polls the specified directory periodically and notifies the downstream operator with a new file that just appeared. There is a companion C++ project for this SPL project. Please refer to the RecursiveDirScanLib project for the C++ logic.Important sequence of logic for this application: 1) SPL code resolves the C++ native function in its native.function/function.xml file.2) A call from the SPL code to the native function lands in the wrapper inline C++ function defined in the RecursiveDirScanWrappers.h file of the companion C++ project.3) From that wrapper function, it gets access to a singleton C++ object of the RecursiveDirScan class and then invokes the getFileNamesInDirectory C++ method.4) When that C++ method returns, it will have the results stored in a list<string> reference that was passed to it.5) Back in the SPL code, there is additional logic to cache the already seen files and to filter only the newly found files to send to the downstream operator.In order to test this application, please refer to the commentary at the top of the SPL file in this project.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED RecursiveDirScanLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/050_recursive_dir_scan_recursive_dir_scan_recursive_dir_scan_spl",
	"urlLink": "",
	"tags": ["recursive directory scan in c++", "c++ native functions example", "c++", "application development"]
}, {
	"State": "live",
	"name": "005_throttle_at_work",
	"description": "This example shows how a stream can be throttled to flow at a specified rate. This example also mixes other operators such as Beacon, Custom, and FileSink.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/005_throttle_at_work_sample_throttle_at_work_spl",
	"urlLink": "",
	"tags": ["custom", " throttle", " slow down", "delay", " create tuple", " custom", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "004_delay_at_work",
	"description": "This example shows how a Delay standard toolkit operator can be used to delay a stream. This example also introduces the Custom operator that can be used to perform custom logic. You can also notice the use of a state variable that is mutable inside the Custom operator. It also shows how to create a new tuple on the fly and do your own submissions onto the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/004_delay_at_work_sample_delay_at_work_spl",
	"urlLink": "",
	"tags": ["custom", "delay", "filesink"]
}, {
	"State": "live",
	"name": "019_import_export_at_work",
	"description": "This example demonstrates how two different SPL applications can share streams between them. This is an important feature that is elegantly done using two pseudo operators called Export and Import. This application also shows how two different main composites can be part of the same application by using two different namespaces. As an aside, there is also a demonstration of using a Custom operator to customize the Beacon generated tuples by involving state variables. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/019_import_export_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["import", "export", "microservices", "export stream", "import stream"]
}, {
	"State": "live",
	"name": "033_java_primitive_operator_at_work",
	"description": "This example shows how a Java primitive operator is created from scratch. Java primitive operator is different from JavaOp that you have seen earlier in a different example. Java primitive operator is a first class operator in SPL, whereas JavaOp only permits a callout to another Java operator. In addition, Java primitive operator has the advantage of keeping its name as the operator\u2019s runtime instance name.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT NAMED RSS_Reader_Primitive THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/033_java_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["java operator", " primitive java operator", "java operators", " application development"]
}, {
	"State": "live",
	"name": "043_import_export_filter_at_work",
	"description": "This example shows how to use the SPL feature to apply a filter for what gets exported and what gets imported. This powerful feature lets the downstream import operators to specify what kind of tuples they want to receive by specifying conditional expressions involving tuple attributes. That lets the Streams runtime to apply content-based filtering at the point of export. Those who need such a feature to control what information should be sent downstream based on the tuple contents can make use of this flexible feature. This can be done on the fly without stopping and restarting the application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/043_import_export_filter_at_work_importing_exporting_filter_import_with_filter_spl",
	"urlLink": "",
	"tags": ["import", "export", "filtered import", "dynamic import", "microservices", "export stream", " filter imports", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "017_filesource_filesink_at_work",
	"description": "We have used the FileSource and the FileSink operators in other examples before. However, this example shows off the following intriguing features that will become handy in a lot of practical situations.a) Automatic deletion of a file after the FileSource finishes reading all the records.b) Flushing the sink file on demand after writing a certain number of tuples.c) Ability of the FileSource to move the file once it reads all the content in that file.d) Creating a fresh and new output sink file after writing a certain number of tuples.e) Ability of the FileSource to keep reading from a hot file as new CSV records get written to the end of that file.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/017_filesource_filesink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "advanced file operations", " reread file", "move file", " hot file", "flushing", " automatic deletion", "delete a file"]
}, {
	"State": "live",
	"name": "008_get_submission_time_value",
	"description": "This example shows how the tuple attributes can be assigned values that were supplied by the user at the application/job submission time. It employs the getSubmissionTimeValue function to obtain different values made of different SPL data types. ",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/008_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["functor", "getsubmissiontimevalue", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "014_sort_at_work",
	"description": "This example shows the use of the Sort operator in the context of an application. Sort operator is highly configurable with all kinds of windowing support. In this example, the following window configurations are applied for sorting the incoming tuples:a) Count-based tumbling window.b) Time-based tumbling window.c) Punctuation-based tumbling window.d) Delta-based tumbling window.e) Count-based sliding window.",
	"language": ["SPL"],
	"category": ["transform", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/014_sort_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["sort", " Time-based", " delta based", "time based", " punctuation-based Count based", "sort", " tumbling window", " sliding window", " punctuation based", " sort with windowing", " count-based"]
}, {
	"State": "live",
	"name": "027_java_op_at_work",
	"description": "This example shows an important operator that brings Java into the C++ dominated world of Streams!!! That operator is called JavaOp, which is used to call out to other operators implemented in Java using the Java Operator API. In this example, we will have a tiny Java logic that will calculate the current time and add that time string to a tuple attribute and output that tuple. There is another example that shows the Java primitive operator that is different from the JavaOp operator.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/027_java_op_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in and C++ primitive operators that are NOT fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["dps", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "dps", "c++", "share data"]
}, {
	"State": "live",
	"name": "053_java_primitive_operator_with_complex_output_tuple_types",
	"description": "This example shows important features that can be done via a Java primitive operator. It shows how to do tracing and logging inside a Java operator. It also shows how we can create an output tuple inside a Java primitive operator to have a list of tuple objects carrying complex typed attributes.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT CALLED Java_Complex_Tuple_Type_Submission THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/053_java_primitive_operator_with_complex_output_tuple_types_com_acme_test_java_primitive_operator_with_complex_output_tuple_types_spl",
	"urlLink": "",
	"tags": [" submit tuple from java", "tuple in java operator", "tuple", "complex tuple", " java operator"]
}, {
	"State": "live",
	"name": "035_c++_primitive_operator_at_work",
	"description": "This example shows the steps required to create a C++ primitive operator from scratch. In this application, a C++ primitive operator model XML file can be explored to learn how the different fields in that file are configured. Then, the code generation template header and implementation files (*_h.cgt and *_cpp.cgt) can be browsed to learn about the primitive operator logic. Additionally, this example demonstrates about including a Java operator and a C++ primitive operator as part of the application flow.",
	"language": ["C++"],
	"category": ["Operators & Functions", " Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/035_c++_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["c++ operators", "c++ example", "c++ operator model", " application development"]
}, {
	"State": "live",
	"name": "037_odbc_adapters_for_solid_db_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters for connecting to a SolidDB in-memory database. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test SolidDB database inside IBM. You have to create your own SolidDB database and tables to make this application work in your environment.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/037_odbc_adapters_for_solid_db_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "soliddb"]
}, {
	"State": "live",
	"name": "061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators that are not fused with each other and a C++ native function. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "hsa", "java", "native function", "db", "query"]
}, {
	"State": "live",
	"name": "006_barrier_at_work",
	"description": "This example shows how to synchronize the incoming tuples using a Barrier operator. It uses a bank deposit/debit scenario to split the deposit/debit requests, perform that account activity, and then combine the post-activity result with the incoming requests. Barrier operator does what is needed to accomplish that i.e. it waits for the streams to arrive at all the configured input ports before emitting an output tuple.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/006_barrier_at_work_sample_barrier_at_work_spl",
	"urlLink": "",
	"tags": ["barrier", "functor", "custom", " slow down stream", "delay", "create tuple", "slow down tuples", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "015_join_at_work",
	"description": "This example shows one of the power-packed standard toolkit operators; i.e. Join. This operator is so versatile that it is hard to do justice in explaining it thoroughly in a simple example such as this one.  This example provides coverage to the following Join operator features.a) Inner Join,b) Inner (Equi) Join,c) Left Outer Join,d) Right Outer Join,e) Full Outer Join",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/015_join_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["join", " inner join", "merge stream", "join", " join stream"]
}, {
	"State": "live",
	"name": "031_spl_mixed_mode_at_work",
	"description": "This example shows a cool SPL feature called mixed-mode support. In this, developers can mix PERL code islands inside of an SPL application. Mixed-mode enables the easy parameterization of SPL applications. This example gives a slight flavor of how a PERL code snippet inter-mixed with SPL allows us to parameterize the SPL Stream names and the number of output stream definitions for an SPL operator. ",
	"language": ["perl"],
	"category": ["Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/031_spl_mixed_mode_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["mixed mode", "spl", "mixed mode", "code generation"]
}, {
	"State": "live",
	"name": "047_streams_host_tags_at_work",
	"description": "This example shows how to create host tags for a given Streams instance and then use those host tags inside an SPL application. By using host tags, it is possible to avoid hard-coding the host names inside the SPL application code. Detailed instructions about creating and using host tags are explained in this example.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/047_streams_host_tags_at_work_host_tags_streams_host_tags_at_work_spl",
	"urlLink": "",
	"tags": ["tcpsink", "tcpsource", "host tags", "operator placement", "tcpsink", "tcpsource", "config clause", "host pools"]
}, {
	"State": "live",
	"name": "049_json_to_tuple_to_json_using_java",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished via two Java primitive operators that make use of the JSON (Java) libraries shipped as part of the Streams product. Those two Java operators are JSONToTuple and TupleToJSON.Note: Performance of the JSON<-->Tuple conversion in this example will be limited by the speed of your Java environment. If you want to get better performance, C++ code would help. There is a separate example (055_json_to_tuple_to_json_using_c++) that shows how to do this conversion using C++.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/049_json_to_tuple_to_json_using_java_sample_Main_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "json", " parse json"]
}, {
	"State": "live",
	"name": "046_launching_external_apps_in_spl",
	"description": "This example shows how to launch/execute an external application within the Streams SPL code. In this case, we defined a simple C++ native function in which we have the required C++ code to launch an external application. That C++ code uses pipes to execute a given application. This function would be useful to launch any custom script within the Streams application logic when certain application specific conditions arise.",
	"language": ["C++"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/046_launching_external_apps_in_spl_launch_external_apps_launching_external_apps_spl",
	"urlLink": "",
	"tags": ["launch an external app", " spl utility functions", "launch a program", "execute program"]
}, {
	"State": "live",
	"name": "059_dynamic_scaleout_of_streams_application",
	"description": "This example shows a particular style of writing Streams applications that can be scaled up or scaled down as the application input workload changes. It uses a familiar scenario from the Financial Services Sector, where the price calculation engines will require scaling up when the market data load increases. Code written in this example uses a pattern for starting more instances of an analytic operator to increase parallelism. New instances of such analytic operators can be started on demand without disrupting the already running application flow. As soon as the newly started operator instances are ready, application load will be promptly distributed across the existing and the newly started instances of that operator. In the same way, when the application data load is not high, some of the most recently started operator instances can be stopped to release the CPU cores for other use. This technique is one of many ways to design Streams applications that will scale up and down dynamically according to the changing input data workload.",
	"language": ["C++"],
	"category": ["Tips,Best Practices,Microservices,Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/059_dynamic_scaleout_of_streams_application_com_ibm_streams_pricing_test_DynamicScaleOut_spl",
	"urlLink": "",
	"tags": ["import", "export", "ingest"]
}, {
	"State": "live",
	"name": "009_custom_operator_using_get_submission_time_value",
	"description": "This example demonstrates how to assign tuple attributes at the time of job submission inside a custom operator. When the incoming tuples arrive at the Custom operator in this example, values entered by the user at the application startup are assigned to the tuple attributes.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/009_custom_operator_using_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["custom", "getsubmissiontimevalue", "get submission time value", " submission time", "parameter lists", " parameters", " custom", "create tuple"]
}, {
	"State": "live",
	"name": "012_filter_functor_at_work",
	"description": "This example puts the two commonly used standard toolkit operators to work. They are Filter and Functor. Filter allows you to route tuples based on conditional checks. It provides two output ports to send the matched tuples on the first output port and the unmatched tuples on the second output port. Functor operator allows us to transform the incoming tuple attributes and then to send it on many different output ports with different stream schemas.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/012_filter_functor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["functor", "filter", "filter tuples", "remove tuples"]
}, {
	"State": "live",
	"name": "022_deduplicate_at_work",
	"description": "This example describes the use of an important operator that is highly applicable in many Telco scenarios. That operator is called DeDuplicate, which eliminates duplicate tuples for a specified duration of time. It also has an optional second output port on which duplicate tuples could be sent out for additional processing.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/022_deduplicate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["deduplicate", "separate two streams", "remove duplicates", "split streams"]
}, {
	"State": "live",
	"name": "013_punctor_at_work",
	"description": "This example shows how a Punctor operator could be used in an application. Punctor operator allows us to transform the input tuples and then inject puncuation markers either before or after the output tuple as configured.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/013_punctor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["punctor", "custom logic", " generate punctuation", " punctuation"]
}, {
	"State": "live",
	"name": "036_shared_lib_primitive_operator_at_work",
	"description": "This example demonstrates two important techniques that will be commonly used in real-world use cases.1) Creating a C++ primitive operator.2) Calling a function available inside a .so shared library from the C++ primitive operator logic.Application logic here is to receive input tuples as hostnames and then make the C++ primitive operator logic invoke a shared library function that does a name server lookup.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED PrimitiveOperatorLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/036_shared_lib_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" c++", " operator dependencies", " library", "shared library", " application development"]
}, {
	"State": "live",
	"name": "003_sink_at_work",
	"description": "This example shows how FileSink and Custom sinks can be employed in applications. It also shows how a Beacon operator can be used to customize tuple attributes. In addition, it introduces the Filter operator to route the incoming tuples by inspecting their attributes using a conditional statement specified in the filter parameter. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/003_sink_at_work_sample_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "read", "files", "write"]
}, {
	"State": "live",
	"name": "023_union_at_work",
	"description": "This example demonstrates an utility operator called Union. This operator combines all the tuples from several input ports as they arrive and emits a single output stream. All the input ports must have a schema that contains attributes of the same name and type as those of the output port. The order of the attributes in the input ports need not match the order in the output port.",
	"language": ["SPL"],
	"category": ["enrich", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/023_union_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["union", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "044_streams_checkpointing_at_work",
	"description": "This example shows a key feature of Streams by which an operator's state variables can be preserved when a PE fails and gets restarted. This is done through a combination of the SPL configuration directives named 'checkpointing' and 'restartable'. Developers can protect their critical operator data by taking advantage of this built-in checkpointing feature. When you run this example, you will see data flows without any gaps or interruption, when a PE is killed manually and then gets restored automatically by the Streams runtime.",
	"language": ["SPL"],
	"category": ["performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/044_streams_checkpointing_at_work_checkpointing_example_streams_checkpointing_at_work_spl",
	"urlLink": "",
	"tags": ["checkpoint config clause", " data consistency", "automatic checkpointing", " fail over", "checkpoint"]
}, {
	"State": "live",
	"name": "001_hello_world_in_spl",
	"description": "This example is the simplest possible SPL application. It uses a Beacon operator to generate tuples that carry Hello World' messages. A custom sink operator receives the tuples from Beacon and displays it on the console.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/001_hello_world_in_spl_HelloWorld_spl",
	"urlLink": "",
	"tags": ["custom"]
}, {
	"State": "live",
	"name": "038_spl_built_in_functions_at_work",
	"description": "This is a very simple example that showcases a random collection of powerful built-in SPL functions that are available out of the box. This application demonstrates how time, math, and collection type functions can be used inside of an SPL application.",
	"language": ["SPL"],
	"category": ["Best Practices", "Collections and Data Types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/038_spl_built_in_functions_at_work_test_scratch_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "data types", " spl functions", "list", " mutable", " convert time stamp", "map", " convert timestamp", " timestamps", " utility functions"]
}, {
	"State": "live",
	"name": "056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example shows a particular implementation about how data can be shared across multiple FUSED operators using an SPL map based in-memory store. Here, we are simply showing a way to use the SPL native function facility to perform data sharing via an SPL map based in-memory store that will serve multiple SPL standard toolkit operators and C++ primitive operators. As mentioned above, this example shows data sharing between multiple operators that are fused inside a single PE (Processing Element). This technical approach is called Process Store (ps). This data sharing mechanism will NOT work between operators that are on different PEs. This example depends on the com.ibm.streamsx.ps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "db", "query"]
}, {
	"State": "live",
	"name": "034_odbc_adapters_for_db2_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test DB2 database inside IBM. You have to create your own DB2 database and tables to make this application work in your environment. After creating your own database and tables, you have to change the etc/connections.xml file in this application's directory to match your database/table names, userid, and password. You also have to make changes in the SPL code using your database information for all the three ODBC operator invocations.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/034_odbc_adapters_for_db2_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "db2"]
}, {
	"State": "live",
	"name": "051_native_functions_with_collection_types",
	"description": "This example shows an important feature of Streams. In Streams applications, it may be necessary to accept and return collection types in and out of the C++ native functions. This will require native function code that can directly deal with types such as list, map, and tuple. Streams provides C++ reflection APIs to directly deal with such collection types. In this example, developers can learn how to build native functions inside of a C++ class and then pass list, map, and tuple types to those native functions. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionsWithCollectionTypesLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/051_native_functions_with_collection_types_com_ibm_nf_test_native_functions_with_collection_types_spl",
	"urlLink": "",
	"tags": [" data types", "native functions", "collections", "list", "c++ native functions example", "c++", "map", " collections", "application development", "tuple"]
}, {
	"State": "live",
	"name": "040_ingest_data_generation_in_spl",
	"description": "This example shows how SPL provides rich features to generate synthetic data required for large scale testing. Many real-life applications in the Telco and the Retail Banking sectors consume large amounts of daily business data through CSV formatted text files. There could be huge amounts of CDR data from several telecom circles or daily transaction data for millions of accounts in a retail bank.While building and testing the SPL applications, it will become necessary to generate such ingest data files with artificial data that is close enough to be realistic. This application shows how such large amounts of data in several thousands of files can be created very quickly using the SPL standard toolkit operators as well as the SPL file IO and math random built-in functions.",
	"language": ["SPL"],
	"category": ["Collections & Data types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/040_ingest_data_generation_in_spl_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["test data generation", "data types", " test data generation", "sample data", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "025_dynamic_filter_at_work",
	"description": "This example deals with an interesting standard toolkit operator called DynamicFilter. This operator is a special version of the Filter operator that you have already seen in another example; it decides at runtime which input tuples will be passed through, based on the control input it receives. This operator is applicable in many real-life scenarios. This example also demonstrates using a second composite operator to perform a sub-task that the main composite will make use of. There is also coverage to show how the second composite can take its own operator parameters.  ",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/025_dynamic_filter_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["dynamicfilter", " reusable composite", "composite operators", " filter based on input", " dynamic filter", "filter"]
}, {
	"State": "live",
	"name": "062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators and a Java primitive operator that are not fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples. In this SPL project, you will find a Java primitive operator that exercises all the dps APIs in a very comprehensive manner. In order to get access to the dps APIs, this project's build path is added with dps-helper.jar available inside the com.ibm.streamsx.dps toolkit directory (i.e. impl/java/bin). Please read at the top of this project's SPL file and the TickerIdGenerator.java primitive operator file for an extensive commentary about how to run this example.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["java database", "database", "redis", "hsa", "java", "mongo", "db", "query"]
}, {
	"State": "live",
	"name": "063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators",
	"description": "This example shows how to create a tuple on the fly inside a Java primitive operator. In addition, this example also shows how to convert a tuple into a blob (Java byte buffer) and how to convert a blob (Java byte buffer) in to a tuple. It is an interesting concept that a Java primitive operator developer can put into use in certain situations that warrant dynamic tuple creation, tuple encoding and decoding all inside Java.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators_application_Main_spl",
	"urlLink": "",
	"tags": ["create tuple in java", "java", "blob", "blob java", "create tuple"]
}, {
	"State": "live",
	"name": "064_using_spl_composite_params",
	"description": "This example shows different ways in which parameters can be passed to SPL composites. It is very useful to pass parameters as attributes, expressions, functions, operators, and types. These different ways of passing parameters to the composites is the focus of this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/064_using_spl_composite_params_com_acme_test_CompositeParams_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "065_using_multiple_threads_in_java_operator",
	"description": "This example shows how to spawn multiple threads within a Java primitive operator and then submit tuples from within those threads concurrently.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/065_using_multiple_threads_in_java_operator_com_acme_test_JavaOpSubmitFromMultipleThreads_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "066_load_balancing_using_gate",
	"description": "As documented in the Streams Info Center for a ThreadedSplit, if the processing time of a tuple varies considerably depending on the tuple data, it may cause problems where a tuple with a long processing time may cause subsequent tuples to be backed up in the stream. This example shows how a Gate operator can be combined with the ThreadedSplit can be used to ensure load balancing.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/066_load_balancing_using_gate_com_acme_test_LoadBalancingUsingGate_spl",
	"urlLink": "",
	"tags": ["gate"]
}, {
	"State": "live",
	"name": "067_simple_java_source_operator",
	"description": "This example shows a basic source operator implemented in Java. There are specific steps required for implementing a source operator and it can be learned in this example.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/067_simple_java_source_operator_com_acme_test_Temp1_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "068_tuple_introspection_inside_java_operator",
	"description": "This example shows how a tuple can be introspected to learn about its structure and its attribute names and their types. Inside a Java operator, this example illustrates how it is possible to recursively look through a tuple to understand its composition.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/068_tuple_introspection_inside_java_operator_com_acme_test_Temp2_spl",
	"urlLink": "",
	"tags": ["parse tuple in java", "tuples", " collections", "tuples java", " java operator", "spl data types"]
}, {
	"State": "live",
	"name": "069_changing_map_value_during_iteration",
	"description": "Until the release of Streams version 3.2.1, it was not possible to modify the value of a map inside an iteration loop. This example shows a new feature available in Streams version 3.2.1 that permits the value of a map to be modified inside a for loop.",
	"language": ["SPL"],
	"category": ["Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/069_changing_map_value_during_iteration_com_acme_test_ChangeCollectionValue_spl",
	"urlLink": "",
	"tags": ["iterate over map", "iteration", "change map value", "change map"]
}, {
	"State": "live",
	"name": "070_convert_block_data_into_tuples_using_parse",
	"description": "This example shows how a block of data ingested as a blob type can be converted into individual tuples using the Parse operator.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/070_convert_block_data_into_tuples_using_parse_com_acme_test_ConvertBlockDataWithParse_spl",
	"urlLink": "",
	"tags": ["parse", "parse operator", "parse blob", " convert blob to tuple", "tuples"]
}, {
	"State": "live",
	"name": "071_java_native_functions",
	"description": "Java native functions provide a cool way to add user-defined functions in Java and then call them directly within the SPL code. This example shows how easy it is to create java native functions.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/071_java_native_functions_com_acme_test_JavaNativeFunctions_spl",
	"urlLink": "",
	"tags": ["create java native function", "java function"]
}, {
	"State": "live",
	"name": "072_using_streams_rest_apis",
	"description": "Streams provides REST APIs to query different kinds of metrics about the instances, jobs, resources during the runtime operation. It is a comprehensive set of APIs that can be used with proper security configuration. This example shows a few different REST APIs in action by invoking them within Java code.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/072_using_streams_rest_apis_com_acme_test_UsingStreamsRestApis_spl",
	"urlLink": "",
	"tags": ["get job info", "monitoring", "rest", "rest api example", "jobs"]
}, {
	"State": "live",
	"name": "073_java_operator_fusion",
	"description": "This example shows how two different Java operators one performing the Sink operation and the other performing the analytics operation can be fused to operate within a single PE.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/073_java_operator_fusion_com_acme_test_JavaFusion_spl",
	"urlLink": "",
	"tags": ["java operator fusion", " ", "fuse multiple operators"]
}, {
	"State": "live",
	"name": "074_user_defined_parallelism_01",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/074_user_defined_parallelism_01_com_acme_test_UDP1_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "075_user_defined_parallelism_02",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/075_user_defined_parallelism_02_com_acme_test_UDP2_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "076_user_defined_parallelism_03",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/076_user_defined_parallelism_03_com_acme_test_UDP3_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "077_user_defined_parallelism_04",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/077_user_defined_parallelism_04_com_acme_test_UDP4_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "078_user_defined_parallelism_05",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/078_user_defined_parallelism_05_com_acme_test_UDP5_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "079_user_defined_parallelism_06",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/079_user_defined_parallelism_06_com_acme_test_UDP6_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "080_user_defined_parallelism_07",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/080_user_defined_parallelism_07_com_acme_test_UDP7_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "081_user_defined_parallelism_08",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/081_user_defined_parallelism_08_com_acme_test_UDP8_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "083_user_defined_parallelism_10",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/083_user_defined_parallelism_10_com_acme_test_UDP10_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "084_user_defined_parallelism_11",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/084_user_defined_parallelism_11_com_acme_test_UDP11_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "085_user_defined_parallelism_12",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/085_user_defined_parallelism_12_com_acme_test_UDP12_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "086_jms_source_sink_using_activemq",
	"description": "This example shows how the JMSSource and JMSSink operators from the Streams standard toolkit can be put to use for sending messages from Streams into the Apache ActiveMQ queues and topics as well as reading messages from there into Streams.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/086_jms_source_sink_using_activemq_com_acme_test_JMSSourceSink_spl",
	"urlLink": "",
	"tags": ["jmssource", "jmssink", "activemq", "jms", "read from activemq", "messaging server", "messaging"]
}, {
	"State": "live",
	"name": "087_email_alerts_via_java_native_function",
	"description": "This example shows a way to send email alerts from an SPL application. It is done via a Java native function by using the email API available in the standard Java platform. If an SMTP server is present in the same   network where Streams servers are connected, the technique shown in this example can be put to use for sending email alerts.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/087_email_alerts_via_java_native_function_com_acme_test_EmailAlerts_spl",
	"urlLink": "",
	"tags": ["send email", "email", "send email java"]
}, {
	"State": "live",
	"name": "088_java_operator_params_and_multiple_input_output_ports",
	"description": "This example demonstrates two different features of the Java primitive operator framework. It first shows how operator parameters can be easily processed inside the Java operators via the @Parameter annotations. Then, it shows how multiple input and output ports can be accessed inside the Java operators. As a bonus, it also shows a better approach for on the fly creation of the output tuples made with complex nested types.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/088_java_operator_params_and_multiple_input_output_ports_com_acme_test_JavaOperatorParams_spl",
	"urlLink": "",
	"tags": [" complex tuple", "java operator", "java operator parameters", "java", "java operator", "multiple input ports", "create tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "089_integrating_streams_apps_with_web_apps",
	"description": "This example demonstrates one of the Streams open source toolkits (com.ibm.streamsx.inet). Using this toolkit one can integrate Streams applications with web applications. Please read the comments in the SPL file for this example project to download that toolkit, install it, and then use that toolkit inside a simple SPL application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/089_integrating_streams_apps_with_web_apps_com_acme_test_WebCalculator_spl",
	"urlLink": "",
	"tags": ["httptupleinjection", "httptupleview", "send tuples to browser", "rest", "post to streams app", "streams web app"]
}, {
	"State": "live",
	"name": "090_consistent_region_spl_01",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/090_consistent_region_spl_01_com_acme_test_ConsistentRegion1_spl",
	"urlLink": "",
	"tags": ["filesource"]
}, {
	"State": "live",
	"name": "091_consistent_region_spl_02",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a FileSource with a periodic checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/091_consistent_region_spl_02_com_acme_test_ConsistentRegion2_spl",
	"urlLink": "",
	"tags": ["beacon"]
}, {
	"State": "live",
	"name": "092_consistent_region_spl_03",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the Aggregate operators in this application is forcefully aborted inside the application multiple times to prove that application survive those multiple crashes at different times and yet will continue processing tuples normally after an automatic restart of that failed operator. In addition, during those crashes Streams will preserve the windows contents of that Aggregate operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/092_consistent_region_spl_03_com_acme_test_ConsistentRegion3_spl",
	"urlLink": "",
	"tags": ["aggregate", "consistent region window", "consistent region"]
}, {
	"State": "live",
	"name": "093_consistent_region_spl_04",
	"description": "This example demonstrates how a consistent region can be defined for two different composites acting as sources for this application. These consistent regions have a periodic checkpoint trigger. Couple of different Custom operators connected to those sources are forcefully aborted inside the application. Output streams of those operators will be combined using a Join operator. This application will ensure that the application will continue normally without losing any tuples by withstanding the random crash of those two Custom operators.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/093_consistent_region_spl_04_com_acme_test_ConsistentRegion4_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "094_consistent_region_spl_05",
	"description": "This particular example shows how only a portion of the topology will take part in the consistent region by having an autonomous section in the application graph. This example simulates the operator failure by aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Join operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration. At the same time, parts of the application that is in the autonomous area will get duplicate tuples during a crash recovery happening in the consistent region of this application graph. This example's purpose is to make the users aware of this fact. In the autonomous area, measures need to be taken to do deduplication.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/094_consistent_region_spl_05_com_acme_test_ConsistentRegion5_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "095_consistent_region_spl_06",
	"description": "This particular example shows how a non-replay capable Source operator will not be a show stopper when it comes to employing the consistent region feature in such applications. When using sources (such as TCPSource) that can't realistically replay data, there is way to configure your application with consistent region by using an utility operator called ReplaybleStart (shipped with the Streams product). In this example, we will use a topology that uses TCPSource along with ReplayableStart to achieve application-level fault tolerance.  This example simulates the operator failure by  aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Aggregate operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/095_consistent_region_spl_06_com_acme_test_ConsistentRegion6_spl",
	"urlLink": "",
	"tags": ["replayablestart", "enabling consistent regions when the source operator deos not support it", "failure", "crash", "high availability", "guaranteed processing", "replayablestart"]
}, {
	"State": "live",
	"name": "100_using_jmx_api_01",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to query information about the Streams domain and the Streams instance.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/100_using_jmx_api_01",
	"urlLink": "",
	"tags": ["jmx api", " jmx", " monitoring", "domains"]
}, {
	"State": "live",
	"name": "101_using_jmx_api_02",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to fetch the bulk contents from a log file for a given domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/101_using_jmx_api_02",
	"urlLink": "",
	"tags": ["jmx api", "monitoring", "get log file using jmx"]
}, {
	"State": "live",
	"name": "102_using_jmx_api_03",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX API notifications to get alerted via callback functions about an inactivity timeout in a given Streams domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/102_using_jmx_api_03",
	"urlLink": "",
	"tags": [" use jmx to get alerts", " monitoring", "jmx"]
}, {
	"State": "live",
	"name": "103_view_annotation_at_work",
	"description": "This is a simple SPL application that explains the steps required to use the view annotation and then how to visualize the view annotated stream in the Streams web console. Detailed steps to view the annotated stream are shown in the commentary section of this SPL file.",
	"language": ["SPL"],
	"category": ["Visualization and Reporting"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/103_view_annotation_at_work_com_acme_test_ViewAnnotationAtWork_spl",
	"urlLink": "",
	"tags": ["microsoft excel", "console", "view annotation", "views example", "reporting", "views", "visualization", "visualize", "application development"]
}, {
	"State": "live",
	"name": "901_cat_example",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/901_cat_example_NumberedCat_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "902_word_count",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/902_word_count_word_count_WordCount_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "903_unique",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/903_unique_Main_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "904_primitive_round_robin_split",
	"description": "SPL Introductory Tutorial sample",
	"language": ["C++"],
	"category": ["Beginner/General", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/904_primitive_round_robin_split_Main_spl",
	"urlLink": "",
	"tags": ["pair", "spl"]
}, {
	"State": "live",
	"name": "905_gate_load_balancer",
	"description": "SPL Introductory Tutorial sample\"",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/905_gate_load_balancer_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "gate", "improve performance", " gate operator", "threadedsplit", " threadedsplit operator", "gate"]
}
,{
	"State": "live",
	"name": "021_pair_at_work",
	"description": "This example shows off the Pair operator that is used for pairing tuples arriving on different input ports. Only when all the tuples arrive at all the input ports, this operator will emit them one after the other in their order of arrival.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/021_pair_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["pair", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "'096_consistent_region_spl_07",
	"description": "This particular example shows how a C++ primitive operator can play a role inside a consistent region.  It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/096_consistent_region_cpp_07_com_acme_test_ConsistentRegion7_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "097_consistent_region_spl_08",
	"description": "This particular example shows how a C++ primitive operator can be the start of a consistent region.   It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/097_consistent_region_cpp_08_com_acme_test_ConsistentRegion8_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "098_consistent_region_spl_09",
	"description": "This particular example shows how a Java primitive operator can be the start of a consistent region. ",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/098_consistent_region_java_09_com_acme_test_ConsistentRegion9_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "099_consistent_region_spl_10",
	"description": "This particular example shows how a Java primitive operator can play a role inside a consistent region. It demonstrates how to implement the necessary callback functions to support checkpoint and reset.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/099_consistent_region_java_10_com_acme_test_ConsistentRegion10_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "052_streams_to_python",
	"description": "This example shows a powerful feature of Streams to wrap existing code assets written using the Python programming language. This example teaches developers how to use the Streams C++ native functions to call any arbitrary Python function and return the results back to SPL code. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory. You can also read a very detailed IBM developerWorks technical article about this example:  http://tinyurl.com/c3s56fq. [THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED StreamsToPythonLib THAT IS DESCRIBED BELOW.]",
	"language": ["Python"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/052_streams_to_python_python_wrapper_example_streams_to_python_spl",
	"urlLink": "",
	"tags": ["call python from streams", "call python from cpp", " python"]
}, {
	"State": "live",
	"name": "042_dynamic_import_export_api_at_work",
	"description": "This example shows how to use the SPL APIs for dynamically importing and exporting streams. This is achieved by changing the import and export properties on the fly. This powerful feature in Streams provides a way to change the streams producing and consuming operators to change the way in which they publish and subscribe to streams while the application is running.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/042_dynamic_import_export_api_at_work_dynamic_importing_exporting_dynamic_import_spl",
	"urlLink": "",
	"tags": ["import", "export", "dynamic import", "microservices", "export stream", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "045_file_source_using_spl_custom_operator",
	"description": "This example shows how to create source operators using the Custom operator available in the SPL standard toolkit. Starting in Streams 3.x, it is possible to create source operators without writing primitive source operators in C++ or Java. Simple source operators can be written using the built-in SPL Custom operator. This will come handy for those who don't want to do an extra layer of C++ or Java code for satisfying simple needs for a source operator. You will see a function of a file source operator being implemented all using SPL code in this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions,Ingest & Store Data", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/045_file_source_using_spl_custom_operator_my_file_source_file_source_using_spl_custom_operator_spl",
	"urlLink": "",
	"tags": ["read a file using a custom", "custom", "read a file", "filesource", "open a file", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "032_native_function_at_work",
	"description": "This application shows how native functions written in C++ can be called within an SPL application.There are two ways in which native functions can be written in C++.1) Code for the C++ functions can be written in a C++ header file.2) C++ functions can be written outside of the SPL project and packaged into a shared library (.so) file. All the SPL developer will have to work with are an .so file and a C++ header file.This application demonstrates incorporating native functions built in both of those ways.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/032_native_function_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["native functions", " c++", "native functions", " native function model"]
}, {
	"State": "live",
	"name": "018_directory_scan_at_work",
	"description": "This example demonstrates one of the important features desired in the real world (mostly in the Retail banking and in the Telco industries). In many real-world scenarios, they still work via files and such files get dropped into a directory for processing. It is shown here how the DirectoryScan operator picks up a new file as soon as it appears inside an input directory. (Apply caution if huge files are copied to the watch directory. DirectoryScan may detect that big file copy as multiple new files and output multiple tuples with the same file name.)",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/018_directory_scan_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["directoryscan", "read directory repeatedly", "scan directory", "list directory"]
}, {
	"State": "live",
	"name": "011_compiler_intrinsic_functions",
	"description": "Streams compiler provides several intrinsic functions to query the SPL filename, file path, absolute path of the directory, source code line number, composite instance name etc. This example shows the use of the compiler intrinsic functions inside of a Functor operator.",
	"language": ["SPL"],
	"category": ["troubleshooting", " Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/011_compiler_intrinsic_functions_Main_spl",
	"urlLink": "",
	"tags": ["compiler functions", " utility", "print line number", " current line number", " print line number", " print file name", " get file name", " print debug info"]
}, {
	"State": "live",
	"name": "041_real_time_streams_merger",
	"description": "This example shows how two or more incoming streams with a common schema can be merged to flow in a sequence one after the other. This merger is done using a common tuple attribute in those multiple incoming streams as a key. We will use a C++ primitive operator called OrderedMerger that is included in this project. In order for the OrderedMerger to work correctly, it is assumed that multiple input streams for this primitive operator should already be in sorted order based on the key used to merge and sequence them together. ",
	"language": ["C++"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/041_real_time_streams_merger_real_time_merger_real_time_streams_merger_spl",
	"urlLink": "",
	"tags": ["ordered merge of multiple streams ", "c++ example", "merge  streams", " join streams", " c++ operator model", " application development", " ordered merge"]
}, {
	"State": "live",
	"name": "060_simple_pe_failover_technique_at_work",
	"description": "This example shows a way to protect the logic in an analytic operator  when its PE (Processing Element) or its host machine crashes. It uses a well-known fail-over technique that is done through a primary/secondary pair configured for an operator that will need safety from PE or machine crash. This example outlines a scheme for protecting the analytic logic written inside an SPL Custom operator against failures. When such failures occur, a specific fail-over technique employed here will continue the business logic without any interruption. This is done by making a secondary PE to takeover the tasks of the failed primary PE. Thus, the secondary PE does the detection of the primary PE's failure and then changes its role from a secondary PE to a new primary PE. All of this is done without losing any data during the fail-over. At the same time, the failed primary PE will be automatically restarted to do its work as a new secondary PE. This particular fail-over technique ensures that there is always a primary/secondary pair working in concert to provide high availability for a business-critical operator that is coded and configured in this manner.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/060_simple_pe_failover_technique_at_work_com_acme_failover_test_simple_pe_failover_technique_at_work_spl",
	"urlLink": "",
	"tags": ["recovery", " fail over", " crash", "redundancy"]
}, {
	"State": "live",
	"name": "030_spl_config_at_work",
	"description": "This example introduces one of the must-learn features of the SPL language. SPL language offers an extensive list of options to do configuration at the operator level as well as at the composite level. This application attempts to sprinkle many of the available configuration parameters as shown below.a) host,b) hostColocation,c) partitionColocation,d) placement,e) threadedPort and queue,f) relocatable and many more.In addition, this example shows how to make this application toolkit dependent on another (025_dynamic_filter_at_work) SPL toolkit project.",
	"language": ["SPL"],
	"category": ["Tips", "Configuration", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/030_spl_config_at_work_my_sample3_Main_spl",
	"urlLink": "",
	"tags": ["spl config clause", "spl", "concurrency", " threading", "operator fusion", "threading", "host exlocation", "job submission", "load balancing", "host colocation", " spl config clause", "threaded port", "resource allocation", "application deployment"]
}, {
	"State": "live",
	"name": "048_source_operator_with_control_port",
	"description": "This example shows a way to create a C++ primitive source operator and then provide a control input port for it. Certain classes of applications can make use of this facility to control the kind of data a source operator generates. In addition, this example shows how to pass one or more string literals to the C++ primitive operator as invocation time parameters. As a bonus, this example also shows a simple way to do performance measurement inside the SPL code using the built-in SPL high precision timestamp functions.",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/048_source_operator_with_control_port_source_op_with_control_port_source_operator_with_control_port_spl",
	"urlLink": "",
	"tags": ["customized source operator in c++", " control port", "custom", "read a file", "filesource", "open a file", "c++ primitive operator", " custom source operator", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "055_json_to_tuple_to_json_using_c++",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished using an open source C++ JSON API. In order to run this application, you will be required to download an open source component that carries a BSD license. Please read the detailed instructions available in the SPL file for this project. There is also another SPL project that does similar conversion using Java (049_json_to_tuple_to_json_using_java).",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "ttp://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/055_json_to_tuple_to_json_using_c++_com_acme_test_json_to_tuple_to_json_using_cpp_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "parse json from c++", "jsontotuple", "c++ native function"]
}, {
	"State": "live",
	"name": "029_spl_functions_at_work",
	"description": "This example shows how helper and utility functions can be written using the SPL language. It also shows how such SPL functions can be put to use inside the context of an application. Learning this simple concept will go a long way in doing a lot of neat stuff in real-world applications.",
	"language": ["SPL"],
	"category": [" Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/029_spl_functions_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "007_split_at_work",
	"description": "This example shows how a Split operator can be used to split the incoming tuples based on a key. In this example, the split condition (which tuples comes out on which port) is pre configured through a text file. Alternatively, one can compute the index of the output port on the fly inside the Split operator parameter section.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/007_split_at_work_sample_split_at_work_spl",
	"urlLink": "",
	"tags": ["split", "split", " split stream", " divide stream"]
}, {
	"State": "live",
	"name": "028_multiple_composites_at_work",
	"description": "This example shows the use of multiple composites in a single application. There is a main composite that in turn uses two other composites. This application shows how the additional composites in different namespaces get included into the main composite via the 'use' directive. It also demonstrates how the additional composites can accept their own operator parameters. It teaches the basics of an important feature that will come handy when big applications need to be componentized. ",
	"language": ["SPL"],
	"category": ["Best Practices", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/028_multiple_composites_at_work_my_sample1_Main_spl",
	"urlLink": "",
	"tags": ["multiple composites", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "024_threaded_split_at_work",
	"description": "This example demonstrates an important standard toolkit operator named ThreadedSplit. It is a multi-threaded split that is different from the other content-based Split operator. ThreadedSplit uses its own algorithm to split the incoming tuples to the available output ports to improve concurrency. This will speed up the distribution of tuples by using individual threads assigned to each of the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "performance"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/024_threaded_split_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "split stream", "threaded split"]
}, {
	"State": "live",
	"name": "057_reading_nested_tuple_data_via_file_source",
	"description": "This example shows how to ingest nested tuple data via input files specified in a CSV format. There are certain syntactical rules that need to be followed in specifying data for nested tuples inside a CSV formatted input file. This example is a good one for developers to get an idea about how to do this.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/057_reading_nested_tuple_data_via_file_source_com_acme_test_Test1_spl",
	"urlLink": "",
	"tags": ["filesource", "parse", " nested tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "016_aggregate_at_work",
	"description": "This example shows off yet another powerful standard toolkit operator named the Aggregate. It is very good in computing on the fly aggregate values after collecting a set of tuples. Tuples are grouped based on tumbling and sliding windows with partitioned variants. This example also shows how to use the built-in assignment functions provided by this operator to compute regular statistical calculations such as min, max, average, standard deviation etc.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/016_aggregate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["aggregate", "aggregate", "rolling average", "windowing", "average", "window"]
}, {
	"State": "live",
	"name": "020_metrics_sink_at_work",
	"description": "This example shows how one can use the MetricsSink standard toolkit operator to create application-specific custom metrics that can be viewed in real-time when the application is running. Viewing of custom metrics is typically done inside Streams Explorer view of the Streams Studio or by using the capturestate option in streamtool.",
	"language": ["SPL"],
	"category": ["Monitoring", "metrics"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/020_metrics_sink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["metricssink", "metrics", "custom metrics", "application monitoring", "custom statistics"]
}, {
	"State": "live",
	"name": "002_source_sink_at_work",
	"description": "This example shows how a FileSource operator can be used to read CSV formatted records from a file and then receive those tuples in a FileSink to be written to a file in the data directory of this application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/002_source_sink_at_work_sample_source_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", " ", "filesink"]
}, {
	"State": "live",
	"name": "026_gate_at_work",
	"description": "This is an example that uses the Gate operator from the standard toolkit. This operator delays the incoming tuples until a downstream operator signals with an acknowledgment to receive any further tuples. This is a great way to have a feedback through which we can control the rate at which tuples are passed through. (Please refer to another example named 905_gate_load_balancer that shows the effectiveness of the Gate operator in combination with the ThreadedSplit operator to provide load balancing the incoming tuples.)",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/026_gate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["gate", "wait", " hold tuples until signal", "control tuple flow", "wait for tuples"]
}, {
	"State": "live",
	"name": "050_recursive_dir_scan",
	"description": "This example shows how to use the Streams C++ native function facility to recursively scan a given directory and obtain the names of the files present. The logic for the recursive directory scan polls the specified directory periodically and notifies the downstream operator with a new file that just appeared. There is a companion C++ project for this SPL project. Please refer to the RecursiveDirScanLib project for the C++ logic.Important sequence of logic for this application: 1) SPL code resolves the C++ native function in its native.function/function.xml file.2) A call from the SPL code to the native function lands in the wrapper inline C++ function defined in the RecursiveDirScanWrappers.h file of the companion C++ project.3) From that wrapper function, it gets access to a singleton C++ object of the RecursiveDirScan class and then invokes the getFileNamesInDirectory C++ method.4) When that C++ method returns, it will have the results stored in a list<string> reference that was passed to it.5) Back in the SPL code, there is additional logic to cache the already seen files and to filter only the newly found files to send to the downstream operator.In order to test this application, please refer to the commentary at the top of the SPL file in this project.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED RecursiveDirScanLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/050_recursive_dir_scan_recursive_dir_scan_recursive_dir_scan_spl",
	"urlLink": "",
	"tags": ["recursive directory scan in c++", "c++ native functions example", "c++", "application development"]
}, {
	"State": "live",
	"name": "005_throttle_at_work",
	"description": "This example shows how a stream can be throttled to flow at a specified rate. This example also mixes other operators such as Beacon, Custom, and FileSink.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/005_throttle_at_work_sample_throttle_at_work_spl",
	"urlLink": "",
	"tags": ["custom", " throttle", " slow down", "delay", " create tuple", " custom", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "004_delay_at_work",
	"description": "This example shows how a Delay standard toolkit operator can be used to delay a stream. This example also introduces the Custom operator that can be used to perform custom logic. You can also notice the use of a state variable that is mutable inside the Custom operator. It also shows how to create a new tuple on the fly and do your own submissions onto the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/004_delay_at_work_sample_delay_at_work_spl",
	"urlLink": "",
	"tags": ["custom", "delay", "filesink"]
}, {
	"State": "live",
	"name": "019_import_export_at_work",
	"description": "This example demonstrates how two different SPL applications can share streams between them. This is an important feature that is elegantly done using two pseudo operators called Export and Import. This application also shows how two different main composites can be part of the same application by using two different namespaces. As an aside, there is also a demonstration of using a Custom operator to customize the Beacon generated tuples by involving state variables. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/019_import_export_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["import", "export", "microservices", "export stream", "import stream"]
}, {
	"State": "live",
	"name": "033_java_primitive_operator_at_work",
	"description": "This example shows how a Java primitive operator is created from scratch. Java primitive operator is different from JavaOp that you have seen earlier in a different example. Java primitive operator is a first class operator in SPL, whereas JavaOp only permits a callout to another Java operator. In addition, Java primitive operator has the advantage of keeping its name as the operator\u2019s runtime instance name.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT NAMED RSS_Reader_Primitive THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/033_java_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["java operator", " primitive java operator", "java operators", " application development"]
}, {
	"State": "live",
	"name": "043_import_export_filter_at_work",
	"description": "This example shows how to use the SPL feature to apply a filter for what gets exported and what gets imported. This powerful feature lets the downstream import operators to specify what kind of tuples they want to receive by specifying conditional expressions involving tuple attributes. That lets the Streams runtime to apply content-based filtering at the point of export. Those who need such a feature to control what information should be sent downstream based on the tuple contents can make use of this flexible feature. This can be done on the fly without stopping and restarting the application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/043_import_export_filter_at_work_importing_exporting_filter_import_with_filter_spl",
	"urlLink": "",
	"tags": ["import", "export", "filtered import", "dynamic import", "microservices", "export stream", " filter imports", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "017_filesource_filesink_at_work",
	"description": "We have used the FileSource and the FileSink operators in other examples before. However, this example shows off the following intriguing features that will become handy in a lot of practical situations.a) Automatic deletion of a file after the FileSource finishes reading all the records.b) Flushing the sink file on demand after writing a certain number of tuples.c) Ability of the FileSource to move the file once it reads all the content in that file.d) Creating a fresh and new output sink file after writing a certain number of tuples.e) Ability of the FileSource to keep reading from a hot file as new CSV records get written to the end of that file.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/017_filesource_filesink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "advanced file operations", " reread file", "move file", " hot file", "flushing", " automatic deletion", "delete a file"]
}, {
	"State": "live",
	"name": "008_get_submission_time_value",
	"description": "This example shows how the tuple attributes can be assigned values that were supplied by the user at the application/job submission time. It employs the getSubmissionTimeValue function to obtain different values made of different SPL data types. ",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/008_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["functor", "getsubmissiontimevalue", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "014_sort_at_work",
	"description": "This example shows the use of the Sort operator in the context of an application. Sort operator is highly configurable with all kinds of windowing support. In this example, the following window configurations are applied for sorting the incoming tuples:a) Count-based tumbling window.b) Time-based tumbling window.c) Punctuation-based tumbling window.d) Delta-based tumbling window.e) Count-based sliding window.",
	"language": ["SPL"],
	"category": ["transform", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/014_sort_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["sort", " Time-based", " delta based", "time based", " punctuation-based Count based", "sort", " tumbling window", " sliding window", " punctuation based", " sort with windowing", " count-based"]
}, {
	"State": "live",
	"name": "027_java_op_at_work",
	"description": "This example shows an important operator that brings Java into the C++ dominated world of Streams!!! That operator is called JavaOp, which is used to call out to other operators implemented in Java using the Java Operator API. In this example, we will have a tiny Java logic that will calculate the current time and add that time string to a tuple attribute and output that tuple. There is another example that shows the Java primitive operator that is different from the JavaOp operator.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/027_java_op_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in and C++ primitive operators that are NOT fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["dps", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "dps", "c++", "share data"]
}, {
	"State": "live",
	"name": "053_java_primitive_operator_with_complex_output_tuple_types",
	"description": "This example shows important features that can be done via a Java primitive operator. It shows how to do tracing and logging inside a Java operator. It also shows how we can create an output tuple inside a Java primitive operator to have a list of tuple objects carrying complex typed attributes.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT CALLED Java_Complex_Tuple_Type_Submission THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/053_java_primitive_operator_with_complex_output_tuple_types_com_acme_test_java_primitive_operator_with_complex_output_tuple_types_spl",
	"urlLink": "",
	"tags": [" submit tuple from java", "tuple in java operator", "tuple", "complex tuple", " java operator"]
}, {
	"State": "live",
	"name": "035_c++_primitive_operator_at_work",
	"description": "This example shows the steps required to create a C++ primitive operator from scratch. In this application, a C++ primitive operator model XML file can be explored to learn how the different fields in that file are configured. Then, the code generation template header and implementation files (*_h.cgt and *_cpp.cgt) can be browsed to learn about the primitive operator logic. Additionally, this example demonstrates about including a Java operator and a C++ primitive operator as part of the application flow.",
	"language": ["C++"],
	"category": ["Operators & Functions", " Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/035_c++_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["c++ operators", "c++ example", "c++ operator model", " application development"]
}, {
	"State": "live",
	"name": "037_odbc_adapters_for_solid_db_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters for connecting to a SolidDB in-memory database. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test SolidDB database inside IBM. You have to create your own SolidDB database and tables to make this application work in your environment.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/037_odbc_adapters_for_solid_db_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "soliddb"]
}, {
	"State": "live",
	"name": "061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators that are not fused with each other and a C++ native function. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "hsa", "java", "native function", "db", "query"]
}, {
	"State": "live",
	"name": "006_barrier_at_work",
	"description": "This example shows how to synchronize the incoming tuples using a Barrier operator. It uses a bank deposit/debit scenario to split the deposit/debit requests, perform that account activity, and then combine the post-activity result with the incoming requests. Barrier operator does what is needed to accomplish that i.e. it waits for the streams to arrive at all the configured input ports before emitting an output tuple.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/006_barrier_at_work_sample_barrier_at_work_spl",
	"urlLink": "",
	"tags": ["barrier", "functor", "custom", " slow down stream", "delay", "create tuple", "slow down tuples", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "015_join_at_work",
	"description": "This example shows one of the power-packed standard toolkit operators; i.e. Join. This operator is so versatile that it is hard to do justice in explaining it thoroughly in a simple example such as this one.  This example provides coverage to the following Join operator features.a) Inner Join,b) Inner (Equi) Join,c) Left Outer Join,d) Right Outer Join,e) Full Outer Join",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/015_join_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["join", " inner join", "merge stream", "join", " join stream"]
}, {
	"State": "live",
	"name": "031_spl_mixed_mode_at_work",
	"description": "This example shows a cool SPL feature called mixed-mode support. In this, developers can mix PERL code islands inside of an SPL application. Mixed-mode enables the easy parameterization of SPL applications. This example gives a slight flavor of how a PERL code snippet inter-mixed with SPL allows us to parameterize the SPL Stream names and the number of output stream definitions for an SPL operator. ",
	"language": ["perl"],
	"category": ["Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/031_spl_mixed_mode_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["mixed mode", "spl", "mixed mode", "code generation"]
}, {
	"State": "live",
	"name": "047_streams_host_tags_at_work",
	"description": "This example shows how to create host tags for a given Streams instance and then use those host tags inside an SPL application. By using host tags, it is possible to avoid hard-coding the host names inside the SPL application code. Detailed instructions about creating and using host tags are explained in this example.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/047_streams_host_tags_at_work_host_tags_streams_host_tags_at_work_spl",
	"urlLink": "",
	"tags": ["tcpsink", "tcpsource", "host tags", "operator placement", "tcpsink", "tcpsource", "config clause", "host pools"]
}, {
	"State": "live",
	"name": "049_json_to_tuple_to_json_using_java",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished via two Java primitive operators that make use of the JSON (Java) libraries shipped as part of the Streams product. Those two Java operators are JSONToTuple and TupleToJSON.Note: Performance of the JSON<-->Tuple conversion in this example will be limited by the speed of your Java environment. If you want to get better performance, C++ code would help. There is a separate example (055_json_to_tuple_to_json_using_c++) that shows how to do this conversion using C++.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/049_json_to_tuple_to_json_using_java_sample_Main_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "json", " parse json"]
}, {
	"State": "live",
	"name": "046_launching_external_apps_in_spl",
	"description": "This example shows how to launch/execute an external application within the Streams SPL code. In this case, we defined a simple C++ native function in which we have the required C++ code to launch an external application. That C++ code uses pipes to execute a given application. This function would be useful to launch any custom script within the Streams application logic when certain application specific conditions arise.",
	"language": ["C++"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/046_launching_external_apps_in_spl_launch_external_apps_launching_external_apps_spl",
	"urlLink": "",
	"tags": ["launch an external app", " spl utility functions", "launch a program", "execute program"]
}, {
	"State": "live",
	"name": "059_dynamic_scaleout_of_streams_application",
	"description": "This example shows a particular style of writing Streams applications that can be scaled up or scaled down as the application input workload changes. It uses a familiar scenario from the Financial Services Sector, where the price calculation engines will require scaling up when the market data load increases. Code written in this example uses a pattern for starting more instances of an analytic operator to increase parallelism. New instances of such analytic operators can be started on demand without disrupting the already running application flow. As soon as the newly started operator instances are ready, application load will be promptly distributed across the existing and the newly started instances of that operator. In the same way, when the application data load is not high, some of the most recently started operator instances can be stopped to release the CPU cores for other use. This technique is one of many ways to design Streams applications that will scale up and down dynamically according to the changing input data workload.",
	"language": ["C++"],
	"category": ["Tips,Best Practices,Microservices,Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/059_dynamic_scaleout_of_streams_application_com_ibm_streams_pricing_test_DynamicScaleOut_spl",
	"urlLink": "",
	"tags": ["import", "export", "ingest"]
}, {
	"State": "live",
	"name": "009_custom_operator_using_get_submission_time_value",
	"description": "This example demonstrates how to assign tuple attributes at the time of job submission inside a custom operator. When the incoming tuples arrive at the Custom operator in this example, values entered by the user at the application startup are assigned to the tuple attributes.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/009_custom_operator_using_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["custom", "getsubmissiontimevalue", "get submission time value", " submission time", "parameter lists", " parameters", " custom", "create tuple"]
}, {
	"State": "live",
	"name": "012_filter_functor_at_work",
	"description": "This example puts the two commonly used standard toolkit operators to work. They are Filter and Functor. Filter allows you to route tuples based on conditional checks. It provides two output ports to send the matched tuples on the first output port and the unmatched tuples on the second output port. Functor operator allows us to transform the incoming tuple attributes and then to send it on many different output ports with different stream schemas.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/012_filter_functor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["functor", "filter", "filter tuples", "remove tuples"]
}, {
	"State": "live",
	"name": "022_deduplicate_at_work",
	"description": "This example describes the use of an important operator that is highly applicable in many Telco scenarios. That operator is called DeDuplicate, which eliminates duplicate tuples for a specified duration of time. It also has an optional second output port on which duplicate tuples could be sent out for additional processing.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/022_deduplicate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["deduplicate", "separate two streams", "remove duplicates", "split streams"]
}, {
	"State": "live",
	"name": "013_punctor_at_work",
	"description": "This example shows how a Punctor operator could be used in an application. Punctor operator allows us to transform the input tuples and then inject puncuation markers either before or after the output tuple as configured.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/013_punctor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["punctor", "custom logic", " generate punctuation", " punctuation"]
}, {
	"State": "live",
	"name": "036_shared_lib_primitive_operator_at_work",
	"description": "This example demonstrates two important techniques that will be commonly used in real-world use cases.1) Creating a C++ primitive operator.2) Calling a function available inside a .so shared library from the C++ primitive operator logic.Application logic here is to receive input tuples as hostnames and then make the C++ primitive operator logic invoke a shared library function that does a name server lookup.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED PrimitiveOperatorLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/036_shared_lib_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" c++", " operator dependencies", " library", "shared library", " application development"]
}, {
	"State": "live",
	"name": "003_sink_at_work",
	"description": "This example shows how FileSink and Custom sinks can be employed in applications. It also shows how a Beacon operator can be used to customize tuple attributes. In addition, it introduces the Filter operator to route the incoming tuples by inspecting their attributes using a conditional statement specified in the filter parameter. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/003_sink_at_work_sample_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "read", "files", "write"]
}, {
	"State": "live",
	"name": "023_union_at_work",
	"description": "This example demonstrates an utility operator called Union. This operator combines all the tuples from several input ports as they arrive and emits a single output stream. All the input ports must have a schema that contains attributes of the same name and type as those of the output port. The order of the attributes in the input ports need not match the order in the output port.",
	"language": ["SPL"],
	"category": ["enrich", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/023_union_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["union", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "044_streams_checkpointing_at_work",
	"description": "This example shows a key feature of Streams by which an operator's state variables can be preserved when a PE fails and gets restarted. This is done through a combination of the SPL configuration directives named 'checkpointing' and 'restartable'. Developers can protect their critical operator data by taking advantage of this built-in checkpointing feature. When you run this example, you will see data flows without any gaps or interruption, when a PE is killed manually and then gets restored automatically by the Streams runtime.",
	"language": ["SPL"],
	"category": ["performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/044_streams_checkpointing_at_work_checkpointing_example_streams_checkpointing_at_work_spl",
	"urlLink": "",
	"tags": ["checkpoint config clause", " data consistency", "automatic checkpointing", " fail over", "checkpoint"]
}, {
	"State": "live",
	"name": "001_hello_world_in_spl",
	"description": "This example is the simplest possible SPL application. It uses a Beacon operator to generate tuples that carry Hello World' messages. A custom sink operator receives the tuples from Beacon and displays it on the console.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/001_hello_world_in_spl_HelloWorld_spl",
	"urlLink": "",
	"tags": ["custom"]
}, {
	"State": "live",
	"name": "038_spl_built_in_functions_at_work",
	"description": "This is a very simple example that showcases a random collection of powerful built-in SPL functions that are available out of the box. This application demonstrates how time, math, and collection type functions can be used inside of an SPL application.",
	"language": ["SPL"],
	"category": ["Best Practices", "Collections and Data Types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/038_spl_built_in_functions_at_work_test_scratch_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "data types", " spl functions", "list", " mutable", " convert time stamp", "map", " convert timestamp", " timestamps", " utility functions"]
}, {
	"State": "live",
	"name": "056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example shows a particular implementation about how data can be shared across multiple FUSED operators using an SPL map based in-memory store. Here, we are simply showing a way to use the SPL native function facility to perform data sharing via an SPL map based in-memory store that will serve multiple SPL standard toolkit operators and C++ primitive operators. As mentioned above, this example shows data sharing between multiple operators that are fused inside a single PE (Processing Element). This technical approach is called Process Store (ps). This data sharing mechanism will NOT work between operators that are on different PEs. This example depends on the com.ibm.streamsx.ps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "db", "query"]
}, {
	"State": "live",
	"name": "034_odbc_adapters_for_db2_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test DB2 database inside IBM. You have to create your own DB2 database and tables to make this application work in your environment. After creating your own database and tables, you have to change the etc/connections.xml file in this application's directory to match your database/table names, userid, and password. You also have to make changes in the SPL code using your database information for all the three ODBC operator invocations.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/034_odbc_adapters_for_db2_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "db2"]
}, {
	"State": "live",
	"name": "051_native_functions_with_collection_types",
	"description": "This example shows an important feature of Streams. In Streams applications, it may be necessary to accept and return collection types in and out of the C++ native functions. This will require native function code that can directly deal with types such as list, map, and tuple. Streams provides C++ reflection APIs to directly deal with such collection types. In this example, developers can learn how to build native functions inside of a C++ class and then pass list, map, and tuple types to those native functions. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionsWithCollectionTypesLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/051_native_functions_with_collection_types_com_ibm_nf_test_native_functions_with_collection_types_spl",
	"urlLink": "",
	"tags": [" data types", "native functions", "collections", "list", "c++ native functions example", "c++", "map", " collections", "application development", "tuple"]
}, {
	"State": "live",
	"name": "040_ingest_data_generation_in_spl",
	"description": "This example shows how SPL provides rich features to generate synthetic data required for large scale testing. Many real-life applications in the Telco and the Retail Banking sectors consume large amounts of daily business data through CSV formatted text files. There could be huge amounts of CDR data from several telecom circles or daily transaction data for millions of accounts in a retail bank.While building and testing the SPL applications, it will become necessary to generate such ingest data files with artificial data that is close enough to be realistic. This application shows how such large amounts of data in several thousands of files can be created very quickly using the SPL standard toolkit operators as well as the SPL file IO and math random built-in functions.",
	"language": ["SPL"],
	"category": ["Collections & Data types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/040_ingest_data_generation_in_spl_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["test data generation", "data types", " test data generation", "sample data", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "025_dynamic_filter_at_work",
	"description": "This example deals with an interesting standard toolkit operator called DynamicFilter. This operator is a special version of the Filter operator that you have already seen in another example; it decides at runtime which input tuples will be passed through, based on the control input it receives. This operator is applicable in many real-life scenarios. This example also demonstrates using a second composite operator to perform a sub-task that the main composite will make use of. There is also coverage to show how the second composite can take its own operator parameters.  ",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/025_dynamic_filter_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["dynamicfilter", " reusable composite", "composite operators", " filter based on input", " dynamic filter", "filter"]
}, {
	"State": "live",
	"name": "062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators and a Java primitive operator that are not fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples. In this SPL project, you will find a Java primitive operator that exercises all the dps APIs in a very comprehensive manner. In order to get access to the dps APIs, this project's build path is added with dps-helper.jar available inside the com.ibm.streamsx.dps toolkit directory (i.e. impl/java/bin). Please read at the top of this project's SPL file and the TickerIdGenerator.java primitive operator file for an extensive commentary about how to run this example.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["java database", "database", "redis", "hsa", "java", "mongo", "db", "query"]
}, {
	"State": "live",
	"name": "063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators",
	"description": "This example shows how to create a tuple on the fly inside a Java primitive operator. In addition, this example also shows how to convert a tuple into a blob (Java byte buffer) and how to convert a blob (Java byte buffer) in to a tuple. It is an interesting concept that a Java primitive operator developer can put into use in certain situations that warrant dynamic tuple creation, tuple encoding and decoding all inside Java.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators_application_Main_spl",
	"urlLink": "",
	"tags": ["create tuple in java", "java", "blob", "blob java", "create tuple"]
}, {
	"State": "live",
	"name": "064_using_spl_composite_params",
	"description": "This example shows different ways in which parameters can be passed to SPL composites. It is very useful to pass parameters as attributes, expressions, functions, operators, and types. These different ways of passing parameters to the composites is the focus of this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/064_using_spl_composite_params_com_acme_test_CompositeParams_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "065_using_multiple_threads_in_java_operator",
	"description": "This example shows how to spawn multiple threads within a Java primitive operator and then submit tuples from within those threads concurrently.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/065_using_multiple_threads_in_java_operator_com_acme_test_JavaOpSubmitFromMultipleThreads_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "066_load_balancing_using_gate",
	"description": "As documented in the Streams Info Center for a ThreadedSplit, if the processing time of a tuple varies considerably depending on the tuple data, it may cause problems where a tuple with a long processing time may cause subsequent tuples to be backed up in the stream. This example shows how a Gate operator can be combined with the ThreadedSplit can be used to ensure load balancing.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/066_load_balancing_using_gate_com_acme_test_LoadBalancingUsingGate_spl",
	"urlLink": "",
	"tags": ["gate"]
}, {
	"State": "live",
	"name": "067_simple_java_source_operator",
	"description": "This example shows a basic source operator implemented in Java. There are specific steps required for implementing a source operator and it can be learned in this example.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/067_simple_java_source_operator_com_acme_test_Temp1_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "068_tuple_introspection_inside_java_operator",
	"description": "This example shows how a tuple can be introspected to learn about its structure and its attribute names and their types. Inside a Java operator, this example illustrates how it is possible to recursively look through a tuple to understand its composition.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/068_tuple_introspection_inside_java_operator_com_acme_test_Temp2_spl",
	"urlLink": "",
	"tags": ["parse tuple in java", "tuples", " collections", "tuples java", " java operator", "spl data types"]
}, {
	"State": "live",
	"name": "069_changing_map_value_during_iteration",
	"description": "Until the release of Streams version 3.2.1, it was not possible to modify the value of a map inside an iteration loop. This example shows a new feature available in Streams version 3.2.1 that permits the value of a map to be modified inside a for loop.",
	"language": ["SPL"],
	"category": ["Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/069_changing_map_value_during_iteration_com_acme_test_ChangeCollectionValue_spl",
	"urlLink": "",
	"tags": ["iterate over map", "iteration", "change map value", "change map"]
}, {
	"State": "live",
	"name": "070_convert_block_data_into_tuples_using_parse",
	"description": "This example shows how a block of data ingested as a blob type can be converted into individual tuples using the Parse operator.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/070_convert_block_data_into_tuples_using_parse_com_acme_test_ConvertBlockDataWithParse_spl",
	"urlLink": "",
	"tags": ["parse", "parse operator", "parse blob", " convert blob to tuple", "tuples"]
}, {
	"State": "live",
	"name": "071_java_native_functions",
	"description": "Java native functions provide a cool way to add user-defined functions in Java and then call them directly within the SPL code. This example shows how easy it is to create java native functions.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/071_java_native_functions_com_acme_test_JavaNativeFunctions_spl",
	"urlLink": "",
	"tags": ["create java native function", "java function"]
}, {
	"State": "live",
	"name": "072_using_streams_rest_apis",
	"description": "Streams provides REST APIs to query different kinds of metrics about the instances, jobs, resources during the runtime operation. It is a comprehensive set of APIs that can be used with proper security configuration. This example shows a few different REST APIs in action by invoking them within Java code.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/072_using_streams_rest_apis_com_acme_test_UsingStreamsRestApis_spl",
	"urlLink": "",
	"tags": ["get job info", "monitoring", "rest", "rest api example", "jobs"]
}, {
	"State": "live",
	"name": "073_java_operator_fusion",
	"description": "This example shows how two different Java operators one performing the Sink operation and the other performing the analytics operation can be fused to operate within a single PE.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/073_java_operator_fusion_com_acme_test_JavaFusion_spl",
	"urlLink": "",
	"tags": ["java operator fusion", " ", "fuse multiple operators"]
}, {
	"State": "live",
	"name": "074_user_defined_parallelism_01",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/074_user_defined_parallelism_01_com_acme_test_UDP1_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "075_user_defined_parallelism_02",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/075_user_defined_parallelism_02_com_acme_test_UDP2_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "076_user_defined_parallelism_03",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/076_user_defined_parallelism_03_com_acme_test_UDP3_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "077_user_defined_parallelism_04",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/077_user_defined_parallelism_04_com_acme_test_UDP4_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "078_user_defined_parallelism_05",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/078_user_defined_parallelism_05_com_acme_test_UDP5_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "079_user_defined_parallelism_06",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/079_user_defined_parallelism_06_com_acme_test_UDP6_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "080_user_defined_parallelism_07",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/080_user_defined_parallelism_07_com_acme_test_UDP7_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "081_user_defined_parallelism_08",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/081_user_defined_parallelism_08_com_acme_test_UDP8_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "083_user_defined_parallelism_10",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/083_user_defined_parallelism_10_com_acme_test_UDP10_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "084_user_defined_parallelism_11",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/084_user_defined_parallelism_11_com_acme_test_UDP11_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "085_user_defined_parallelism_12",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/085_user_defined_parallelism_12_com_acme_test_UDP12_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "086_jms_source_sink_using_activemq",
	"description": "This example shows how the JMSSource and JMSSink operators from the Streams standard toolkit can be put to use for sending messages from Streams into the Apache ActiveMQ queues and topics as well as reading messages from there into Streams.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/086_jms_source_sink_using_activemq_com_acme_test_JMSSourceSink_spl",
	"urlLink": "",
	"tags": ["jmssource", "jmssink", "activemq", "jms", "read from activemq", "messaging server", "messaging"]
}, {
	"State": "live",
	"name": "087_email_alerts_via_java_native_function",
	"description": "This example shows a way to send email alerts from an SPL application. It is done via a Java native function by using the email API available in the standard Java platform. If an SMTP server is present in the same   network where Streams servers are connected, the technique shown in this example can be put to use for sending email alerts.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/087_email_alerts_via_java_native_function_com_acme_test_EmailAlerts_spl",
	"urlLink": "",
	"tags": ["send email", "email", "send email java"]
}, {
	"State": "live",
	"name": "088_java_operator_params_and_multiple_input_output_ports",
	"description": "This example demonstrates two different features of the Java primitive operator framework. It first shows how operator parameters can be easily processed inside the Java operators via the @Parameter annotations. Then, it shows how multiple input and output ports can be accessed inside the Java operators. As a bonus, it also shows a better approach for on the fly creation of the output tuples made with complex nested types.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/088_java_operator_params_and_multiple_input_output_ports_com_acme_test_JavaOperatorParams_spl",
	"urlLink": "",
	"tags": [" complex tuple", "java operator", "java operator parameters", "java", "java operator", "multiple input ports", "create tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "089_integrating_streams_apps_with_web_apps",
	"description": "This example demonstrates one of the Streams open source toolkits (com.ibm.streamsx.inet). Using this toolkit one can integrate Streams applications with web applications. Please read the comments in the SPL file for this example project to download that toolkit, install it, and then use that toolkit inside a simple SPL application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/089_integrating_streams_apps_with_web_apps_com_acme_test_WebCalculator_spl",
	"urlLink": "",
	"tags": ["httptupleinjection", "httptupleview", "send tuples to browser", "rest", "post to streams app", "streams web app"]
}, {
	"State": "live",
	"name": "090_consistent_region_spl_01",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/090_consistent_region_spl_01_com_acme_test_ConsistentRegion1_spl",
	"urlLink": "",
	"tags": ["filesource"]
}, {
	"State": "live",
	"name": "091_consistent_region_spl_02",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a FileSource with a periodic checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/091_consistent_region_spl_02_com_acme_test_ConsistentRegion2_spl",
	"urlLink": "",
	"tags": ["beacon"]
}, {
	"State": "live",
	"name": "092_consistent_region_spl_03",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the Aggregate operators in this application is forcefully aborted inside the application multiple times to prove that application survive those multiple crashes at different times and yet will continue processing tuples normally after an automatic restart of that failed operator. In addition, during those crashes Streams will preserve the windows contents of that Aggregate operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/092_consistent_region_spl_03_com_acme_test_ConsistentRegion3_spl",
	"urlLink": "",
	"tags": ["aggregate", "consistent region window", "consistent region"]
}, {
	"State": "live",
	"name": "093_consistent_region_spl_04",
	"description": "This example demonstrates how a consistent region can be defined for two different composites acting as sources for this application. These consistent regions have a periodic checkpoint trigger. Couple of different Custom operators connected to those sources are forcefully aborted inside the application. Output streams of those operators will be combined using a Join operator. This application will ensure that the application will continue normally without losing any tuples by withstanding the random crash of those two Custom operators.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/093_consistent_region_spl_04_com_acme_test_ConsistentRegion4_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "094_consistent_region_spl_05",
	"description": "This particular example shows how only a portion of the topology will take part in the consistent region by having an autonomous section in the application graph. This example simulates the operator failure by aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Join operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration. At the same time, parts of the application that is in the autonomous area will get duplicate tuples during a crash recovery happening in the consistent region of this application graph. This example's purpose is to make the users aware of this fact. In the autonomous area, measures need to be taken to do deduplication.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/094_consistent_region_spl_05_com_acme_test_ConsistentRegion5_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "095_consistent_region_spl_06",
	"description": "This particular example shows how a non-replay capable Source operator will not be a show stopper when it comes to employing the consistent region feature in such applications. When using sources (such as TCPSource) that can't realistically replay data, there is way to configure your application with consistent region by using an utility operator called ReplaybleStart (shipped with the Streams product). In this example, we will use a topology that uses TCPSource along with ReplayableStart to achieve application-level fault tolerance.  This example simulates the operator failure by  aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Aggregate operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/095_consistent_region_spl_06_com_acme_test_ConsistentRegion6_spl",
	"urlLink": "",
	"tags": ["replayablestart", "enabling consistent regions when the source operator deos not support it", "failure", "crash", "high availability", "guaranteed processing", "replayablestart"]
}, {
	"State": "live",
	"name": "100_using_jmx_api_01",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to query information about the Streams domain and the Streams instance.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/100_using_jmx_api_01",
	"urlLink": "",
	"tags": ["jmx api", " jmx", " monitoring", "domains"]
}, {
	"State": "live",
	"name": "101_using_jmx_api_02",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to fetch the bulk contents from a log file for a given domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/101_using_jmx_api_02",
	"urlLink": "",
	"tags": ["jmx api", "monitoring", "get log file using jmx"]
}, {
	"State": "live",
	"name": "102_using_jmx_api_03",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX API notifications to get alerted via callback functions about an inactivity timeout in a given Streams domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/102_using_jmx_api_03",
	"urlLink": "",
	"tags": [" use jmx to get alerts", " monitoring", "jmx"]
}, {
	"State": "live",
	"name": "103_view_annotation_at_work",
	"description": "This is a simple SPL application that explains the steps required to use the view annotation and then how to visualize the view annotated stream in the Streams web console. Detailed steps to view the annotated stream are shown in the commentary section of this SPL file.",
	"language": ["SPL"],
	"category": ["Visualization and Reporting"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/103_view_annotation_at_work_com_acme_test_ViewAnnotationAtWork_spl",
	"urlLink": "",
	"tags": ["microsoft excel", "console", "view annotation", "views example", "reporting", "views", "visualization", "visualize", "application development"]
}, {
	"State": "live",
	"name": "901_cat_example",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/901_cat_example_NumberedCat_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "902_word_count",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/902_word_count_word_count_WordCount_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "903_unique",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/903_unique_Main_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "904_primitive_round_robin_split",
	"description": "SPL Introductory Tutorial sample",
	"language": ["C++"],
	"category": ["Beginner/General", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/904_primitive_round_robin_split_Main_spl",
	"urlLink": "",
	"tags": ["pair", "spl"]
}, {
	"State": "live",
	"name": "905_gate_load_balancer",
	"description": "SPL Introductory Tutorial sample\"",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/905_gate_load_balancer_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "gate", "improve performance", " gate operator", "threadedsplit", " threadedsplit operator", "gate"]
}
,{
	"State": "live",
	"name": "021_pair_at_work",
	"description": "This example shows off the Pair operator that is used for pairing tuples arriving on different input ports. Only when all the tuples arrive at all the input ports, this operator will emit them one after the other in their order of arrival.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/021_pair_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["pair", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "'096_consistent_region_spl_07",
	"description": "This particular example shows how a C++ primitive operator can play a role inside a consistent region.  It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/096_consistent_region_cpp_07_com_acme_test_ConsistentRegion7_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "097_consistent_region_spl_08",
	"description": "This particular example shows how a C++ primitive operator can be the start of a consistent region.   It demonstrates how to implement the necessary callback functions and also verifies that no data is lost after a crash",
	"language": ["C++"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/097_consistent_region_cpp_08_com_acme_test_ConsistentRegion8_spl/",
	"urlLink": "",
	"tags": ["cpp consistent region example", "consistent region c++"]
}, {
	"State": "live",
	"name": "098_consistent_region_spl_09",
	"description": "This particular example shows how a Java primitive operator can be the start of a consistent region. ",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/098_consistent_region_java_09_com_acme_test_ConsistentRegion9_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "099_consistent_region_spl_10",
	"description": "This particular example shows how a Java primitive operator can play a role inside a consistent region. It demonstrates how to implement the necessary callback functions to support checkpoint and reset.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/099_consistent_region_java_10_com_acme_test_ConsistentRegion10_spl/",
	"urlLink": "",
	"tags": ["java consistent region example", "consistent region", "java consistent region"]
}, {
	"State": "live",
	"name": "052_streams_to_python",
	"description": "This example shows a powerful feature of Streams to wrap existing code assets written using the Python programming language. This example teaches developers how to use the Streams C++ native functions to call any arbitrary Python function and return the results back to SPL code. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory. You can also read a very detailed IBM developerWorks technical article about this example:  http://tinyurl.com/c3s56fq. [THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED StreamsToPythonLib THAT IS DESCRIBED BELOW.]",
	"language": ["Python"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/052_streams_to_python_python_wrapper_example_streams_to_python_spl",
	"urlLink": "",
	"tags": ["call python from streams", "call python from cpp", " python"]
}, {
	"State": "live",
	"name": "042_dynamic_import_export_api_at_work",
	"description": "This example shows how to use the SPL APIs for dynamically importing and exporting streams. This is achieved by changing the import and export properties on the fly. This powerful feature in Streams provides a way to change the streams producing and consuming operators to change the way in which they publish and subscribe to streams while the application is running.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/042_dynamic_import_export_api_at_work_dynamic_importing_exporting_dynamic_import_spl",
	"urlLink": "",
	"tags": ["import", "export", "dynamic import", "microservices", "export stream", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "045_file_source_using_spl_custom_operator",
	"description": "This example shows how to create source operators using the Custom operator available in the SPL standard toolkit. Starting in Streams 3.x, it is possible to create source operators without writing primitive source operators in C++ or Java. Simple source operators can be written using the built-in SPL Custom operator. This will come handy for those who don't want to do an extra layer of C++ or Java code for satisfying simple needs for a source operator. You will see a function of a file source operator being implemented all using SPL code in this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions,Ingest & Store Data", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/045_file_source_using_spl_custom_operator_my_file_source_file_source_using_spl_custom_operator_spl",
	"urlLink": "",
	"tags": ["read a file using a custom", "custom", "read a file", "filesource", "open a file", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "032_native_function_at_work",
	"description": "This application shows how native functions written in C++ can be called within an SPL application.There are two ways in which native functions can be written in C++.1) Code for the C++ functions can be written in a C++ header file.2) C++ functions can be written outside of the SPL project and packaged into a shared library (.so) file. All the SPL developer will have to work with are an .so file and a C++ header file.This application demonstrates incorporating native functions built in both of those ways.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/032_native_function_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["native functions", " c++", "native functions", " native function model"]
}, {
	"State": "live",
	"name": "018_directory_scan_at_work",
	"description": "This example demonstrates one of the important features desired in the real world (mostly in the Retail banking and in the Telco industries). In many real-world scenarios, they still work via files and such files get dropped into a directory for processing. It is shown here how the DirectoryScan operator picks up a new file as soon as it appears inside an input directory. (Apply caution if huge files are copied to the watch directory. DirectoryScan may detect that big file copy as multiple new files and output multiple tuples with the same file name.)",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/018_directory_scan_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["directoryscan", "read directory repeatedly", "scan directory", "list directory"]
}, {
	"State": "live",
	"name": "011_compiler_intrinsic_functions",
	"description": "Streams compiler provides several intrinsic functions to query the SPL filename, file path, absolute path of the directory, source code line number, composite instance name etc. This example shows the use of the compiler intrinsic functions inside of a Functor operator.",
	"language": ["SPL"],
	"category": ["troubleshooting", " Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/011_compiler_intrinsic_functions_Main_spl",
	"urlLink": "",
	"tags": ["compiler functions", " utility", "print line number", " current line number", " print line number", " print file name", " get file name", " print debug info"]
}, {
	"State": "live",
	"name": "041_real_time_streams_merger",
	"description": "This example shows how two or more incoming streams with a common schema can be merged to flow in a sequence one after the other. This merger is done using a common tuple attribute in those multiple incoming streams as a key. We will use a C++ primitive operator called OrderedMerger that is included in this project. In order for the OrderedMerger to work correctly, it is assumed that multiple input streams for this primitive operator should already be in sorted order based on the key used to merge and sequence them together. ",
	"language": ["C++"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/041_real_time_streams_merger_real_time_merger_real_time_streams_merger_spl",
	"urlLink": "",
	"tags": ["ordered merge of multiple streams ", "c++ example", "merge  streams", " join streams", " c++ operator model", " application development", " ordered merge"]
}, {
	"State": "live",
	"name": "060_simple_pe_failover_technique_at_work",
	"description": "This example shows a way to protect the logic in an analytic operator  when its PE (Processing Element) or its host machine crashes. It uses a well-known fail-over technique that is done through a primary/secondary pair configured for an operator that will need safety from PE or machine crash. This example outlines a scheme for protecting the analytic logic written inside an SPL Custom operator against failures. When such failures occur, a specific fail-over technique employed here will continue the business logic without any interruption. This is done by making a secondary PE to takeover the tasks of the failed primary PE. Thus, the secondary PE does the detection of the primary PE's failure and then changes its role from a secondary PE to a new primary PE. All of this is done without losing any data during the fail-over. At the same time, the failed primary PE will be automatically restarted to do its work as a new secondary PE. This particular fail-over technique ensures that there is always a primary/secondary pair working in concert to provide high availability for a business-critical operator that is coded and configured in this manner.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/060_simple_pe_failover_technique_at_work_com_acme_failover_test_simple_pe_failover_technique_at_work_spl",
	"urlLink": "",
	"tags": ["recovery", " fail over", " crash", "redundancy"]
}, {
	"State": "live",
	"name": "030_spl_config_at_work",
	"description": "This example introduces one of the must-learn features of the SPL language. SPL language offers an extensive list of options to do configuration at the operator level as well as at the composite level. This application attempts to sprinkle many of the available configuration parameters as shown below.a) host,b) hostColocation,c) partitionColocation,d) placement,e) threadedPort and queue,f) relocatable and many more.In addition, this example shows how to make this application toolkit dependent on another (025_dynamic_filter_at_work) SPL toolkit project.",
	"language": ["SPL"],
	"category": ["Tips", "Configuration", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/030_spl_config_at_work_my_sample3_Main_spl",
	"urlLink": "",
	"tags": ["spl config clause", "spl", "concurrency", " threading", "operator fusion", "threading", "host exlocation", "job submission", "load balancing", "host colocation", " spl config clause", "threaded port", "resource allocation", "application deployment"]
}, {
	"State": "live",
	"name": "048_source_operator_with_control_port",
	"description": "This example shows a way to create a C++ primitive source operator and then provide a control input port for it. Certain classes of applications can make use of this facility to control the kind of data a source operator generates. In addition, this example shows how to pass one or more string literals to the C++ primitive operator as invocation time parameters. As a bonus, this example also shows a simple way to do performance measurement inside the SPL code using the built-in SPL high precision timestamp functions.",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/048_source_operator_with_control_port_source_op_with_control_port_source_operator_with_control_port_spl",
	"urlLink": "",
	"tags": ["customized source operator in c++", " control port", "custom", "read a file", "filesource", "open a file", "c++ primitive operator", " custom source operator", "parse a file", "spl utility functions"]
}, {
	"State": "live",
	"name": "055_json_to_tuple_to_json_using_c++",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished using an open source C++ JSON API. In order to run this application, you will be required to download an open source component that carries a BSD license. Please read the detailed instructions available in the SPL file for this project. There is also another SPL project that does similar conversion using Java (049_json_to_tuple_to_json_using_java).",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "ttp://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/055_json_to_tuple_to_json_using_c++_com_acme_test_json_to_tuple_to_json_using_cpp_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "parse json from c++", "jsontotuple", "c++ native function"]
}, {
	"State": "live",
	"name": "029_spl_functions_at_work",
	"description": "This example shows how helper and utility functions can be written using the SPL language. It also shows how such SPL functions can be put to use inside the context of an application. Learning this simple concept will go a long way in doing a lot of neat stuff in real-world applications.",
	"language": ["SPL"],
	"category": [" Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/029_spl_functions_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "007_split_at_work",
	"description": "This example shows how a Split operator can be used to split the incoming tuples based on a key. In this example, the split condition (which tuples comes out on which port) is pre configured through a text file. Alternatively, one can compute the index of the output port on the fly inside the Split operator parameter section.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/007_split_at_work_sample_split_at_work_spl",
	"urlLink": "",
	"tags": ["split", "split", " split stream", " divide stream"]
}, {
	"State": "live",
	"name": "028_multiple_composites_at_work",
	"description": "This example shows the use of multiple composites in a single application. There is a main composite that in turn uses two other composites. This application shows how the additional composites in different namespaces get included into the main composite via the 'use' directive. It also demonstrates how the additional composites can accept their own operator parameters. It teaches the basics of an important feature that will come handy when big applications need to be componentized. ",
	"language": ["SPL"],
	"category": ["Best Practices", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/028_multiple_composites_at_work_my_sample1_Main_spl",
	"urlLink": "",
	"tags": ["multiple composites", "best practices", "reuse composites", "modularization", " application design"]
}, {
	"State": "live",
	"name": "024_threaded_split_at_work",
	"description": "This example demonstrates an important standard toolkit operator named ThreadedSplit. It is a multi-threaded split that is different from the other content-based Split operator. ThreadedSplit uses its own algorithm to split the incoming tuples to the available output ports to improve concurrency. This will speed up the distribution of tuples by using individual threads assigned to each of the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "performance"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/024_threaded_split_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "split stream", "threaded split"]
}, {
	"State": "live",
	"name": "057_reading_nested_tuple_data_via_file_source",
	"description": "This example shows how to ingest nested tuple data via input files specified in a CSV format. There are certain syntactical rules that need to be followed in specifying data for nested tuples inside a CSV formatted input file. This example is a good one for developers to get an idea about how to do this.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/057_reading_nested_tuple_data_via_file_source_com_acme_test_Test1_spl",
	"urlLink": "",
	"tags": ["filesource", "parse", " nested tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "016_aggregate_at_work",
	"description": "This example shows off yet another powerful standard toolkit operator named the Aggregate. It is very good in computing on the fly aggregate values after collecting a set of tuples. Tuples are grouped based on tumbling and sliding windows with partitioned variants. This example also shows how to use the built-in assignment functions provided by this operator to compute regular statistical calculations such as min, max, average, standard deviation etc.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/016_aggregate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["aggregate", "aggregate", "rolling average", "windowing", "average", "window"]
}, {
	"State": "live",
	"name": "020_metrics_sink_at_work",
	"description": "This example shows how one can use the MetricsSink standard toolkit operator to create application-specific custom metrics that can be viewed in real-time when the application is running. Viewing of custom metrics is typically done inside Streams Explorer view of the Streams Studio or by using the capturestate option in streamtool.",
	"language": ["SPL"],
	"category": ["Monitoring", "metrics"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/020_metrics_sink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["metricssink", "metrics", "custom metrics", "application monitoring", "custom statistics"]
}, {
	"State": "live",
	"name": "002_source_sink_at_work",
	"description": "This example shows how a FileSource operator can be used to read CSV formatted records from a file and then receive those tuples in a FileSink to be written to a file in the data directory of this application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/002_source_sink_at_work_sample_source_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", " ", "filesink"]
}, {
	"State": "live",
	"name": "026_gate_at_work",
	"description": "This is an example that uses the Gate operator from the standard toolkit. This operator delays the incoming tuples until a downstream operator signals with an acknowledgment to receive any further tuples. This is a great way to have a feedback through which we can control the rate at which tuples are passed through. (Please refer to another example named 905_gate_load_balancer that shows the effectiveness of the Gate operator in combination with the ThreadedSplit operator to provide load balancing the incoming tuples.)",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/026_gate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["gate", "wait", " hold tuples until signal", "control tuple flow", "wait for tuples"]
}, {
	"State": "live",
	"name": "050_recursive_dir_scan",
	"description": "This example shows how to use the Streams C++ native function facility to recursively scan a given directory and obtain the names of the files present. The logic for the recursive directory scan polls the specified directory periodically and notifies the downstream operator with a new file that just appeared. There is a companion C++ project for this SPL project. Please refer to the RecursiveDirScanLib project for the C++ logic.Important sequence of logic for this application: 1) SPL code resolves the C++ native function in its native.function/function.xml file.2) A call from the SPL code to the native function lands in the wrapper inline C++ function defined in the RecursiveDirScanWrappers.h file of the companion C++ project.3) From that wrapper function, it gets access to a singleton C++ object of the RecursiveDirScan class and then invokes the getFileNamesInDirectory C++ method.4) When that C++ method returns, it will have the results stored in a list<string> reference that was passed to it.5) Back in the SPL code, there is additional logic to cache the already seen files and to filter only the newly found files to send to the downstream operator.In order to test this application, please refer to the commentary at the top of the SPL file in this project.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED RecursiveDirScanLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Ingest & Store Data", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/050_recursive_dir_scan_recursive_dir_scan_recursive_dir_scan_spl",
	"urlLink": "",
	"tags": ["recursive directory scan in c++", "c++ native functions example", "c++", "application development"]
}, {
	"State": "live",
	"name": "005_throttle_at_work",
	"description": "This example shows how a stream can be throttled to flow at a specified rate. This example also mixes other operators such as Beacon, Custom, and FileSink.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/005_throttle_at_work_sample_throttle_at_work_spl",
	"urlLink": "",
	"tags": ["custom", " throttle", " slow down", "delay", " create tuple", " custom", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "004_delay_at_work",
	"description": "This example shows how a Delay standard toolkit operator can be used to delay a stream. This example also introduces the Custom operator that can be used to perform custom logic. You can also notice the use of a state variable that is mutable inside the Custom operator. It also shows how to create a new tuple on the fly and do your own submissions onto the output ports.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/004_delay_at_work_sample_delay_at_work_spl",
	"urlLink": "",
	"tags": ["custom", "delay", "filesink"]
}, {
	"State": "live",
	"name": "019_import_export_at_work",
	"description": "This example demonstrates how two different SPL applications can share streams between them. This is an important feature that is elegantly done using two pseudo operators called Export and Import. This application also shows how two different main composites can be part of the same application by using two different namespaces. As an aside, there is also a demonstration of using a Custom operator to customize the Beacon generated tuples by involving state variables. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/019_import_export_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["import", "export", "microservices", "export stream", "import stream"]
}, {
	"State": "live",
	"name": "033_java_primitive_operator_at_work",
	"description": "This example shows how a Java primitive operator is created from scratch. Java primitive operator is different from JavaOp that you have seen earlier in a different example. Java primitive operator is a first class operator in SPL, whereas JavaOp only permits a callout to another Java operator. In addition, Java primitive operator has the advantage of keeping its name as the operator\u2019s runtime instance name.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT NAMED RSS_Reader_Primitive THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/033_java_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["java operator", " primitive java operator", "java operators", " application development"]
}, {
	"State": "live",
	"name": "043_import_export_filter_at_work",
	"description": "This example shows how to use the SPL feature to apply a filter for what gets exported and what gets imported. This powerful feature lets the downstream import operators to specify what kind of tuples they want to receive by specifying conditional expressions involving tuple attributes. That lets the Streams runtime to apply content-based filtering at the point of export. Those who need such a feature to control what information should be sent downstream based on the tuple contents can make use of this flexible feature. This can be done on the fly without stopping and restarting the application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/043_import_export_filter_at_work_importing_exporting_filter_import_with_filter_spl",
	"urlLink": "",
	"tags": ["import", "export", "filtered import", "dynamic import", "microservices", "export stream", " filter imports", "dynamic export", "import stream"]
}, {
	"State": "live",
	"name": "017_filesource_filesink_at_work",
	"description": "We have used the FileSource and the FileSink operators in other examples before. However, this example shows off the following intriguing features that will become handy in a lot of practical situations.a) Automatic deletion of a file after the FileSource finishes reading all the records.b) Flushing the sink file on demand after writing a certain number of tuples.c) Ability of the FileSource to move the file once it reads all the content in that file.d) Creating a fresh and new output sink file after writing a certain number of tuples.e) Ability of the FileSource to keep reading from a hot file as new CSV records get written to the end of that file.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/017_filesource_filesink_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "advanced file operations", " reread file", "move file", " hot file", "flushing", " automatic deletion", "delete a file"]
}, {
	"State": "live",
	"name": "008_get_submission_time_value",
	"description": "This example shows how the tuple attributes can be assigned values that were supplied by the user at the application/job submission time. It employs the getSubmissionTimeValue function to obtain different values made of different SPL data types. ",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/008_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["functor", "getsubmissiontimevalue", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "014_sort_at_work",
	"description": "This example shows the use of the Sort operator in the context of an application. Sort operator is highly configurable with all kinds of windowing support. In this example, the following window configurations are applied for sorting the incoming tuples:a) Count-based tumbling window.b) Time-based tumbling window.c) Punctuation-based tumbling window.d) Delta-based tumbling window.e) Count-based sliding window.",
	"language": ["SPL"],
	"category": ["transform", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/014_sort_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["sort", " Time-based", " delta based", "time based", " punctuation-based Count based", "sort", " tumbling window", " sliding window", " punctuation based", " sort with windowing", " count-based"]
}, {
	"State": "live",
	"name": "027_java_op_at_work",
	"description": "This example shows an important operator that brings Java into the C++ dominated world of Streams!!! That operator is called JavaOp, which is used to call out to other operators implemented in Java using the Java Operator API. In this example, we will have a tiny Java logic that will calculate the current time and add that time string to a tuple attribute and output that tuple. There is another example that shows the Java primitive operator that is different from the JavaOp operator.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/027_java_op_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in and C++ primitive operators that are NOT fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["dps", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "dps", "c++", "share data"]
}, {
	"State": "live",
	"name": "053_java_primitive_operator_with_complex_output_tuple_types",
	"description": "This example shows important features that can be done via a Java primitive operator. It shows how to do tracing and logging inside a Java operator. It also shows how we can create an output tuple inside a Java primitive operator to have a list of tuple objects carrying complex typed attributes.[THIS EXAMPLE HAS A COMPANION JAVA PROJECT CALLED Java_Complex_Tuple_Type_Submission THAT IS DESCRIBED BELOW.]",
	"language": ["Java"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/053_java_primitive_operator_with_complex_output_tuple_types_com_acme_test_java_primitive_operator_with_complex_output_tuple_types_spl",
	"urlLink": "",
	"tags": [" submit tuple from java", "tuple in java operator", "tuple", "complex tuple", " java operator"]
}, {
	"State": "live",
	"name": "035_c++_primitive_operator_at_work",
	"description": "This example shows the steps required to create a C++ primitive operator from scratch. In this application, a C++ primitive operator model XML file can be explored to learn how the different fields in that file are configured. Then, the code generation template header and implementation files (*_h.cgt and *_cpp.cgt) can be browsed to learn about the primitive operator logic. Additionally, this example demonstrates about including a Java operator and a C++ primitive operator as part of the application flow.",
	"language": ["C++"],
	"category": ["Operators & Functions", " Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/035_c++_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["c++ operators", "c++ example", "c++ operator model", " application development"]
}, {
	"State": "live",
	"name": "037_odbc_adapters_for_solid_db_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters for connecting to a SolidDB in-memory database. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test SolidDB database inside IBM. You have to create your own SolidDB database and tables to make this application work in your environment.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/037_odbc_adapters_for_solid_db_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "soliddb"]
}, {
	"State": "live",
	"name": "061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators that are not fused with each other and a C++ native function. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "redis", "hsa", "java", "native function", "db", "query"]
}, {
	"State": "live",
	"name": "006_barrier_at_work",
	"description": "This example shows how to synchronize the incoming tuples using a Barrier operator. It uses a bank deposit/debit scenario to split the deposit/debit requests, perform that account activity, and then combine the post-activity result with the incoming requests. Barrier operator does what is needed to accomplish that i.e. it waits for the streams to arrive at all the configured input ports before emitting an output tuple.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/006_barrier_at_work_sample_barrier_at_work_spl",
	"urlLink": "",
	"tags": ["barrier", "functor", "custom", " slow down stream", "delay", "create tuple", "slow down tuples", " coordinate", " synchronize"]
}, {
	"State": "live",
	"name": "015_join_at_work",
	"description": "This example shows one of the power-packed standard toolkit operators; i.e. Join. This operator is so versatile that it is hard to do justice in explaining it thoroughly in a simple example such as this one.  This example provides coverage to the following Join operator features.a) Inner Join,b) Inner (Equi) Join,c) Left Outer Join,d) Right Outer Join,e) Full Outer Join",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/015_join_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["join", " inner join", "merge stream", "join", " join stream"]
}, {
	"State": "live",
	"name": "031_spl_mixed_mode_at_work",
	"description": "This example shows a cool SPL feature called mixed-mode support. In this, developers can mix PERL code islands inside of an SPL application. Mixed-mode enables the easy parameterization of SPL applications. This example gives a slight flavor of how a PERL code snippet inter-mixed with SPL allows us to parameterize the SPL Stream names and the number of output stream definitions for an SPL operator. ",
	"language": ["perl"],
	"category": ["Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/031_spl_mixed_mode_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["mixed mode", "spl", "mixed mode", "code generation"]
}, {
	"State": "live",
	"name": "047_streams_host_tags_at_work",
	"description": "This example shows how to create host tags for a given Streams instance and then use those host tags inside an SPL application. By using host tags, it is possible to avoid hard-coding the host names inside the SPL application code. Detailed instructions about creating and using host tags are explained in this example.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/047_streams_host_tags_at_work_host_tags_streams_host_tags_at_work_spl",
	"urlLink": "",
	"tags": ["tcpsink", "tcpsource", "host tags", "operator placement", "tcpsink", "tcpsource", "config clause", "host pools"]
}, {
	"State": "live",
	"name": "049_json_to_tuple_to_json_using_java",
	"description": "This example shows how an SPL application can consume JSON formatted data and convert it to SPL tuples. It also shows how to do the reverse action i.e. converting SPL tuples to JSON formatted data. JSON<-->Tuple bidirectional conversion is accomplished via two Java primitive operators that make use of the JSON (Java) libraries shipped as part of the Streams product. Those two Java operators are JSONToTuple and TupleToJSON.Note: Performance of the JSON<-->Tuple conversion in this example will be limited by the speed of your Java environment. If you want to get better performance, C++ code would help. There is a separate example (055_json_to_tuple_to_json_using_c++) that shows how to do this conversion using C++.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/049_json_to_tuple_to_json_using_java_sample_Main_spl",
	"urlLink": "",
	"tags": ["tupletojson", "jsontotuple", "json", " parse json"]
}, {
	"State": "live",
	"name": "046_launching_external_apps_in_spl",
	"description": "This example shows how to launch/execute an external application within the Streams SPL code. In this case, we defined a simple C++ native function in which we have the required C++ code to launch an external application. That C++ code uses pipes to execute a given application. This function would be useful to launch any custom script within the Streams application logic when certain application specific conditions arise.",
	"language": ["C++"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/046_launching_external_apps_in_spl_launch_external_apps_launching_external_apps_spl",
	"urlLink": "",
	"tags": ["launch an external app", " spl utility functions", "launch a program", "execute program"]
}, {
	"State": "live",
	"name": "059_dynamic_scaleout_of_streams_application",
	"description": "This example shows a particular style of writing Streams applications that can be scaled up or scaled down as the application input workload changes. It uses a familiar scenario from the Financial Services Sector, where the price calculation engines will require scaling up when the market data load increases. Code written in this example uses a pattern for starting more instances of an analytic operator to increase parallelism. New instances of such analytic operators can be started on demand without disrupting the already running application flow. As soon as the newly started operator instances are ready, application load will be promptly distributed across the existing and the newly started instances of that operator. In the same way, when the application data load is not high, some of the most recently started operator instances can be stopped to release the CPU cores for other use. This technique is one of many ways to design Streams applications that will scale up and down dynamically according to the changing input data workload.",
	"language": ["C++"],
	"category": ["Tips,Best Practices,Microservices,Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/059_dynamic_scaleout_of_streams_application_com_ibm_streams_pricing_test_DynamicScaleOut_spl",
	"urlLink": "",
	"tags": ["import", "export", "ingest"]
}, {
	"State": "live",
	"name": "009_custom_operator_using_get_submission_time_value",
	"description": "This example demonstrates how to assign tuple attributes at the time of job submission inside a custom operator. When the incoming tuples arrive at the Custom operator in this example, values entered by the user at the application startup are assigned to the tuple attributes.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/009_custom_operator_using_get_submission_time_value_Main_spl",
	"urlLink": "",
	"tags": ["custom", "getsubmissiontimevalue", "get submission time value", " submission time", "parameter lists", " parameters", " custom", "create tuple"]
}, {
	"State": "live",
	"name": "012_filter_functor_at_work",
	"description": "This example puts the two commonly used standard toolkit operators to work. They are Filter and Functor. Filter allows you to route tuples based on conditional checks. It provides two output ports to send the matched tuples on the first output port and the unmatched tuples on the second output port. Functor operator allows us to transform the incoming tuple attributes and then to send it on many different output ports with different stream schemas.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/012_filter_functor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["functor", "filter", "filter tuples", "remove tuples"]
}, {
	"State": "live",
	"name": "022_deduplicate_at_work",
	"description": "This example describes the use of an important operator that is highly applicable in many Telco scenarios. That operator is called DeDuplicate, which eliminates duplicate tuples for a specified duration of time. It also has an optional second output port on which duplicate tuples could be sent out for additional processing.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/022_deduplicate_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["deduplicate", "separate two streams", "remove duplicates", "split streams"]
}, {
	"State": "live",
	"name": "013_punctor_at_work",
	"description": "This example shows how a Punctor operator could be used in an application. Punctor operator allows us to transform the input tuples and then inject puncuation markers either before or after the output tuple as configured.",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/013_punctor_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["punctor", "custom logic", " generate punctuation", " punctuation"]
}, {
	"State": "live",
	"name": "036_shared_lib_primitive_operator_at_work",
	"description": "This example demonstrates two important techniques that will be commonly used in real-world use cases.1) Creating a C++ primitive operator.2) Calling a function available inside a .so shared library from the C++ primitive operator logic.Application logic here is to receive input tuples as hostnames and then make the C++ primitive operator logic invoke a shared library function that does a name server lookup.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED PrimitiveOperatorLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Operators & Functions", "Best Practices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/036_shared_lib_primitive_operator_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": [" c++", " operator dependencies", " library", "shared library", " application development"]
}, {
	"State": "live",
	"name": "003_sink_at_work",
	"description": "This example shows how FileSink and Custom sinks can be employed in applications. It also shows how a Beacon operator can be used to customize tuple attributes. In addition, it introduces the Filter operator to route the incoming tuples by inspecting their attributes using a conditional statement specified in the filter parameter. ",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/003_sink_at_work_sample_sink_at_work_spl",
	"urlLink": "",
	"tags": [" filesource", "filesink", "read", "files", "write"]
}, {
	"State": "live",
	"name": "023_union_at_work",
	"description": "This example demonstrates an utility operator called Union. This operator combines all the tuples from several input ports as they arrive and emits a single output stream. All the input ports must have a schema that contains attributes of the same name and type as those of the output port. The order of the attributes in the input ports need not match the order in the output port.",
	"language": ["SPL"],
	"category": ["enrich", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/023_union_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["union", "synchronize streams", "join two streams", "merge streams"]
}, {
	"State": "live",
	"name": "044_streams_checkpointing_at_work",
	"description": "This example shows a key feature of Streams by which an operator's state variables can be preserved when a PE fails and gets restarted. This is done through a combination of the SPL configuration directives named 'checkpointing' and 'restartable'. Developers can protect their critical operator data by taking advantage of this built-in checkpointing feature. When you run this example, you will see data flows without any gaps or interruption, when a PE is killed manually and then gets restored automatically by the Streams runtime.",
	"language": ["SPL"],
	"category": ["performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/044_streams_checkpointing_at_work_checkpointing_example_streams_checkpointing_at_work_spl",
	"urlLink": "",
	"tags": ["checkpoint config clause", " data consistency", "automatic checkpointing", " fail over", "checkpoint"]
}, {
	"State": "live",
	"name": "001_hello_world_in_spl",
	"description": "This example is the simplest possible SPL application. It uses a Beacon operator to generate tuples that carry Hello World' messages. A custom sink operator receives the tuples from Beacon and displays it on the console.",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/001_hello_world_in_spl_HelloWorld_spl",
	"urlLink": "",
	"tags": ["custom"]
}, {
	"State": "live",
	"name": "038_spl_built_in_functions_at_work",
	"description": "This is a very simple example that showcases a random collection of powerful built-in SPL functions that are available out of the box. This application demonstrates how time, math, and collection type functions can be used inside of an SPL application.",
	"language": ["SPL"],
	"category": ["Best Practices", "Collections and Data Types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/038_spl_built_in_functions_at_work_test_scratch_Main_spl",
	"urlLink": "",
	"tags": ["spl functions", "data types", " spl functions", "list", " mutable", " convert time stamp", "map", " convert timestamp", " timestamps", " utility functions"]
}, {
	"State": "live",
	"name": "056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators",
	"description": "This example shows a particular implementation about how data can be shared across multiple FUSED operators using an SPL map based in-memory store. Here, we are simply showing a way to use the SPL native function facility to perform data sharing via an SPL map based in-memory store that will serve multiple SPL standard toolkit operators and C++ primitive operators. As mentioned above, this example shows data sharing between multiple operators that are fused inside a single PE (Processing Element). This technical approach is called Process Store (ps). This data sharing mechanism will NOT work between operators that are on different PEs. This example depends on the com.ibm.streamsx.ps toolkit that is packaged along with these examples.",
	"language": ["C++"],
	"category": ["Tips", "Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/056_data_sharing_between_fused_spl_custom_and_cpp_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["database", "db", "query"]
}, {
	"State": "live",
	"name": "034_odbc_adapters_for_db2_at_work",
	"description": "This example shows the use of the three Streams ODBC adapters. Those operators are ODBCSource, ODBCAppend, and ODBCEnrich. The code in this example is written to access a particular test DB2 database inside IBM. You have to create your own DB2 database and tables to make this application work in your environment. After creating your own database and tables, you have to change the etc/connections.xml file in this application's directory to match your database/table names, userid, and password. You also have to make changes in the SPL code using your database information for all the three ODBC operator invocations.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/034_odbc_adapters_for_db2_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["odbcappend", " odbcsource", "odbcenrich", "database", "odbc", "jdbc", "db2"]
}, {
	"State": "live",
	"name": "051_native_functions_with_collection_types",
	"description": "This example shows an important feature of Streams. In Streams applications, it may be necessary to accept and return collection types in and out of the C++ native functions. This will require native function code that can directly deal with types such as list, map, and tuple. Streams provides C++ reflection APIs to directly deal with such collection types. In this example, developers can learn how to build native functions inside of a C++ class and then pass list, map, and tuple types to those native functions. In order to run this example, please follow the instructions specified in the README.txt file in the SPL project directory.[THIS EXAMPLE HAS A COMPANION C++ PROJECT CALLED NativeFunctionsWithCollectionTypesLib THAT IS DESCRIBED BELOW.]",
	"language": ["C++"],
	"category": ["Collections and Data Types", "Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/051_native_functions_with_collection_types_com_ibm_nf_test_native_functions_with_collection_types_spl",
	"urlLink": "",
	"tags": [" data types", "native functions", "collections", "list", "c++ native functions example", "c++", "map", " collections", "application development", "tuple"]
}, {
	"State": "live",
	"name": "040_ingest_data_generation_in_spl",
	"description": "This example shows how SPL provides rich features to generate synthetic data required for large scale testing. Many real-life applications in the Telco and the Retail Banking sectors consume large amounts of daily business data through CSV formatted text files. There could be huge amounts of CDR data from several telecom circles or daily transaction data for millions of accounts in a retail bank.While building and testing the SPL applications, it will become necessary to generate such ingest data files with artificial data that is close enough to be realistic. This application shows how such large amounts of data in several thousands of files can be created very quickly using the SPL standard toolkit operators as well as the SPL file IO and math random built-in functions.",
	"language": ["SPL"],
	"category": ["Collections & Data types", "Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/040_ingest_data_generation_in_spl_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["test data generation", "data types", " test data generation", "sample data", " submission time", "parameters", "parameter lists"]
}, {
	"State": "live",
	"name": "025_dynamic_filter_at_work",
	"description": "This example deals with an interesting standard toolkit operator called DynamicFilter. This operator is a special version of the Filter operator that you have already seen in another example; it decides at runtime which input tuples will be passed through, based on the control input it receives. This operator is applicable in many real-life scenarios. This example also demonstrates using a second composite operator to perform a sub-task that the main composite will make use of. There is also coverage to show how the second composite can take its own operator parameters.  ",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/025_dynamic_filter_at_work_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["dynamicfilter", " reusable composite", "composite operators", " filter based on input", " dynamic filter", "filter"]
}, {
	"State": "live",
	"name": "062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators",
	"description": "This example is a very useful one that addresses an important aspect of distributed data sharing between Streams built-in operators and a Java primitive operator that are not fused with each other. This technical approach is called Distributed Process Store (dps). It lets the Streams  developers share any arbitrarily structured data between multiple PEs (Processing Elements) running on a single or multiple machines. This is accomplished via SPL native functions and with the power of the memcached, redis, cassandra, cloudant, hbase, mongo, couchbase, aerospike and redis-cluster open source data stores. It provides a complementary function to what is already done by the Process Store (ps) in another example above (056_XXXXX). This example depends on the com.ibm.streamsx.dps toolkit that is packaged along with these examples. In this SPL project, you will find a Java primitive operator that exercises all the dps APIs in a very comprehensive manner. In order to get access to the dps APIs, this project's build path is added with dps-helper.jar available inside the com.ibm.streamsx.dps toolkit directory (i.e. impl/java/bin). Please read at the top of this project's SPL file and the TickerIdGenerator.java primitive operator file for an extensive commentary about how to run this example.",
	"language": ["Java"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators_com_acme_test_Main_spl",
	"urlLink": "",
	"tags": ["java database", "database", "redis", "hsa", "java", "mongo", "db", "query"]
}, {
	"State": "live",
	"name": "063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators",
	"description": "This example shows how to create a tuple on the fly inside a Java primitive operator. In addition, this example also shows how to convert a tuple into a blob (Java byte buffer) and how to convert a blob (Java byte buffer) in to a tuple. It is an interesting concept that a Java primitive operator developer can put into use in certain situations that warrant dynamic tuple creation, tuple encoding and decoding all inside Java.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/063_on_the_fly_tuple_creation_and_encoding_decoding_in_java_primitive_operators_application_Main_spl",
	"urlLink": "",
	"tags": ["create tuple in java", "java", "blob", "blob java", "create tuple"]
}, {
	"State": "live",
	"name": "064_using_spl_composite_params",
	"description": "This example shows different ways in which parameters can be passed to SPL composites. It is very useful to pass parameters as attributes, expressions, functions, operators, and types. These different ways of passing parameters to the composites is the focus of this example.",
	"language": ["SPL"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/064_using_spl_composite_params_com_acme_test_CompositeParams_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "065_using_multiple_threads_in_java_operator",
	"description": "This example shows how to spawn multiple threads within a Java primitive operator and then submit tuples from within those threads concurrently.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/065_using_multiple_threads_in_java_operator_com_acme_test_JavaOpSubmitFromMultipleThreads_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "066_load_balancing_using_gate",
	"description": "As documented in the Streams Info Center for a ThreadedSplit, if the processing time of a tuple varies considerably depending on the tuple data, it may cause problems where a tuple with a long processing time may cause subsequent tuples to be backed up in the stream. This example shows how a Gate operator can be combined with the ThreadedSplit can be used to ensure load balancing.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/066_load_balancing_using_gate_com_acme_test_LoadBalancingUsingGate_spl",
	"urlLink": "",
	"tags": ["gate"]
}, {
	"State": "live",
	"name": "067_simple_java_source_operator",
	"description": "This example shows a basic source operator implemented in Java. There are specific steps required for implementing a source operator and it can be learned in this example.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/067_simple_java_source_operator_com_acme_test_Temp1_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "068_tuple_introspection_inside_java_operator",
	"description": "This example shows how a tuple can be introspected to learn about its structure and its attribute names and their types. Inside a Java operator, this example illustrates how it is possible to recursively look through a tuple to understand its composition.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/068_tuple_introspection_inside_java_operator_com_acme_test_Temp2_spl",
	"urlLink": "",
	"tags": ["parse tuple in java", "tuples", " collections", "tuples java", " java operator", "spl data types"]
}, {
	"State": "live",
	"name": "069_changing_map_value_during_iteration",
	"description": "Until the release of Streams version 3.2.1, it was not possible to modify the value of a map inside an iteration loop. This example shows a new feature available in Streams version 3.2.1 that permits the value of a map to be modified inside a for loop.",
	"language": ["SPL"],
	"category": ["Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/069_changing_map_value_during_iteration_com_acme_test_ChangeCollectionValue_spl",
	"urlLink": "",
	"tags": ["iterate over map", "iteration", "change map value", "change map"]
}, {
	"State": "live",
	"name": "070_convert_block_data_into_tuples_using_parse",
	"description": "This example shows how a block of data ingested as a blob type can be converted into individual tuples using the Parse operator.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/070_convert_block_data_into_tuples_using_parse_com_acme_test_ConvertBlockDataWithParse_spl",
	"urlLink": "",
	"tags": ["parse", "parse operator", "parse blob", " convert blob to tuple", "tuples"]
}, {
	"State": "live",
	"name": "071_java_native_functions",
	"description": "Java native functions provide a cool way to add user-defined functions in Java and then call them directly within the SPL code. This example shows how easy it is to create java native functions.",
	"language": ["Java"],
	"category": ["Operators & Functions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/071_java_native_functions_com_acme_test_JavaNativeFunctions_spl",
	"urlLink": "",
	"tags": ["create java native function", "java function"]
}, {
	"State": "live",
	"name": "072_using_streams_rest_apis",
	"description": "Streams provides REST APIs to query different kinds of metrics about the instances, jobs, resources during the runtime operation. It is a comprehensive set of APIs that can be used with proper security configuration. This example shows a few different REST APIs in action by invoking them within Java code.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/072_using_streams_rest_apis_com_acme_test_UsingStreamsRestApis_spl",
	"urlLink": "",
	"tags": ["get job info", "monitoring", "rest", "rest api example", "jobs"]
}, {
	"State": "live",
	"name": "073_java_operator_fusion",
	"description": "This example shows how two different Java operators one performing the Sink operation and the other performing the analytics operation can be fused to operate within a single PE.",
	"language": ["Java"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/073_java_operator_fusion_com_acme_test_JavaFusion_spl",
	"urlLink": "",
	"tags": ["java operator fusion", " ", "fuse multiple operators"]
}, {
	"State": "live",
	"name": "074_user_defined_parallelism_01",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/074_user_defined_parallelism_01_com_acme_test_UDP1_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "075_user_defined_parallelism_02",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/075_user_defined_parallelism_02_com_acme_test_UDP2_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "076_user_defined_parallelism_03",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/076_user_defined_parallelism_03_com_acme_test_UDP3_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "077_user_defined_parallelism_04",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/077_user_defined_parallelism_04_com_acme_test_UDP4_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "078_user_defined_parallelism_05",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/078_user_defined_parallelism_05_com_acme_test_UDP5_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "079_user_defined_parallelism_06",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/079_user_defined_parallelism_06_com_acme_test_UDP6_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "080_user_defined_parallelism_07",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/080_user_defined_parallelism_07_com_acme_test_UDP7_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "081_user_defined_parallelism_08",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/081_user_defined_parallelism_08_com_acme_test_UDP8_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "083_user_defined_parallelism_10",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/083_user_defined_parallelism_10_com_acme_test_UDP10_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "084_user_defined_parallelism_11",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/084_user_defined_parallelism_11_com_acme_test_UDP11_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "085_user_defined_parallelism_12",
	"description": "User Defined Parallelism (UDP) is an excellent feature introduced in Streams version 3.2 and it provides a very simple way to run either a part or a full flow graph in a concurrent manner. It is an easy mechanism to scale and speed up the Streams flow graph. These 12 different examples provide a walk through of various UDP scenarios.\"",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/085_user_defined_parallelism_12_com_acme_test_UDP12_spl",
	"urlLink": "",
	"tags": ["udp", "parallel processing", "performance", "user defined parallelism", "scale application"]
}, {
	"State": "live",
	"name": "086_jms_source_sink_using_activemq",
	"description": "This example shows how the JMSSource and JMSSink operators from the Streams standard toolkit can be put to use for sending messages from Streams into the Apache ActiveMQ queues and topics as well as reading messages from there into Streams.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/086_jms_source_sink_using_activemq_com_acme_test_JMSSourceSink_spl",
	"urlLink": "",
	"tags": ["jmssource", "jmssink", "activemq", "jms", "read from activemq", "messaging server", "messaging"]
}, {
	"State": "live",
	"name": "087_email_alerts_via_java_native_function",
	"description": "This example shows a way to send email alerts from an SPL application. It is done via a Java native function by using the email API available in the standard Java platform. If an SMTP server is present in the same   network where Streams servers are connected, the technique shown in this example can be put to use for sending email alerts.",
	"language": ["Java"],
	"category": ["Tips"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/087_email_alerts_via_java_native_function_com_acme_test_EmailAlerts_spl",
	"urlLink": "",
	"tags": ["send email", "email", "send email java"]
}, {
	"State": "live",
	"name": "088_java_operator_params_and_multiple_input_output_ports",
	"description": "This example demonstrates two different features of the Java primitive operator framework. It first shows how operator parameters can be easily processed inside the Java operators via the @Parameter annotations. Then, it shows how multiple input and output ports can be accessed inside the Java operators. As a bonus, it also shows a better approach for on the fly creation of the output tuples made with complex nested types.",
	"language": ["Java"],
	"category": ["Operators & Functions", "Collections and Data Types"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/088_java_operator_params_and_multiple_input_output_ports_com_acme_test_JavaOperatorParams_spl",
	"urlLink": "",
	"tags": [" complex tuple", "java operator", "java operator parameters", "java", "java operator", "multiple input ports", "create tuple", "nested tuple"]
}, {
	"State": "live",
	"name": "089_integrating_streams_apps_with_web_apps",
	"description": "This example demonstrates one of the Streams open source toolkits (com.ibm.streamsx.inet). Using this toolkit one can integrate Streams applications with web applications. Please read the comments in the SPL file for this example project to download that toolkit, install it, and then use that toolkit inside a simple SPL application.",
	"language": ["SPL"],
	"category": ["Ingest & Store Data", "Microservices"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/089_integrating_streams_apps_with_web_apps_com_acme_test_WebCalculator_spl",
	"urlLink": "",
	"tags": ["httptupleinjection", "httptupleview", "send tuples to browser", "rest", "post to streams app", "streams web app"]
}, {
	"State": "live",
	"name": "090_consistent_region_spl_01",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/090_consistent_region_spl_01_com_acme_test_ConsistentRegion1_spl",
	"urlLink": "",
	"tags": ["filesource"]
}, {
	"State": "live",
	"name": "091_consistent_region_spl_02",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a FileSource with a periodic checkpoint trigger. One of the operators in this application is forcefully aborted inside the application to prove that application will continue processing tuples normally after an automatic restart of that failed operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/091_consistent_region_spl_02_com_acme_test_ConsistentRegion2_spl",
	"urlLink": "",
	"tags": ["beacon"]
}, {
	"State": "live",
	"name": "092_consistent_region_spl_03",
	"description": "This example demonstrates how a consistent region can be defined for the entire application topology starting from a Beacon with an operator driven checkpoint trigger. One of the Aggregate operators in this application is forcefully aborted inside the application multiple times to prove that application survive those multiple crashes at different times and yet will continue processing tuples normally after an automatic restart of that failed operator. In addition, during those crashes Streams will preserve the windows contents of that Aggregate operator.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/092_consistent_region_spl_03_com_acme_test_ConsistentRegion3_spl",
	"urlLink": "",
	"tags": ["aggregate", "consistent region window", "consistent region"]
}, {
	"State": "live",
	"name": "093_consistent_region_spl_04",
	"description": "This example demonstrates how a consistent region can be defined for two different composites acting as sources for this application. These consistent regions have a periodic checkpoint trigger. Couple of different Custom operators connected to those sources are forcefully aborted inside the application. Output streams of those operators will be combined using a Join operator. This application will ensure that the application will continue normally without losing any tuples by withstanding the random crash of those two Custom operators.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/093_consistent_region_spl_04_com_acme_test_ConsistentRegion4_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "094_consistent_region_spl_05",
	"description": "This particular example shows how only a portion of the topology will take part in the consistent region by having an autonomous section in the application graph. This example simulates the operator failure by aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Join operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration. At the same time, parts of the application that is in the autonomous area will get duplicate tuples during a crash recovery happening in the consistent region of this application graph. This example's purpose is to make the users aware of this fact. In the autonomous area, measures need to be taken to do deduplication.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/094_consistent_region_spl_05_com_acme_test_ConsistentRegion5_spl",
	"urlLink": "",
	"tags": []
}, {
	"State": "live",
	"name": "095_consistent_region_spl_06",
	"description": "This particular example shows how a non-replay capable Source operator will not be a show stopper when it comes to employing the consistent region feature in such applications. When using sources (such as TCPSource) that can't realistically replay data, there is way to configure your application with consistent region by using an utility operator called ReplaybleStart (shipped with the Streams product). In this example, we will use a topology that uses TCPSource along with ReplayableStart to achieve application-level fault tolerance.  This example simulates the operator failure by  aborting one of the operators automatically when the application is in the middle of executing the logic. By doing that, the core fault tolerance feature of the consistent region will get triggered to recover from a failure that occurred in an application graph. It will prove that the tuples will not be missed and the Aggregate operator's window state will not be compromised during the course of the unexpected operator failure and the subsequent recovery/restoration.",
	"language": ["SPL"],
	"category": ["Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/095_consistent_region_spl_06_com_acme_test_ConsistentRegion6_spl",
	"urlLink": "",
	"tags": ["replayablestart", "enabling consistent regions when the source operator deos not support it", "failure", "crash", "high availability", "guaranteed processing", "replayablestart"]
}, {
	"State": "live",
	"name": "100_using_jmx_api_01",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to query information about the Streams domain and the Streams instance.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/100_using_jmx_api_01",
	"urlLink": "",
	"tags": ["jmx api", " jmx", " monitoring", "domains"]
}, {
	"State": "live",
	"name": "101_using_jmx_api_02",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX APIs to fetch the bulk contents from a log file for a given domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/101_using_jmx_api_02",
	"urlLink": "",
	"tags": ["jmx api", "monitoring", "get log file using jmx"]
}, {
	"State": "live",
	"name": "102_using_jmx_api_03",
	"description": "This is a plain Java application written to show how one can use the JMX APIs available in Streams 4.x and higher versions. Using the JMX (Java Management Extensions) APIs, it is convenient to monitor and manage Streams artifacts. This example shows how one can use the Streams JMX API notifications to get alerted via callback functions about an inactivity timeout in a given Streams domain.",
	"language": ["Java"],
	"category": ["Monitoring"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/102_using_jmx_api_03",
	"urlLink": "",
	"tags": [" use jmx to get alerts", " monitoring", "jmx"]
}, {
	"State": "live",
	"name": "103_view_annotation_at_work",
	"description": "This is a simple SPL application that explains the steps required to use the view annotation and then how to visualize the view annotated stream in the Streams web console. Detailed steps to view the annotated stream are shown in the commentary section of this SPL file.",
	"language": ["SPL"],
	"category": ["Visualization and Reporting"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/103_view_annotation_at_work_com_acme_test_ViewAnnotationAtWork_spl",
	"urlLink": "",
	"tags": ["microsoft excel", "console", "view annotation", "views example", "reporting", "views", "visualization", "visualize", "application development"]
}, {
	"State": "live",
	"name": "901_cat_example",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/901_cat_example_NumberedCat_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "902_word_count",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/902_word_count_word_count_WordCount_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "903_unique",
	"description": "SPL Introductory Tutorial sample",
	"language": ["SPL"],
	"category": ["Beginner/General"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/903_unique_Main_spl",
	"urlLink": "",
	"tags": ["beginner", "spl"]
}, {
	"State": "live",
	"name": "904_primitive_round_robin_split",
	"description": "SPL Introductory Tutorial sample",
	"language": ["C++"],
	"category": ["Beginner/General", "Correlate & Merge Streams"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/904_primitive_round_robin_split_Main_spl",
	"urlLink": "",
	"tags": ["pair", "spl"]
}, {
	"State": "live",
	"name": "905_gate_load_balancer",
	"description": "SPL Introductory Tutorial sample\"",
	"language": ["SPL"],
	"category": ["Correlate & Merge Streams", "Performance & Consistent Regions"],
	"blogPost": "",
	"url": "http://ibmstreams.github.io/streamsx.documentation/samples/spl-for-beginner/905_gate_load_balancer_my_sample_Main_spl",
	"urlLink": "",
	"tags": ["threadedsplit", "gate", "improve performance", " gate operator", "threadedsplit", " threadedsplit operator", "gate"]
}
]
